{"id": "2505.01049v2_gap_0", "arxiv_id": "2505.01049v2", "title": "Multi-Step Consistency Models: Fast Generation with Theoretical Guarantees", "publication_date": "2025-05-02", "problem_input": {"global_context": {"setup": "Let the data distribution $p_{data}$ on $\\mathbb{R}^d$ have a finite second moment $\\mathbb{E}[\\|\\mathbf{x}\\|^2] = m_2$. Consider a forward Ornstein-Uhlenbeck process $d\\mathbf{x}_t = -\\mathbf{x}_t dt + \\sqrt{2} dw_t$, which yields the marginal $p_t$. Let the score function be $\\mathbf{s}_t(\\mathbf{x}) = \\nabla \\log p_t(\\mathbf{x})$. Assume the estimated score function $\\hat{\\mathbf{s}}_t$ satisfies $\\mathbb{E}[\\|\\hat{\\mathbf{s}}_t(\\mathbf{x}) - \\mathbf{s}_t(\\mathbf{x})\\|^2] \\le \\varepsilon_{score}^2$ for all $t$. Consider a multi-step consistency sampling algorithm (Algorithm 1) that generates samples $\\hat{\\mathbf{x}}_0 \\sim \\hat{p}_{t_0}$ by iteratively applying a consistency mapping $\\hat{f}$ and adding Gaussian noise steps defined by time sequence $t_K > \\dots > t_0$. We do \\textit{not} assume the score function $\\mathbf{s}_t$ is Lipschitz continuous.", "goal": "For the multi-step sampling algorithm with step sizes $h'_k$ and total iterations $K$, the KL divergence is bounded by $KL(p_{t_\\delta}\\|\\hat{p}_{t_\\delta}) \\leq (d+m_2) e^{-T} +  e^4{h'}_k^2\\varepsilon^2_{score} \\sum_{k=1}^K\\frac{1}{4{(t_k-{t'}_k)}}$."}, "local_context": {"anchor_latex": "Let $P$ be a probability measure on $\\mathbb{R}^d$. Consider the density of its Gaussian perturbation defined as:\n\\[\np_\\sigma(\\mathbf{x}) \\propto \\int_{\\mathbb{R}^d} \\exp \\left(- \\frac{\\|\\mathbf{x} - \\mathbf{y}\\|^2}{2\\sigma^2} \\right) dP(\\mathbf{y}).\n\\]", "gap_objective": "To control the smoothness of the score function without assuming a global Lipschitz constant, we must bound the sub-exponential norm of the Hessian of the log-density of this Gaussian perturbation."}}, "ground_truth": {"target_citation_key": "chen2023improved", "target_lemma_latex": "\\|\\nabla^2 \\log p_\\sigma(\\mathbf{x})\\|_{F, \\psi_1} \\leq \\frac{d}{\\sigma^2}", "target_citation_content": "Chen, H., Lee, H., and Lu, J. (2023a). \\newblock Improved analysis of score-based generative modeling: User-friendly bounds under minimal smoothness assumptions. \\newblock In \\em International Conference on Machine Learning, pages 4735--4763. PMLR."}}
{"id": "2407.13743v3_gap_1", "arxiv_id": "2407.13743v3", "title": "Optimistic Q-learning for average reward and episodic reinforcement learning", "publication_date": "2024-07-18", "problem_input": {"global_context": {"setup": "Consider a Markov Decision Process (MDP) given by tuple $(\\mathcal{S}, \\mathcal{A}, P, R)$, where $\\mathcal{S}$ and $\\mathcal{A}$ are finite state and action spaces, $P$ is the transition kernel, and $R(s,a) \\in [0,1]$ is the expected reward. We assume there exists a state $s_0 \\in \\mathcal{S}$ and constants $H \\ge 1, p > 0$ such that under any policy (stationary or non-stationary), starting from any state $s \\in \\mathcal{S}$, the probability of visiting $s_0$ within $H$ steps is at least $p$. Let $\\rho^*$ be the optimal asymptotic average reward (gain) and $V^*$ be the optimal bias vector satisfying the Bellman equation $\\rho^* + V^*(s) = \\max_{a} (R(s,a) + [P_{s,a} V^*])$, where $P_{s,a} V^* = \\mathbb{E}_{s' \\sim P(\\cdot|s,a)}[V^*(s')]$. The regret over horizon $T$ is defined as $\\text{Reg}(T) = \\sum_{t=1}^T (\\rho^* - R(s_t, a_t))$.", "goal": "With probability at least $1-\\delta$, the regret is upper bounded by $\\text{Reg}(T) \\le \\tilde{O}\\left(\\frac{1}{p^3}H^5S\\sqrt{AT} + \\frac{1}{p^{4.5}}H^8 S^2A\\right)$."}, "local_context": {"anchor_latex": "HT\\rho^* -  \\sum_{t,h} R(s_t,a_{t,h})   \\le  \\sum_{t,h} \\left(LV^*(s_t) - Lv^{t,h}(s_t) - P_{s_t,a_t}(V^*-v^{t,h})\\right)\\newline + \\sum_{t,h} (P_{s_t,a_t}V^*-V^*(s_t)) +  C_1   \\sum_{t,h} b_{n_{t,h}} + C_2.", "gap_objective": "We must bound the summation of exploration bonuses $\\sum_{t,h} b_{n_{t,h}}$, where $b_n$ scales with $1/\\sqrt{n}$, to prove the sublinear regret term."}}, "ground_truth": {"target_citation_key": "jin2018q", "target_lemma_latex": "\\sum_{t=1}^T \\frac{1}{\\sqrt{N_t(s_t, a_t)}} \\le O(\\sqrt{H S A T})", "target_citation_content": "Chi Jin, Zeyuan Allen-Zhu, Sebastien Bubeck, and Michael~I Jordan. \\newblock Is q-learning provably efficient? \\newblock In \\emphInternational Conference on Neural Information Processing Systems, pages 4868--4878, 2018."}}
{"id": "2502.07232v1_gap_0", "arxiv_id": "2502.07232v1", "title": "Simplifying Adversarially Robust PAC Learning with Tolerance", "publication_date": "2025-02-11", "problem_input": {"global_context": {"setup": "Let $\\mathcal{X}$ be an input domain (e.g., $\\mathbb{R}^d$) equipped with a metric $\\text{dist}$, and $\\mathcal{Y}=\\{0,1\\}$. Let $\\mathcal{H} \\subseteq \\mathcal{Y}^{\\mathcal{X}}$ be a hypothesis class with finite VC-dimension $\\text{VC}(\\mathcal{H})$. Define two perturbation types $\\mathcal{U}, \\mathcal{V}: \\mathcal{X} \\to 2^{\\mathcal{X}}$ such that $\\mathcal{U}(x) \\subseteq \\mathcal{V}(x)$ for all $x$ (tolerance condition). Typically, $\\mathcal{U}(x) = B_r(x)$ and $\\mathcal{V}(x) = B_{r(1+\\gamma)}(x)$ for $\\gamma > 0$. The adversarial loss is defined as $\\ell^{\\mathcal{U}}(h, x, y) = \\max_{z \\in \\mathcal{U}(x)} \\mathbb{I}[h(z) \\neq y]$. A learner $\\mathcal{A}$ outputs a hypothesis (potentially outside $\\mathcal{H}$) based on a sample $S \\sim P^n$.", "goal": "Construct a learning algorithm $\\mathcal{A}$ such that for any distribution $P$, with probability $1-\\delta$, the expected adversarial loss with respect to $\\mathcal{U}$ satisfies: $\\mathbb{E}[\\ell^{\\mathcal{U}}(\\mathcal{A}(S))] \\leq \\inf_{h \\in \\mathcal{H}} \\mathbb{E}[\\ell^{\\mathcal{V}}(h)] + \\epsilon$, with sample complexity polynomial in $d, \\text{VC}(\\mathcal{H}), 1/\\gamma, 1/\\epsilon, 1/\\delta$."}, "local_context": {"anchor_latex": "\\text{The VC-dimension of the loss class } \\mathcal{H}_\\mathcal{U} \\text{ for adversarial robust losses } \\ell^\\mathcal{U} \\text{ can be arbitrarily larger than } \\vc(\\mathcal{H}), \\text{ but for finite perturbation types it can be bounded}", "gap_objective": "Bound the VC-dimension of the robust loss class \\mathcal{H}_\\mathcal{C} when the perturbation sets \\mathcal{C}(x) have a uniform size bound k"}}, "ground_truth": {"target_citation_key": "attias2018improved", "target_lemma_latex": "\\vc(\\mathcal{H}_\\mathcal{C}) \\leq \\vc(\\mathcal{H})\\log(k)", "target_citation_content": "Idan Attias, Aryeh Kontorovich, and Yishay Mansour. \\newblock Improved generalization bounds for adversarially robust learning. \\newblock \\emphJournal of Machine Learning Research, 23\\penalty0 (175):\\penalty0 1--31, 2022\\natexlabb."}}
{"id": "2502.07232v1_gap_1", "arxiv_id": "2502.07232v1", "title": "Simplifying Adversarially Robust PAC Learning with Tolerance", "publication_date": "2025-02-11", "problem_input": {"global_context": {"setup": "Let $\\mathcal{X}$ be an input domain (e.g., $\\mathbb{R}^d$) equipped with a metric $\\text{dist}$, and $\\mathcal{Y}=\\{0,1\\}$. Let $\\mathcal{H} \\subseteq \\mathcal{Y}^{\\mathcal{X}}$ be a hypothesis class with finite VC-dimension $\\text{VC}(\\mathcal{H})$. Define two perturbation types $\\mathcal{U}, \\mathcal{V}: \\mathcal{X} \\to 2^{\\mathcal{X}}$ such that $\\mathcal{U}(x) \\subseteq \\mathcal{V}(x)$ for all $x$ (tolerance condition). Typically, $\\mathcal{U}(x) = B_r(x)$ and $\\mathcal{V}(x) = B_{r(1+\\gamma)}(x)$ for $\\gamma > 0$. The adversarial loss is defined as $\\ell^{\\mathcal{U}}(h, x, y) = \\max_{z \\in \\mathcal{U}(x)} \\mathbb{I}[h(z) \\neq y]$. A learner $\\mathcal{A}$ outputs a hypothesis (potentially outside $\\mathcal{H}$) based on a sample $S \\sim P^n$.", "goal": "Construct a learning algorithm $\\mathcal{A}$ such that for any distribution $P$, with probability $1-\\delta$, the expected adversarial loss with respect to $\\mathcal{U}$ satisfies: $\\mathbb{E}[\\ell^{\\mathcal{U}}(\\mathcal{A}(S))] \\leq \\inf_{h \\in \\mathcal{H}} \\mathbb{E}[\\ell^{\\mathcal{V}}(h)] + \\epsilon$, with sample complexity polynomial in $d, \\text{VC}(\\mathcal{H}), 1/\\gamma, 1/\\epsilon, 1/\\delta$."}, "local_context": {"anchor_latex": "\\vc(\\H_\\ell) < \\infty", "gap_objective": "Justify why the finiteness of the VC-dimension of the loss class implies that Empirical Risk Minimization is a successful PAC learning principle, specifically via uniform convergence."}}, "ground_truth": {"target_citation_key": "vapnikcherv71", "target_lemma_latex": "\\sup_{h \\in \\H} |\\bLo{S}(h) - \\bLo{P}(h)| \\xrightarrow{P} 0", "target_citation_content": "V.~N. Vapnik and A.~Ya. Chervonenkis. \\newblock On the uniform convergence of relative frequencies of events to their probabilities. \\newblock \\emphTheory of Probability \\& Its Applications, 16\\penalty0 (2):\\penalty0 264--280, 1971."}}
{"id": "2502.07232v1_gap_2", "arxiv_id": "2502.07232v1", "title": "Simplifying Adversarially Robust PAC Learning with Tolerance", "publication_date": "2025-02-11", "problem_input": {"global_context": {"setup": "Let $\\mathcal{X}$ be an input domain (e.g., $\\mathbb{R}^d$) equipped with a metric $\\text{dist}$, and $\\mathcal{Y}=\\{0,1\\}$. Let $\\mathcal{H} \\subseteq \\mathcal{Y}^{\\mathcal{X}}$ be a hypothesis class with finite VC-dimension $\\text{VC}(\\mathcal{H})$. Define two perturbation types $\\mathcal{U}, \\mathcal{V}: \\mathcal{X} \\to 2^{\\mathcal{X}}$ such that $\\mathcal{U}(x) \\subseteq \\mathcal{V}(x)$ for all $x$ (tolerance condition). Typically, $\\mathcal{U}(x) = B_r(x)$ and $\\mathcal{V}(x) = B_{r(1+\\gamma)}(x)$ for $\\gamma > 0$. The adversarial loss is defined as $\\ell^{\\mathcal{U}}(h, x, y) = \\max_{z \\in \\mathcal{U}(x)} \\mathbb{I}[h(z) \\neq y]$. A learner $\\mathcal{A}$ outputs a hypothesis (potentially outside $\\mathcal{H}$) based on a sample $S \\sim P^n$.", "goal": "Construct a learning algorithm $\\mathcal{A}$ such that for any distribution $P$, with probability $1-\\delta$, the expected adversarial loss with respect to $\\mathcal{U}$ satisfies: $\\mathbb{E}[\\ell^{\\mathcal{U}}(\\mathcal{A}(S))] \\leq \\inf_{h \\in \\mathcal{H}} \\mathbb{E}[\\ell^{\\mathcal{V}}(h)] + \\epsilon$, with sample complexity polynomial in $d, \\text{VC}(\\mathcal{H}), 1/\\gamma, 1/\\epsilon, 1/\\delta$."}, "local_context": {"anchor_latex": "\\U \\prec \\V \\iff \\forall x \\in X, \\U(x)\\subseteq\\V(x)", "gap_objective": "To formally define a PAC learning framework that relaxes the standard adversarial robustness requirement by comparing the learner's performance against perturbations in $\\U$ to the best possible performance against larger perturbations in $\\V$."}}, "ground_truth": {"target_citation_key": "ashtiani2023adversarially", "target_lemma_latex": "\\rLo{\\U}{P}(\\A(S)) \\leq \\rLo{\\V}{P}(\\cH) + \\epsilon", "target_citation_content": "Hassan Ashtiani, Vinayak Pathak, and Ruth Urner. \\newblock Adversarially robust learning with tolerance. \\newblock In \\emphInternational Conference on Algorithmic Learning Theory, pages 115--135. PMLR, 2023."}}
{"id": "2505.09563v1_gap_0", "arxiv_id": "2505.09563v1", "title": "Improved Sample Upper and Lower Bounds for Trace Estimation of Quantum State Powers", "publication_date": "2025-05-14", "problem_input": {"global_context": {"setup": "Let $\\rho$ be a $d$-dimensional mixed quantum state with eigenvalues $\\alpha_1 \\geq \\dots \\geq \n\\alpha_d \\geq 0$. The algorithm accesses $\\rho$ via $n$ independent copies (samples) $\\rho^{\\otimes n}$. The estimation strategy involves 'weak Schur sampling', which measures $\\rho^{\\otimes n}$ to obtain a Young diagram $\\lambda \\vdash n$ distributed according to the Schur-Weyl distribution $\\operatorname{SW}^n(\\alpha)$, where $\\Pr[\\lambda] = \\dim(\\mathcal{P}_\\lambda) \\cdot s_\\lambda(\\alpha)$.", "goal": "Estimate the trace of quantum state powers $\\tr(\\rho^q) = \\sum_{j=1}^d \\alpha_j^q$ for $q > 1$ to within additive error $\\varepsilon$."}, "local_context": {"anchor_latex": "\\lambda \\sim \\operatorname{SW}^n(\\alpha)", "gap_objective": "Bound the expected squared error (variance) of the row lengths \\lambda_j of a random Young diagram \\lambda sampled from the Schur-Weyl distribution relative to the scaled eigenvalues n\\alpha_j."}}, "ground_truth": {"target_citation_key": "OW17", "target_lemma_latex": "\\E_{\\lambda \\sim \\operatorname{SW}^n\\rbra*{\\alpha}}\\sbra*{\\rbra*{\\lambda_j - \\alpha_j n}^2} \\leq O\\rbra{n}", "target_citation_content": "Ryan O'Donnell and John Wright. \\newblock Efficient quantum tomography II. \\newblock In \\em Proceedings of the 49th Annual ACM Symposium on Theory of Computing, pages 962--974, 2017. \\newblock \\href https://doi.org/10.1145/3055399.3055454 \\pathdoi:10.1145/3055399.3055454."}}
{"id": "2505.09563v1_gap_1", "arxiv_id": "2505.09563v1", "title": "Improved Sample Upper and Lower Bounds for Trace Estimation of Quantum State Powers", "publication_date": "2025-05-14", "problem_input": {"global_context": {"setup": "Let $\\rho$ be a $d$-dimensional mixed quantum state with eigenvalues $\\alpha_1 \\geq \\dots \\geq \n\\alpha_d \\geq 0$. The algorithm accesses $\\rho$ via $n$ independent copies (samples) $\\rho^{\\otimes n}$. The estimation strategy involves 'weak Schur sampling', which measures $\\rho^{\\otimes n}$ to obtain a Young diagram $\\lambda \\vdash n$ distributed according to the Schur-Weyl distribution $\\operatorname{SW}^n(\\alpha)$, where $\\Pr[\\lambda] = \\dim(\\mathcal{P}_\\lambda) \\cdot s_\\lambda(\\alpha)$.", "goal": "Estimate the trace of quantum state powers $\\tr(\\rho^q) = \\sum_{j=1}^d \\alpha_j^q$ for $q > 1$ to within additive error $\\varepsilon$."}, "local_context": {"anchor_latex": "Let $X_j^{\\rbra{l}} \\in \\cbra{0, 1}$ be a random variable such that $X_j^{\\rbra{l}} = 1$ if $\\abs{\\underline{\\lambda}_j^{\\rbra{l}} - \\alpha_j} \\geq 2\\sqrt{c/n}$ and $0$ otherwise.", "gap_objective": "Bound the probability that the average of the i.i.d. indicator variables deviates significantly from their expected value."}}, "ground_truth": {"target_citation_key": "Hoe63", "target_lemma_latex": "\\Pr\\sbra*{ \\abs*{\\frac{1}{n} \\sum_{j=1}^n X_j - \\E\\sbra*{X_1}} \\leq t } \\geq 1 - 2 \\exp\\rbra*{-2nt^2}", "target_citation_content": "Wassily Hoeffding. \\newblock Probability inequalities for sums of bounded random variables. \\newblock \\em Journal of the American Statistical Association, 58(301):13--30, 1963. \\newblock \\href https://doi.org/10.1080/01621459.1963.10500830 \\pathdoi:10.1080/01621459.1963.10500830."}}
{"id": "2502.18346v2_gap_0", "arxiv_id": "2502.18346v2", "title": "Testing Thresholds and Spectral Properties of High-Dimensional Random Toroidal Graphs via Edgeworth-Style Expansions", "publication_date": "2025-02-25", "problem_input": {"global_context": {"setup": "The paper considers Random Geometric Graphs (RGGs) on the d-dimensional torus $\\mathbb{T}^d = [0,1]^d$ with the uniform measure. Edges are formed between vertices $u,v$ if their distance $\\Delta(\\{u,v\\}) \\le \\tau$, where the distance is defined via an $L_q$-norm (either finite $q$ or $L_\\infty$) on the torus. The paper focuses on a random vector $\\mathbf{z}$ representing the normalized sum of pairwise distances in a cycle or chain of length $k$, modified by adding small Gaussian noise $\\boldsymbol{\\eta}_i \\sim \\mathcal{N}(0, d^{-2\\eta}\\mathbf{I}_k)$ to ensure integrability of characteristic functions. The analysis relies heavily on cumulants, characteristic functions, and Edgeworth expansions.", "goal": "To approximate the joint density of the random vector $\\mathbf{z}$ (representing geometric statistics of the graph) using Edgeworth expansions, thereby distinguishing RGGs from Erdős-Rényi graphs."}, "local_context": {"anchor_latex": "K_{\\mathbf{z}}(\\mathbf{t}) = \\sum_{j=1}^\\infty \\frac{1}{j!} \\boldsymbol{\\kappa}_j^\\top(i\\mathbf{t})^{\\otimes j}", "gap_objective": "To provide a multivariate version of Taylor's theorem using Kronecker products and a specific remainder form, suitable for the matrix algebra approach to Edgeworth expansions."}}, "ground_truth": {"target_citation_key": "Kundhi_Rilstone_2020", "target_lemma_latex": "f(\\mathbf{x}) = r_J(\\mathbf{x}) + \\sum_{j = 0}^J \\frac{1}{j!} f^{(j)}(\\mathbf{0})^\\top\\mathbf{x}^{\\otimes j} \\quad \\text{where} \\quad r_J(\\mathbf{x}) = \\frac{1}{J!} \\left(f^{(J)}(c\\mathbf{x}) - f^{(J)}(\\mathbf{0})\\right)^\\top\\mathbf{x}^{\\otimes J}", "target_citation_content": "G.~Kundhi and P.~Rilstone. \\newblock Simplified matrix methods for multivariate Edgeworth expansions. \\newblock \\em Journal of Quantitative Economics, 18(2):293鈥326, June 2020."}}
{"id": "2502.18346v2_gap_1", "arxiv_id": "2502.18346v2", "title": "Testing Thresholds and Spectral Properties of High-Dimensional Random Toroidal Graphs via Edgeworth-Style Expansions", "publication_date": "2025-02-25", "problem_input": {"global_context": {"setup": "The paper considers Random Geometric Graphs (RGGs) on the d-dimensional torus $\\mathbb{T}^d = [0,1]^d$ with the uniform measure. Edges are formed between vertices $u,v$ if their distance $\\Delta(\\{u,v\\}) \\le \\tau$, where the distance is defined via an $L_q$-norm (either finite $q$ or $L_\\infty$) on the torus. The paper focuses on a random vector $\\mathbf{z}$ representing the normalized sum of pairwise distances in a cycle or chain of length $k$, modified by adding small Gaussian noise $\\boldsymbol{\\eta}_i \\sim \\mathcal{N}(0, d^{-2\\eta}\\mathbf{I}_k)$ to ensure integrability of characteristic functions. The analysis relies heavily on cumulants, characteristic functions, and Edgeworth expansions.", "goal": "To approximate the joint density of the random vector $\\mathbf{z}$ (representing geometric statistics of the graph) using Edgeworth expansions, thereby distinguishing RGGs from Erdős-Rényi graphs."}, "local_context": {"anchor_latex": "\\kappa_{(1,1,\\ldots,1)} = \\Expected{\\prod_{j=1}^k \\mathbf{z}(j) }  \\text{ and } \\rho_{(1,1,\\ldots,1)} = \\Expected{\\prod_{j=1}^k \\mathbf{z}_1(j) }", "gap_objective": "A local limit theorem to assert that the density of normalized sums of i.i.d. continuous random variables converges uniformly to the Gaussian density."}}, "ground_truth": {"target_citation_key": "Bhattacharya_Rao_2010", "target_lemma_latex": "\\lim_{n \\rightarrow \\infty} \\sup_{x \\in \\mathbb{R}} |f(x) - \\phi_\\sigma(x)| = 0", "target_citation_content": "R.~N. Bhattacharya and R.~R. Rao. \\newblock \\em Normal Approximation and Asymptotic Expansions. \\newblock Classics in Applied Mathematics. Society for Industrial and Applied Mathematics, Jan. 2010."}}
{"id": "2502.18346v2_gap_2", "arxiv_id": "2502.18346v2", "title": "Testing Thresholds and Spectral Properties of High-Dimensional Random Toroidal Graphs via Edgeworth-Style Expansions", "publication_date": "2025-02-25", "problem_input": {"global_context": {"setup": "The paper considers High-Dimensional Random Geometric Graphs (RGGs) on the $d$-dimensional torus $\\mathbb{T}^d$. Vertices $v \\in [n]$ are assigned i.i.d. uniform positions $\\mathbf{x}_v \\in [0,1]^d$. An edge exists between $u$ and $v$ if their distance $\\Delta(\\{u,v\\}) = \\|\\tbf{x}_u - \\tbf{x}_v\\|_q$ is at most a threshold $\\tau$, chosen to achieve marginal edge probability $p$. The analysis focuses on a random vector $\\mathbf{z}$ representing the normalized $L_q$ distances along a cycle of length $k$, modified by adding small Gaussian noise $\\boldsymbol{\\eta}_i$ to ensure integrability. Specifically, $\\mathbf{z} = \\sum_{i=1}^d \\mathbf{z}_i / \\sqrt{d}$, where each $\\mathbf{z}_i$ corresponds to the contribution of the $i$-th dimension to the distances.", "goal": "Theorem 3.5 (Main Density Approximation): To prove that the joint density $f(\\mathbf{z})$ can be approximated by a function $\\tilde{f}(\\mathbf{z})$ derived from a multivariate Edgeworth expansion, and to bound the error $|f(\\mathbf{z}) - \\tilde{f}(\\mathbf{z})|$."}, "local_context": {"anchor_latex": "K_{\\mathbf{z}}(\\mathbf{t}) = \\sum_{j=1}^\\infty \\frac{1}{j!} \\boldsymbol{\\kappa}_j^\\top(i\\mathbf{t})^{\\otimes j}", "gap_objective": "To provide a finite multivariate Taylor expansion with a remainder term using the Kronecker product notation, which allows for approximate expansions of the cumulant generating function."}}, "ground_truth": {"target_citation_key": "Kundhi_Rilstone_2020", "target_lemma_latex": "f(\\mathbf{x}) = r_J(\\mathbf{x}) + \\sum_{j = 0}^J \\frac{1}{j!} f^{(j)}(\\mathbf{0})^\\top\\mathbf{x}^{\\otimes j} \\quad \\text{where} \\quad r_J(\\mathbf{x}) = \\frac{1}{J!} \\left(f^{(J)}(c\\mathbf{x}) - f^{(J)}(\\mathbf{0})\\right)^\\top\\mathbf{x}^{\\otimes J}", "target_citation_content": "G.~Kundhi and P.~Rilstone. \\newblock Simplified matrix methods for multivariate Edgeworth expansions. \\newblock \\em Journal of Quantitative Economics, 18(2):293鈥326, June 2020."}}
{"id": "2502.18346v2_gap_3", "arxiv_id": "2502.18346v2", "title": "Testing Thresholds and Spectral Properties of High-Dimensional Random Toroidal Graphs via Edgeworth-Style Expansions", "publication_date": "2025-02-25", "problem_input": {"global_context": {"setup": "The paper considers High-Dimensional Random Geometric Graphs (RGGs) on the $d$-dimensional torus $\\mathbb{T}^d$. Vertices $v \\in [n]$ are assigned i.i.d. uniform positions $\\mathbf{x}_v \\in [0,1]^d$. An edge exists between $u$ and $v$ if their distance $\\Delta(\\{u,v\\}) = \\|\\tbf{x}_u - \\tbf{x}_v\\|_q$ is at most a threshold $\\tau$, chosen to achieve marginal edge probability $p$. The analysis focuses on a random vector $\\mathbf{z}$ representing the normalized $L_q$ distances along a cycle of length $k$, modified by adding small Gaussian noise $\\boldsymbol{\\eta}_i$ to ensure integrability. Specifically, $\\mathbf{z} = \\sum_{i=1}^d \\mathbf{z}_i / \\sqrt{d}$, where each $\\mathbf{z}_i$ corresponds to the contribution of the $i$-th dimension to the distances.", "goal": "Theorem 3.5 (Main Density Approximation): To prove that the joint density $f(\\mathbf{z})$ can be approximated by a function $\\tilde{f}(\\mathbf{z})$ derived from a multivariate Edgeworth expansion, and to bound the error $|f(\\mathbf{z}) - \\tilde{f}(\\mathbf{z})|$."}, "local_context": {"anchor_latex": "f_i \\in L^1(\\mathbb{R}^k) \\cap L^2(\\mathbb{R}^k)", "gap_objective": "C_{X_i} \\in L^2(\\mathbb{R}^k)"}}, "ground_truth": {"target_citation_key": "Bhattacharya_Rao_2010", "target_lemma_latex": "f \\in L^2(\\mathbb{R}^k) \\implies \\hat{f} \\in L^2(\\mathbb{R}^k)", "target_citation_content": "R.~N. Bhattacharya and R.~R. Rao. \\newblock \\em Normal Approximation and Asymptotic Expansions. \\newblock Classics in Applied Mathematics. Society for Industrial and Applied Mathematics, Jan. 2010."}}
{"id": "2502.14988v1_gap_3", "arxiv_id": "2502.14988v1", "title": "Partial and Exact Recovery of a Random Hypergraph from its Graph Projection", "publication_date": "2025-02-20", "problem_input": {"global_context": {"setup": "Let $n$ be a positive integer and $d \\geq 3$. Consider a random $d$-uniform hypergraph $\\mathcal{H}$ on the vertex set $[n]$, where each possible hyperedge in $\\binom{[n]}{d}$ is included independently with probability $p$. The probability scales as $p = (c+o_n(1))n^{-d+1+\\delta}$ for constants $c>0$ and $\\delta \\in (-\\infty, d-1)$. The observed data is the projection graph $G = \\text{Proj}(\\mathcal{H})$, where an edge $\\{i,j\\}$ exists in $G$ if and only if $\\{i,j\\} \\subset h$ for some hyperedge $h \\in E(\\mathcal{H})$. $\\mathcal{H}_c$ denotes the hypergraph consisting of all $d$-cliques in $G$.", "goal": "Determine the sharp thresholds for $\\delta$ regarding the Partial Recovery (minimizing the fraction of incorrect hyperedges) and Exact Recovery (recovering the entire hypergraph with high probability) of $\\mathcal{H}$ from $\\text{Proj}(\\mathcal{H})$."}, "local_context": {"anchor_latex": "\\delta <  \\frac{2d-4}{2d-1}\\leq d-1-\\frac{1}{m(h)}", "gap_objective": "Determine the asymptotic probability that a fixed graph $h$ appears as a subgraph in the random hypergraph $\\mathcal{H}$ given the condition on $\\delta$."}}, "ground_truth": {"target_citation_key": "reconstruct", "target_lemma_latex": "\\Pr[K\\subset \\mathcal{H}] = \\begin{cases}\no_n(1) & \\text{if } \\delta < d-1-\\frac{1}{m(K)},\n\\\\ 1-o_n(1) & \\text{if } \\delta > d-1-\\frac{1}{m(K)}, \n\\\\ \\Omega_n(1), & \\text{if } \\delta = d-1-\\frac{1}{m(K)},\n\\end{cases}", "target_citation_content": "Guy Bresler, Chenghao Guo, and Yury Polyanskiy. \\newblock Thresholds for Reconstruction of Random Hypergraphs From Graph Projections. \\newblock In \\emphProceedings of Thirty Seventh Conference on Learning Theory, volume 247 of \\emphProceedings of Machine Learning Research, pages 632--647. PMLR, 2024."}}
{"id": "2403.06731v1_gap_1", "arxiv_id": "2403.06731v1", "title": "On the Approximation of Kernel functions", "publication_date": "2024-03-11", "problem_input": {"global_context": {"setup": "The paper considers a design space $\\mathcal{X}=[0,1]^d$ equipped with a design measure $P$ (often uniform). It focuses on the Gaussian kernel $k(x,y) = e^{-\\sigma\\|x-y\\|_2^2}$ and its associated integral operator $L_k: L^2(\\mathcal{X},P) \\to L^2(\\mathcal{X},P)$. The analysis utilizes Mercer's decomposition $k(x,y) = \\sum \\mu_\\ell \\varphi_\\ell(x)\\varphi_\\ell(y)$ and a constructed 'minimal moment function' $W_m^x$ to approximate the point evaluation functional $k_x$.", "goal": "To establish a polynomial upper bound on the sup-norm of the eigenfunctions $\\varphi_\\ell$ of the Gaussian kernel (Theorem 3.8) and use this to derive improved interpolation inequalities (Theorem 4.3) and Nyström method bounds."}, "local_context": {"anchor_latex": "x_{1},\\dots,x_{\\ell} \\sim \\mathcal{U}[0,1] \\text{ are independent random variables and } K=(k(x_{i},x_{j}))_{i,j=1}^{\\ell} \\text{ is the Gramian matrix}", "gap_objective": "Establish a lower bound for the $\\ell$-th eigenvalue $\\mu_{\\ell}$ of the integral operator by relating it to the expected smallest eigenvalue of the finite Gram matrix $K$"}}, "ground_truth": {"target_citation_key": "Shawe-Taylor2002", "target_lemma_latex": "\\mu_{\\ell} \\ge \\frac{1}{\\ell} \\E \\lambda_{\\min}(K)", "target_citation_content": "J.~Shawe-Taylor, C.~Williams, N.~Cristianini, and J.~Kandola. \\newblock \\emphOn the Eigenspectrum of the Gram Matrix and Its Relationship to the Operator Eigenspectrum, pages 12--12. \\newblock Springer Berlin Heidelberg, 2002. \\newblock ISBN 9783540361824. \\newblock \\doi10.1007/3-540-36182-0\\_3."}}
{"id": "2403.06731v1_gap_2", "arxiv_id": "2403.06731v1", "title": "On the Approximation of Kernel functions", "publication_date": "2024-03-11", "problem_input": {"global_context": {"setup": "The paper considers a design space $\\mathcal{X}=[0,1]^d$ equipped with a design measure $P$ (often uniform). It focuses on the Gaussian kernel $k(x,y) = e^{-\\sigma\\|x-y\\|_2^2}$ and its associated integral operator $L_k: L^2(\\mathcal{X},P) \\to L^2(\\mathcal{X},P)$. The analysis utilizes Mercer's decomposition $k(x,y) = \\sum \\mu_\\ell \\varphi_\\ell(x)\\varphi_\\ell(y)$ and a constructed 'minimal moment function' $W_m^x$ to approximate the point evaluation functional $k_x$.", "goal": "To establish a polynomial upper bound on the sup-norm of the eigenfunctions $\\varphi_\\ell$ of the Gaussian kernel (Theorem 3.8) and use this to derive improved interpolation inequalities (Theorem 4.3) and Nyström method bounds."}, "local_context": {"anchor_latex": "\\mu_{\\ell}\\ge\\frac{1}{\\ell}\\E\\lambda_{\\min}(K)", "gap_objective": "A lower bound on the minimum eigenvalue of the Gaussian Gram matrix $K$ in terms of the minimum separation distance $M$ of the points, to allow for the calculation of the expectation."}}, "ground_truth": {"target_citation_key": "Diederichs2019", "target_lemma_latex": "\\lambda_{\\min}(K) \\ge \\tilde{C}(\\sigma) M^{-1} e^{-\\frac{4\\pi^{2}}{16 M^{2}\\sigma}}", "target_citation_content": "B.~Diederichs and A.~Iske. \\newblock Improved estimates for condition numbers of radial basis function interpolation matrices. \\newblock \\emphJournal of Approximation Theory, 238:\\penalty0 38--51, Feb. 2019. \\newblock ISSN 0021-9045. \\newblock \\doi10.1016/j.jat.2017.10.004."}}
{"id": "2403.06731v1_gap_3", "arxiv_id": "2403.06731v1", "title": "On the Approximation of Kernel functions", "publication_date": "2024-03-11", "problem_input": {"global_context": {"setup": "The paper considers a design space $\\mathcal{X}=[0,1]^d$ equipped with a design measure $P$ (often uniform). It focuses on the Gaussian kernel $k(x,y) = e^{-\\sigma\\|x-y\\|_2^2}$ and its associated integral operator $L_k: L^2(\\mathcal{X},P) \\to L^2(\\mathcal{X},P)$. The analysis utilizes Mercer's decomposition $k(x,y) = \\sum \\mu_\\ell \\varphi_\\ell(x)\\varphi_\\ell(y)$ and a constructed 'minimal moment function' $W_m^x$ to approximate the point evaluation functional $k_x$.", "goal": "To establish a polynomial upper bound on the sup-norm of the eigenfunctions $\\varphi_\\ell$ of the Gaussian kernel (Theorem 3.8) and use this to derive improved interpolation inequalities (Theorem 4.3) and Nyström method bounds."}, "local_context": {"anchor_latex": "Let $(\\Omega,\\mathcal{B},P)$ be a probability space, $H$ a separable Hilbert space, and $\\xi\\colon\\Omega\\to\\mathcal{L}_{2}(H)$ be a random variable with values in the set of self-adjoint Hilbert-Schmidt operators. Furthermore, let the operator norm be uniformly bounded, i.e., $\\left\\Vert \\xi\\right\\Vert _{H\\to H}\\le B$ $P$-a.s. and $V$ be a self-adjoint positive semi-definite trace class operator with $\\E_{P}\\xi^{2}\\preccurlyeq V$. Define $g(V)\\coloneqq\\ln(2e\\Tr(V)\\left\\Vert V\\right\\Vert _{H\\to H}^{-1})$, $\\tau\\ge1$, and $n\\ge1$.", "gap_objective": "Establish a concentration inequality for the operator norm of the difference between the empirical mean $\\frac{1}{n}\\sum_{i=1}^{n}\\xi_{i}$ and the expectation $\\E_{P}\\xi$."}}, "ground_truth": {"target_citation_key": "steinwartfischer2020", "target_lemma_latex": "P^{n}\\bigg(\\left\\Vert \\frac{1}{n}\\sum_{i=1}^{n}\\xi_{i}-\\E_{P}\\xi\\right\\Vert _{H\\to H}\\ge\\frac{4\\tau\\,B\\cdot g(V)}{3n}+\\sqrt{\\frac{2\\tau\\left\\Vert V\\right\\Vert _{H\\to H}g(V)}{n}}\\bigg)\\le2e^{-\\tau}", "target_citation_content": "S.~Fischer and I.~Steinwart. \\newblock Sobolev norm learning rates for regularized least-squares algorithms. \\newblock \\emphJ. Mach. Learn. Res., 21\\penalty0 (1), jan 2020. \\newblock ISSN 1532-4435."}}
{"id": "2403.06731v1_gap_4", "arxiv_id": "2403.06731v1", "title": "On the Approximation of Kernel functions", "publication_date": "2024-03-11", "problem_input": {"global_context": {"setup": "The paper considers a design space $\\mathcal{X}=[0,1]^d$ equipped with a design measure $P$ (often uniform). It focuses on the Gaussian kernel $k(x,y) = e^{-\\sigma\\|x-y\\|_2^2}$ and its associated integral operator $L_k: L^2(\\mathcal{X},P) \\to L^2(\\mathcal{X},P)$. The analysis utilizes Mercer's decomposition $k(x,y) = \\sum \\mu_\\ell \\varphi_\\ell(x)\\varphi_\\ell(y)$ and a constructed 'minimal moment function' $W_m^x$ to approximate the point evaluation functional $k_x$.", "goal": "To establish a polynomial upper bound on the sup-norm of the eigenfunctions $\\varphi_\\ell$ of the Gaussian kernel (Theorem 3.8) and use this to derive improved interpolation inequalities (Theorem 4.3) and Nyström method bounds."}, "local_context": {"anchor_latex": "L_{k}^{D}=\\frac{1}{n}\\sum_{i=1}^{n}T_{x_{i}} \\quad \\text{with} \\quad (T_{z}f)(y)=f(z)k(y,z)", "gap_objective": "Establish a concentration inequality for the operator difference $(L_{k}+\\lambda)^{-1}(L_{k}-L_{k}^{D})$ in the RKHS norm."}}, "ground_truth": {"target_citation_key": "dommel2024bound", "target_lemma_latex": "P\\left(\\left\\Vert \\left(L_{k}+\\lambda\\right)^{-1}(L_{k}-L_{k}^{D})\\right\\Vert _{\\mathcal{H}_{k}\\to\\mathcal{H}_{k}}\\le\\frac{4\\tau\\mathcal{N}_{\\infty}(\\lambda)g(\\lambda)}{3n}+\\sqrt{\\frac{2\\tau\\mathcal{N}_{\\infty}(\\lambda)g(\\lambda)}{n}}\\right)\\ge1-2e^{-\\tau}", "target_citation_content": "P.~Dommel. \\newblock A bound on the maximal marginal degrees of freedom, 2024. \\newblock URL \\urlhttps://arxiv.org/abs/2402.12885."}}
{"id": "2403.06731v1_gap_5", "arxiv_id": "2403.06731v1", "title": "On the Approximation of Kernel functions", "publication_date": "2024-03-11", "problem_input": {"global_context": {"setup": "The paper considers a design space $\\mathcal{X}=[0,1]^d$ equipped with a design measure $P$ (often uniform). It focuses on the Gaussian kernel $k(x,y) = e^{-\\sigma\\|x-y\\|_2^2}$ and its associated integral operator $L_k: L^2(\\mathcal{X},P) \\to L^2(\\mathcal{X},P)$. The analysis utilizes Mercer's decomposition $k(x,y) = \\sum \\mu_\\ell \\varphi_\\ell(x)\\varphi_\\ell(y)$ and a constructed 'minimal moment function' $W_m^x$ to approximate the point evaluation functional $k_x$.", "goal": "To establish a polynomial upper bound on the sup-norm of the eigenfunctions $\\varphi_\\ell$ of the Gaussian kernel (Theorem 3.8) and use this to derive improved interpolation inequalities (Theorem 4.3) and Nyström method bounds."}, "local_context": {"anchor_latex": "\\mathcal{N}_{\\infty}(\\lambda) \\le 9c_{p}\\left(3c_{\\sigma}s(\\lambda)+2\\right)^{2d}+1", "gap_objective": "Determine the number of supporting points $m$ required for the Nyström approximation $\\hat{f}_{\\lambda,m}$ to achieve the statistical optimality bound $\\mathcal{E}(\\hat{f}_{\\lambda,m})-\\mathcal{E}(f_{\\mathcal{H}})\\le q^{2}n^{\\frac{2\\nu+1}{2nu+\\gamma+1}}$."}}, "ground_truth": {"target_citation_key": "NIPS2015_03e0704b", "target_lemma_latex": "m \\ge \\left( 67 \\lor 5 \\mathcal{N}_{\\infty}(\\lambda) \\right) \\ln \\lambda^{-1}", "target_citation_content": "A.~Rudi, R.~Camoriano, and L.~Rosasco. \\newblock Less is more: Nystr\\\"om computational regularization. \\newblock In C.~Cortes, N.~Lawrence, D.~Lee, M.~Sugiyama, and R.~Garnett, editors, \\emphAdvances in Neural Information Processing Systems, volume~28. Curran Associates, Inc., 2015. \\newblock URL \\urlhttps://proceedings.neurips.cc/paper_files/paper/2015/file/03e0704b5690a2dee1861dc3ad3316c9-Paper.pdf."}}
{"id": "2501.14928v1_gap_2", "arxiv_id": "2501.14928v1", "title": "Decision Making in Changing Environments: Robustness, Query-Based Learning, and Differential Privacy", "publication_date": "2025-01-24", "problem_input": {"global_context": {"setup": "The paper studies interactive decision making with structured observations (DMSO) under local differential privacy (LDP) constraints. The setup involves a model class $\\mathcal{M} \\subseteq (\\Pi \\to \\Delta(\\mathcal{Z}))$, where $\\Pi$ is a decision space and $\\mathcal{Z}$ is a latent observation space. A learner selects a decision $\\pi^t$, and observes $o^t$ through a privacy mechanism applied to $z^t \\sim M(\\pi^t)$. The performance is measured by the cumulative regret defined via a value function $V_M(\\pi)$ or PAC risk via a loss function $L(M, \\pi)$. Complexity measures include the Decision-Estimation Coefficient (DEC) and the Disagreement Coefficient.", "goal": "To derive optimal minimax sample complexity and regret bounds for LDP decision making, characterized by the private DEC and Disagreement Coefficient."}, "local_context": {"anchor_latex": "F_{p,q}(\\wf, \\mu)\\defeq \\EE_{(M,\\psi)\\sim \\mu} \\Gamma_{\\qd,\\gamma}(p,q,\\wf;M,\\psi), \\quad \\text{where } \\DI \\text{ is compact and convex, } \\wF_A \\text{ is convex, and } F_{p,q} \\text{ is bilinear and concave/continuous in } \\mu.", "gap_objective": "Interchange the infimum over weighting functions $\\wf$ and the maximum over distributions $\\mu$."}}, "ground_truth": {"target_citation_key": "fan1953minimax", "target_lemma_latex": "\\inf_{\\wf\\in\\wF_A} \\max_{\\mu\\in\\DI} F_{p,q}(\\wf,\\mu) = \\max_{\\mu\\in\\DI}  \\inf_{\\wf\\in\\wF_A} F_{p,q}(\\wf,\\mu)", "target_citation_content": "K.~Fan. \\newblock Minimax theorems. \\newblock \\emphProceedings of the National Academy of Sciences, 39\\penalty0 (1):\\penalty0 42--47, 1953."}}
{"id": "2506.08405v1_gap_0", "arxiv_id": "2506.08405v1", "title": "Optimal Graph Reconstruction by Counting Connected Components in Induced Subgraphs", "publication_date": "2025-06-10", "problem_input": {"global_context": {"setup": "Let $G=(V, E)$ be an unknown unweighted, undirected graph with $n$ vertices and at most $m$ edges. We have access to an oracle $\\CC_G(S)$ which, for any subset of vertices $S \\subseteq V$, returns the number of connected components in the induced subgraph $G[S]$. We define $\\density_G(S)$ as the number of edges in $G[S]$.", "goal": "Theorem: There exists an adaptive, randomized algorithm that reconstructs the edge set $E$ of $G$ using $O(\\frac{m \\log n}{\\log m})$ $\\CC$-queries in expectation."}, "local_context": {"anchor_latex": "one $\\CC$ query on $G$ suffices to simulate one $\\density$ query on $G_u$", "gap_objective": "Reconstruct the graph $G_u$ (and thus the forest $G$) with the optimal query complexity by utilizing the simulation."}}, "ground_truth": {"target_citation_key": "DBLP:conf/soda/Mazzawi10", "target_lemma_latex": "There is a polynomial-time algorithm that, given $\\density$-query access to an underlying (unknown) $n$-node graph $G = (V, E)$, the vertex set $V$ and the number of edges $m$, reconstructs the graph $G$ using $\\frac{Cm \\log n}{\\log m}$ queries in the worst case for some universal constant $C$.", "target_citation_content": "Hanna Mazzawi. \\newblock Optimally reconstructing weighted graphs using queries. \\newblock In \\em Proceedings of the Twenty-First Annual ACM-SIAM Symposium on Discrete Algorithms (SODA 2010), pages 608--615, 2010."}}
{"id": "2506.08405v1_gap_1", "arxiv_id": "2506.08405v1", "title": "Optimal Graph Reconstruction by Counting Connected Components in Induced Subgraphs", "publication_date": "2025-06-10", "problem_input": {"global_context": {"setup": "Let $G=(V, E)$ be an unknown unweighted, undirected graph with $n$ vertices and at most $m$ edges. We have access to an oracle $\\CC_G(S)$ which, for any subset of vertices $S \\subseteq V$, returns the number of connected components in the induced subgraph $G[S]$. We define $\\density_G(S)$ as the number of edges in $G[S]$.", "goal": "Theorem: There exists an adaptive, randomized algorithm that reconstructs the edge set $E$ of $G$ using $O(\\frac{m \\log n}{\\log m})$ $\\CC$-queries in expectation."}, "local_context": {"anchor_latex": "\\CC(S \\cup \\{u\\}) - \\CC(S) = \\boldsymbol{1}(\\deg(u,S) = 0) = \\mathsf{OR}_S(x^u)", "gap_objective": "To recover the support of the vector $x^u$ (representing the neighborhood of $u$) using the simulated $\\mathsf{OR}$ queries in a non-adaptive manner with $O(d \\log n)$ complexity."}}, "ground_truth": {"target_citation_key": "BLMS24", "target_lemma_latex": "Let $v \\in \\{0,1\\}^n$ and let \\textsf{supp}(v) = \\{j \\in [n] \\colon x_j = 1\\}. Given $n, d, \\alpha$, there is a non-adaptive algorithm that makes $O(d \\log (n/\\alpha))$ $\\mathsf{OR}$ queries and if $|\\textsf{supp}(v)| \\leq d$, returns \\textsf{supp}(v) with probability $1-\\alpha$, and otherwise certifies that $|\\textsf{supp}(v)| > d$ with probability $1$.", "target_citation_content": "Hadley Black, Euiwoong Lee, Arya Mazumdar, and Barna Saha. \\newblock Clustering with non-adaptive subset queries. \\newblock In \\em Neural Information Processing Systems (NeurIPS), 2024."}}
{"id": "2503.02802v2_gap_0", "arxiv_id": "2503.02802v2", "title": "Computational Equivalence of Spiked Covariance and Spiked Wigner Models via Gram-Schmidt Perturbation", "publication_date": "2025-03-04", "problem_input": {"global_context": {"setup": "The paper considers the Spiked Covariance Model (SC) and the Spiked Wigner Model (SW). For SC, we observe $n$ samples $Z_1, \\dots, Z_n \\in \\mathbb{R}^d$ forming a matrix $Z \\in \\mathbb{R}^{n \\times d}$ given by $Z = X + \\sqrt{\\theta} g u^\\top$, where $X$ has i.i.d. $N(0,1)$ entries, $g \\sim N(0, I_n)$, and $u$ is a $k$-sparse unit vector in $\\mathbb{R}^d$. For SW, we observe a symmetric matrix $Y = \\lambda u u^\\top + W \\in \\mathbb{R}^{d \\times d}$, where $W$ is drawn from the Gaussian Orthogonal Ensemble (GOE) and $u$ is a $k$-sparse unit vector. The parameters are scaled such that $k=d^\\alpha, n=d^\\gamma, \\theta=d^\\beta$ (for SC) and $\\lambda$ corresponds to signal-to-noise ratio.", "goal": "To establish average-case reductions from the Spiked Covariance model to the Spiked Wigner model (specifically mapping SC instances to SW instances) to prove that their computational hardness thresholds are equivalent."}, "local_context": {"anchor_latex": "Y = \\frac1{\\sqrt{n}}(\\Xbar \\up 1)^\\top \\Xbar \\up 2 +  \\frac1{\\sqrt{n}}\\big[ \\theta\\|g\\|^2 u u^\\top + (X_0\\up 1)(X_0\\up 2)^\\top  + \\|g\\|(X_0\\up 1) \\tsq u^\\top + \\|g\\|\\tsq u (X_0\\up 2)^\\top\\big]", "gap_objective": "Justify the approximation of the term $\\frac1{\\sqrt{n}}(\\Xbar \\up 1)^\\top \\Xbar \\up 2$ by a standard Gaussian matrix $G$ in total variation distance given $n \\gg d^2$."}}, "ground_truth": {"target_citation_key": "brennan2021finetti", "target_lemma_latex": "Let X,Y\\in \\R^{n\\times d} and G\\in \\R^{d\\times d} have i.i.d. \\N(0,1) entries. If n\\gg d^2, then \\tv(n^{-1/2}X^\\top Y, G) \\to 0, as n\\to \\infty", "target_citation_content": "Matthew Brennan, Guy Bresler, and Brice Huang. \\newblock De finetti-style results for wishart matrices: Combinatorial structure and phase transitions. \\newblock \\em arXiv preprint arXiv:2103.14011, 2021."}}
{"id": "2501.09178v1_gap_0", "arxiv_id": "2501.09178v1", "title": "Enhancing Graph Representation Learning with Localized Topological Features", "publication_date": "2025-01-15", "problem_input": {"global_context": {"setup": "The paper considers finite simple graphs $G = (V, E)$. For a node $u$, $G_u^k$ denotes the $k$-hop neighborhood subgraph (vicinity graph). The framework utilizes Extended Persistent Homology (EPH) on $G_u^k$ using the shortest path distance from $u$ as the filter function to generate an Extended Persistence Diagram (EPD), denoted as $D_u^k$. The expressive power is analyzed in comparison to the Weisfeiler-Lehman (WL) graph isomorphism tests ($k$-WL).", "goal": "Theorem 1: To establish the expressive power of Graph Neural Networks enhanced with the localized topological features $D_u^k$, specifically showing they are more expressive than 2-WL, not less expressive than 3-WL, and capable of distinguishing most pairs of non-isomorphic regular graphs."}, "local_context": {"anchor_latex": "\\text{The EPD } D_u^k \\text{ induced by this shortest path distance function encodes a rich family of structural information of } G^k_u.", "gap_objective": "\\text{Show that specific local structural invariants, such as the number of triangles incident to } u \\text{ and counts of nodes/edges at each level, are recoverable from } D_u^k."}}, "ground_truth": {"target_citation_key": "TW19", "target_lemma_latex": "\\text{The 1st Betti number of the layer-1 subgraph (neighborhood graph) is determined by the persistence diagram of the distance function, which allows the recovery of the number of edges in the neighborhood and thus the number of triangles incident to } u.", "target_citation_content": "Minghao Tian and Yusu Wang. \\newblock A limit theorem for the $1$st Betti number of layer-$1$ subgraphs in random graphs, 2019. \\newblock arXiv preprint. Available at arXiv:1911.00585."}}
{"id": "2506.16651v1_gap_2", "arxiv_id": "2506.16651v1", "title": "A Distributional-Lifting Theorem for PAC Learning", "publication_date": "2025-06-19", "problem_input": {"global_context": {"setup": "The paper considers a concept class $\\mathcal{C}$ over inputs $\\{\\pm 1\\}^n$ and a family of distributions $\\mathcal{D}$ that is closed under restrictions. A base learner $A$ is assumed to exist which learns $\\mathcal{C}$ under any distribution $D \\in \\mathcal{D}$ with sample complexity $m$ and time $t$. The target distribution $D^\\star$ is assumed to admit a depth-$d$ decision tree decomposition (or a subcube partition) into distributions belonging to $\\mathcal{D}$.", "goal": "To construct a learning algorithm that learns $\\mathcal{C}$ under the distribution $D^\\star$ with expected error $\\epsilon$, using only random examples (without a conditional sampling oracle), with time complexity $n^{O(d)}$ and sample complexity depending on $d$."}, "local_context": {"anchor_latex": "\\text{the indicators } \\Ind[x \\in \\bS] \\text{ for each } x \\in \\bits^n \\text{ are drawn uniformly without replacement from a population containing } \\tfrac{2^n}{2} \\text{ many } 1\\text{s and } \\tfrac{2^n}{2} \\text{ many } 0\\text{s}", "gap_objective": "Bound the probability that the random variable \\textbf{count}(\\ell) deviates from its mean by at least \\frac{1}{6} \\cdot 2^{n-\\depth(\\ell)}."}}, "ground_truth": {"target_citation_key": "Hoe63", "target_lemma_latex": "\\Pr[\\abs*{\\bX - \\mu} \\geq n\\eps] \\leq 2e^{-2\\eps^2n} \\quad\\quad\\text{where}\\quad\\mu \\coloneqq \\Ex[\\bX]", "target_citation_content": "Wassily Hoeffding. \\newblock Probability inequalities for sums of bounded random variables. \\newblock \\em Journal of the American Statistical Association, 58(301):13--30, 1963."}}
{"id": "2506.16651v1_gap_3", "arxiv_id": "2506.16651v1", "title": "A Distributional-Lifting Theorem for PAC Learning", "publication_date": "2025-06-19", "problem_input": {"global_context": {"setup": "The paper considers a concept class $\\mathcal{C}$ over inputs $\\{\\pm 1\\}^n$ and a family of distributions $\\mathcal{D}$ that is closed under restrictions. A base learner $A$ is assumed to exist which learns $\\mathcal{C}$ under any distribution $D \\in \\mathcal{D}$ with sample complexity $m$ and time $t$. The target distribution $D^\\star$ is assumed to admit a depth-$d$ decision tree decomposition (or a subcube partition) into distributions belonging to $\\mathcal{D}$.", "goal": "To construct a learning algorithm that learns $\\mathcal{C}$ under the distribution $D^\\star$ with expected error $\\epsilon$, using only random examples (without a conditional sampling oracle), with time complexity $n^{O(d)}$ and sample complexity depending on $d$."}, "local_context": {"anchor_latex": "\\Ex\\bracket*{\\sup_{g \\in \\mcG}\\abs*{\\error(g, D^{\\star}_f) - \\error(g, \\bS_{\\test}) }} \\leq \\sqrt{\\frac{\\ln (2|\\mcG|)}{2m}}", "gap_objective": "To prove the bound on the expected supremum of the deviation between true and empirical errors by utilizing the maximal inequality for sub-Gaussian random variables."}}, "ground_truth": {"target_citation_key": "Ver18Book", "target_lemma_latex": "\\Ex\\bracket*{\\max_{i \\in [n]} \\abs*{\\bz_i}} \\leq \\sqrt{2 \\sigma^2 \\ln(2n) }", "target_citation_content": "Roman Vershynin. \\newblock \\em High-dimensional probability: An introduction with applications in data science, volume~47. \\newblock Cambridge university press, 2018."}}
{"id": "2504.08377v4_gap_0", "arxiv_id": "2504.08377v4", "title": "Proofs as Explanations: Short Certificates for Reliable Predictions", "publication_date": "2025-04-11", "problem_input": {"global_context": {"setup": "The paper considers a hypothesis class $\\mathcal{H}$ on an input space $\\mathcal{X}$ with labels $\\{-1, 1\\}$. A dataset $S$ is $b$-robustly realizable by $\\mathcal{H}$ if there exists $h \\in \\mathcal{H}$ making at most $b$ mistakes on $S$. A subset $S' \\subseteq S$ is a $b$-robust certificate for a test point $(x, y)$ if every $h \\in \\mathcal{H}$ that makes at most $b$ mistakes on $S'$ satisfies $h(x)=y$. The $b$-robust hollow star number $s_b$ characterizes the worst-case size of such certificates. The certificate coefficient $\\epsilon_x$ measures the probability mass of hypotheses disagreeing with the target on $x$.", "goal": "Theorem 3.6 states that the $b$-robust hollow star number exactly characterizes the minimal certificate size. Theorem 4.2 provides sample complexity bounds for certification in terms of the certificate coefficient $\\epsilon_x$ and VC dimension $d$."}, "local_context": {"anchor_latex": "\\text{For } d\\text{-dimensional halfspaces, the problem of certifying } b\\text{-robust agreement reduces to a geometric tolerance problem via the reasoning in Example 3.1 (relating agreement to conic hull containment).}", "gap_objective": "\\text{Bound the size of the certificate (subset of points) required to preserve this tolerance containment property using a known geometric theorem.}"}}, "ground_truth": {"target_citation_key": "montejano2011tolerance", "target_lemma_latex": "\\text{Tolerance Carath\\'eodory theorem (Theorem 4.1 in [montejano2011tolerance], Theorem 2 in [TUZA198984])}", "target_citation_content": "Luis Montejano and Deborah Oliveros. \\newblock Tolerance in helly-type theorems. \\newblock \\em Discrete \\& Computational Geometry, 45(2):348--357, 2011."}}
{"id": "2504.08377v4_gap_1", "arxiv_id": "2504.08377v4", "title": "Proofs as Explanations: Short Certificates for Reliable Predictions", "publication_date": "2025-04-11", "problem_input": {"global_context": {"setup": "The paper considers a hypothesis class $\\mathcal{H}$ on an input space $\\mathcal{X}$ with labels $\\{-1, 1\\}$. A dataset $S$ is $b$-robustly realizable by $\\mathcal{H}$ if there exists $h \\in \\mathcal{H}$ making at most $b$ mistakes on $S$. A subset $S' \\subseteq S$ is a $b$-robust certificate for a test point $(x, y)$ if every $h \\in \\mathcal{H}$ that makes at most $b$ mistakes on $S'$ satisfies $h(x)=y$. The $b$-robust hollow star number $s_b$ characterizes the worst-case size of such certificates. The certificate coefficient $\\epsilon_x$ measures the probability mass of hypotheses disagreeing with the target on $x$.", "goal": "Theorem 3.6 states that the $b$-robust hollow star number exactly characterizes the minimal certificate size. Theorem 4.2 provides sample complexity bounds for certification in terms of the certificate coefficient $\\epsilon_x$ and VC dimension $d$."}, "local_context": {"anchor_latex": "\\text{For } d\\text{-dimensional halfspaces, a test point } x \\text{ is in the } b\\text{-robust agreement region of } S \\text{ if } x \\in \\bigcap_{Z \\subseteq S, |Z| \\le b} \\operatorname{cone}(S \\setminus Z).", "gap_objective": "Find an upper bound on the size of a subset $S' \\subseteq S$ such that the robust membership property is preserved, i.e., $x \\in \\bigcap_{Z \\subseteq S', |Z| \\le b} \\operatorname{cone}(S' \\setminus Z)$."}}, "ground_truth": {"target_citation_key": "TUZA198984", "target_lemma_latex": "\\text{Theorem 2 in [TUZA198984] (Tolerance Carath\\'eodory Theorem): If } x \\in \\bigcap_{Z \\subset S, |Z| \\le b} \\operatorname{conv}(S \\setminus Z), \\text{ then there exists } S' \\subseteq S \\text{ with } |S'| \\le N(d, b) \\text{ such that } x \\in \\bigcap_{Z \\subset S', |Z| \\le b} \\operatorname{conv}(S' \\setminus Z).", "target_citation_content": "Zsolt Tuza. \\newblock Minimum number of elements representing a set system of given rank. \\newblock \\em Journal of Combinatorial Theory, Series A, 52(1):84--89, 1989."}}
{"id": "2504.08377v4_gap_2", "arxiv_id": "2504.08377v4", "title": "Proofs as Explanations: Short Certificates for Reliable Predictions", "publication_date": "2025-04-11", "problem_input": {"global_context": {"setup": "The paper considers a hypothesis class $\\mathcal{H}$ on an input space $\\mathcal{X}$ with labels $\\{-1, 1\\}$. A dataset $S$ is $b$-robustly realizable by $\\mathcal{H}$ if there exists $h \\in \\mathcal{H}$ making at most $b$ mistakes on $S$. A subset $S' \\subseteq S$ is a $b$-robust certificate for a test point $(x, y)$ if every $h \\in \\mathcal{H}$ that makes at most $b$ mistakes on $S'$ satisfies $h(x)=y$. The $b$-robust hollow star number $s_b$ characterizes the worst-case size of such certificates. The certificate coefficient $\\epsilon_x$ measures the probability mass of hypotheses disagreeing with the target on $x$.", "goal": "Theorem 3.6 states that the $b$-robust hollow star number exactly characterizes the minimal certificate size. Theorem 4.2 provides sample complexity bounds for certification in terms of the certificate coefficient $\\epsilon_x$ and VC dimension $d$."}, "local_context": {"anchor_latex": "\\text{Consider a uniform distribution } \\mathcal{D} \\text{ on } \\{x_1, \\dots, x_k\\} \\text{ and a sample size } m = \\frac{d}{2\\eps_x}\\log\\left(\\frac{1}{\\eps_x}\\right) = \\frac{k}{2}\\log\\left(\\frac{k}{d}\\right).", "gap_objective": "\\text{Establish a lower bound on the number of unobserved elements (or upper bound on distinct observed elements) to ensure a subset of size } d \\text{ remains unseen with constant probability.}"}}, "ground_truth": {"target_citation_key": "bousquet2020proper", "target_lemma_latex": "\\text{Lemma 19 (Coupon Collector Argument): With probability at least } \\frac{1}{100}, \\text{ the number of distinct elements observed from } k \\text{ items in } m = \\frac{k}{2}\\log\\left(\\frac{k}{d}\\right) \\text{ i.i.d. draws is at most } k-d.", "target_citation_content": "Olivier Bousquet, Steve Hanneke, Shay Moran, and Nikita Zhivotovskiy. \\newblock Proper learning, helly number, and an optimal svm bound. \\newblock In \\em Conference on Learning Theory, pages 582--609. PMLR, 2020."}}
{"id": "2501.05333v3_gap_0", "arxiv_id": "2501.05333v3", "title": "Stability and List-Replicability for Agnostic Learners", "publication_date": "2025-01-09", "problem_input": {"global_context": {"setup": "The paper considers the standard PAC learning setting for binary classification. Let $X$ be a domain and $\\mathcal{H} \\subseteq \\{0,1\\}^X$ be a hypothesis class. A learner receives a sample $S \\sim \\mathcal{D}^n$ from a distribution $\\mathcal{D}$ over $X \\times \\{0,1\\}$. The population loss is $\\mathcal{L}_\\mathcal{D}(h) = \\Pr_{(\\bm{x},\\bm{y})\\sim \\mathcal{D}}[h(\\bm{x}) \\neq \\bm{y}]$. $\\mathcal{H}$ is $\\rho$-global stable if there exists a learner that outputs a specific hypothesis $h$ with probability at least $\\rho(\\epsilon)$. The Littlestone dimension, denoted $\\ldim(\\mathcal{H})$, is the depth of the largest complete mistake tree shattered by $\\mathcal{H}$.", "goal": "To characterize hypothesis classes that are learnable under relaxations of agnostic global stability (specifically excess-error dependent stability), proving they are exactly the classes with finite Littlestone dimension, and to establish the equivalence between stability and list-replicability."}, "local_context": {"anchor_latex": "\\text{the infinite class } \\cH^* \\text{ is agnostically globally stable}", "gap_objective": "Establish that a hypothesis class cannot be both infinite and agnostically globally stable to derive a contradiction."}}, "ground_truth": {"target_citation_key": "chase2023local", "target_lemma_latex": "\\text{A hypothesis class } \\cH \\text{ is agnostically globally stable if and only if } \\cH \\text{ is finite.}", "target_citation_content": "Zachary Chase, Bogdan Chornomaz, Shay Moran, and Amir Yehudayoff, \\emphLocal borsuk-ulam, stability, and replicability, Proceedings of the 56th Annual ACM Symposium on Theory of Computing, 2024, p.~1769鈥1780."}}
{"id": "2501.05333v3_gap_1", "arxiv_id": "2501.05333v3", "title": "Stability and List-Replicability for Agnostic Learners", "publication_date": "2025-01-09", "problem_input": {"global_context": {"setup": "The paper considers the standard PAC learning setting for binary classification. Let $X$ be a domain and $\\mathcal{H} \\subseteq \\{0,1\\}^X$ be a hypothesis class. A learner receives a sample $S \\sim \\mathcal{D}^n$ from a distribution $\\mathcal{D}$ over $X \\times \\{0,1\\}$. The population loss is $\\mathcal{L}_\\mathcal{D}(h) = \\Pr_{(\\bm{x},\\bm{y})\\sim \\mathcal{D}}[h(\\bm{x}) \\neq \\bm{y}]$. $\\mathcal{H}$ is $\\rho$-global stable if there exists a learner that outputs a specific hypothesis $h$ with probability at least $\\rho(\\epsilon)$. The Littlestone dimension, denoted $\\ldim(\\mathcal{H})$, is the depth of the largest complete mistake tree shattered by $\\mathcal{H}$.", "goal": "To characterize hypothesis classes that are learnable under relaxations of agnostic global stability (specifically excess-error dependent stability), proving they are exactly the classes with finite Littlestone dimension, and to establish the equivalence between stability and list-replicability."}, "local_context": {"anchor_latex": "\\text{Shelah proved that any class } \\cH \\text{ with infinite Littlestone dimension also has an infinite threshold dimension.}", "gap_objective": "Effective bounds for the threshold dimension of a hypothesis class in terms of its Littlestone dimension."}}, "ground_truth": {"target_citation_key": "hodges1997shorter", "target_lemma_latex": "\\text{If } \\mathcal{H} \\subseteq \\set{0,1}^X \\text{ has } \\ldim(\\mathcal{H}) = d, \\text{ its threshold dimension is at least } \\lfloor \\log d \\rfloor.", "target_citation_content": "Wilfrid Hodges, \\emphA shorter model theory, Cambridge university press, 1997."}}
{"id": "2501.05333v3_gap_3", "arxiv_id": "2501.05333v3", "title": "Stability and List-Replicability for Agnostic Learners", "publication_date": "2025-01-09", "problem_input": {"global_context": {"setup": "The paper considers the standard PAC learning setting for binary classification. Let $X$ be a domain and $\\mathcal{H} \\subseteq \\{0,1\\}^X$ be a hypothesis class. A learner receives a sample $S \\sim \\mathcal{D}^n$ from a distribution $\\mathcal{D}$ over $X \\times \\{0,1\\}$. The population loss is $\\mathcal{L}_\\mathcal{D}(h) = \\Pr_{(\\bm{x},\\bm{y})\\sim \\mathcal{D}}[h(\\bm{x}) \\neq \\bm{y}]$. $\\mathcal{H}$ is $\\rho$-global stable if there exists a learner that outputs a specific hypothesis $h$ with probability at least $\\rho(\\epsilon)$. The Littlestone dimension, denoted $\\ldim(\\mathcal{H})$, is the depth of the largest complete mistake tree shattered by $\\mathcal{H}$.", "goal": "To characterize hypothesis classes that are learnable under relaxations of agnostic global stability (specifically excess-error dependent stability), proving they are exactly the classes with finite Littlestone dimension, and to establish the equivalence between stability and list-replicability."}, "local_context": {"anchor_latex": "\\ldim(\\cH) \\leq d", "gap_objective": "To assert the existence of a globally stable learning algorithm for the hypothesis class H in the realizable setting."}}, "ground_truth": {"target_citation_key": "BLM20", "target_lemma_latex": "Suppose \\cH \\subseteq \\set{0,1}^X satisfy \\ldim(\\cH) \\leq d. Then there exists a sample complexity n:(0,1) \\to  \\mathbb{N} and a learning rule \\bm{\\cA} such that for every \\epsilon > 0, and every realizable \\cD, there exists a hypothesis h \\in \\cH with \\cL_{\\cD}(h) \\leq \\epsilon\\ \\ \\text{ and }\\ \\ \\Pr_{\\bm{S} \\sim \\cD^n } [\\bm{\\cA}(\\bm{S}) = h] \\geq \\frac{1}{(d+1)2^{2^d + 1}}", "target_citation_content": "Mark Bun, Roi Livni, and Shay Moran, \\emphAn equivalence between private classification and online prediction, 2020 IEEE 61st Annual Symposium on Foundations of Computer Science (FOCS), 2020, pp.~389--402."}}
{"id": "2406.04071v2_gap_0", "arxiv_id": "2406.04071v2", "title": "Dynamic angular synchronization under smoothness constraints", "publication_date": "2024-06-06", "problem_input": {"global_context": {"setup": "The paper considers the problem of recovering a sequence of smooth ground truth vectors $g^*(1), \\dots, g^*(T) \\in \\mathbb{C}^n$ (where each entry has unit modulus) from noisy pairwise measurements. The stacked ground truth matrix is denoted $G^*$. Under the Additive Gaussian Noise (AGN) model, the observation matrix $A \\in \\mathbb{C}^{nT \\times n}$ is given by $A = (G^* - \\mathbf{1}_T \\otimes I_n) + \\sigma W$, where $\\mathbf{1}_T$ is the all-ones vector, $I_n$ is the identity matrix, and $W$ is a Hermitian noise matrix with complex Gaussian entries. The smoothness of $G^*$ is quantified by a parameter $S_T$ related to the quadratic variation of the signal on a path graph. The proposed estimator $\\hat{G}$ is obtained via matrix denoising: $\\hat{G} = \\mathcal{P}_{\\tau,n} A$, where $\\mathcal{P}_{\\tau,n}$ projects the columns of $A$ onto the subspace spanned by the first $\\tau$ eigenvectors of the path graph Laplacian.", "goal": "Theorem 3.3 establishes a high-probability non-asymptotic bound on the Frobenius norm error $\\|\\hat{G} - \\Gshift^*\\|_F^2$ (where $\\Gshift^*$ is the shifted ground truth), providing an explicit rate depending on the dimension $n$, time horizon $T$, noise level $\\sigma$, smoothness $S_T$, and the optimal frequency cutoff $\\tau^*$."}, "local_context": {"anchor_latex": "\\sum^n_{j=1}\\|\\projperp \\Gshift^*_{:,j} \\|_2^2\\leq \\frac{5nS_T}{\\lambda_{T-\\tau}}", "gap_objective": "Explicit expression for the eigenvalues of the Laplacian of the path graph"}}, "ground_truth": {"target_citation_key": "brouwer12", "target_lemma_latex": "\\lambda_{T-\\tau}=4\\sin^2{(\\frac{\\tau\\pi}{2T})}", "target_citation_content": "A.E. Brouwer and W.H. Haemers. \\newblock \\em Spectra of Graphs. \\newblock New York, NY, 2012."}}
{"id": "2406.04071v2_gap_1", "arxiv_id": "2406.04071v2", "title": "Dynamic angular synchronization under smoothness constraints", "publication_date": "2024-06-06", "problem_input": {"global_context": {"setup": "The paper considers the problem of recovering a sequence of smooth ground truth vectors $g^*(1), \\dots, g^*(T) \\in \\mathbb{C}^n$ (where each entry has unit modulus) from noisy pairwise measurements. The stacked ground truth matrix is denoted $G^*$. Under the Additive Gaussian Noise (AGN) model, the observation matrix $A \\in \\mathbb{C}^{nT \\times n}$ is given by $A = (G^* - \\mathbf{1}_T \\otimes I_n) + \\sigma W$, where $\\mathbf{1}_T$ is the all-ones vector, $I_n$ is the identity matrix, and $W$ is a Hermitian noise matrix with complex Gaussian entries. The smoothness of $G^*$ is quantified by a parameter $S_T$ related to the quadratic variation of the signal on a path graph. The proposed estimator $\\hat{G}$ is obtained via matrix denoising: $\\hat{G} = \\mathcal{P}_{\\tau,n} A$, where $\\mathcal{P}_{\\tau,n}$ projects the columns of $A$ onto the subspace spanned by the first $\\tau$ eigenvectors of the path graph Laplacian.", "goal": "Theorem 3.3 establishes a high-probability non-asymptotic bound on the Frobenius norm error $\\|\\hat{G} - \\Gshift^*\\|_F^2$ (where $\\Gshift^*$ is the shifted ground truth), providing an explicit rate depending on the dimension $n$, time horizon $T$, noise level $\\sigma$, smoothness $S_T$, and the optimal frequency cutoff $\\tau^*$."}, "local_context": {"anchor_latex": "\\calV_1 = \\conj{W'_1}(I_{2n}\\otimes\\projtaun)W'_1 \\text{ where } W'_1 \\text{ has independent entries drawn from } \\calN(0,1/2) \\text{ or } 0", "gap_objective": "Obtain a concentration bound for the quadratic form $\\calV_1$ around its expectation"}}, "ground_truth": {"target_citation_key": "rudelson_vershynin", "target_lemma_latex": "\\prob(|X^T A X - \\expec[X^T A X]| > t) \\leq 2 \\exp \\left( -c \\min \\left( \\frac{t^2}{K^4 \\|A\\|_F^2}, \\frac{t}{K^2 \\|A\\|_{op}} \\right) \\right)", "target_citation_content": "Mark Rudelson and Roman Vershynin. \\newblock Hanson-Wright inequality and sub-gaussian concentration. \\newblock \\em Electronic Communications in Probability, 18:1 -- 9, 2013."}}
{"id": "2406.04071v2_gap_2", "arxiv_id": "2406.04071v2", "title": "Dynamic angular synchronization under smoothness constraints", "publication_date": "2024-06-06", "problem_input": {"global_context": {"setup": "The paper considers the problem of recovering a sequence of smooth ground truth vectors $g^*(1), \\dots, g^*(T) \\in \\mathbb{C}^n$ (where each entry has unit modulus) from noisy pairwise measurements. The stacked ground truth matrix is denoted $G^*$. Under the Additive Gaussian Noise (AGN) model, the observation matrix $A \\in \\mathbb{C}^{nT \\times n}$ is given by $A = (G^* - \\mathbf{1}_T \\otimes I_n) + \\sigma W$, where $\\mathbf{1}_T$ is the all-ones vector, $I_n$ is the identity matrix, and $W$ is a Hermitian noise matrix with complex Gaussian entries. The smoothness of $G^*$ is quantified by a parameter $S_T$ related to the quadratic variation of the signal on a path graph. The proposed estimator $\\hat{G}$ is obtained via matrix denoising: $\\hat{G} = \\mathcal{P}_{\\tau,n} A$, where $\\mathcal{P}_{\\tau,n}$ projects the columns of $A$ onto the subspace spanned by the first $\\tau$ eigenvectors of the path graph Laplacian.", "goal": "Theorem 3.3 establishes a high-probability non-asymptotic bound on the Frobenius norm error $\\|\\hat{G} - \\Gshift^*\\|_F^2$ (where $\\Gshift^*$ is the shifted ground truth), providing an explicit rate depending on the dimension $n$, time horizon $T$, noise level $\\sigma$, smoothness $S_T$, and the optimal frequency cutoff $\\tau^*$."}, "local_context": {"anchor_latex": "Q(p) := \\|B - p\\|_{\\psi_2}, \\quad \\text{where } B \\sim \\text{Bernoulli}(p)", "gap_objective": "Find the exact expression for the sub-Gaussian norm $Q(p)$"}}, "ground_truth": {"target_citation_key": "Ostrovsky2014ExactVF", "target_lemma_latex": "Q(p) = \\sqrt{\\frac{1-2p}{4 \\log(\\frac{1-p}{p})}}", "target_citation_content": "E.~Ostrovsky and L.~Sirota. \\newblock Exact value for subgaussian norm of centered indicator random variable. \\newblock \\em arXiv:1405.6749, 2014."}}
{"id": "2406.04071v2_gap_3", "arxiv_id": "2406.04071v2", "title": "Dynamic angular synchronization under smoothness constraints", "publication_date": "2024-06-06", "problem_input": {"global_context": {"setup": "The paper considers the problem of recovering a sequence of smooth ground truth vectors $g^*(1), \\dots, g^*(T) \\in \\mathbb{C}^n$ (where each entry has unit modulus) from noisy pairwise measurements. The stacked ground truth matrix is denoted $G^*$. Under the Additive Gaussian Noise (AGN) model, the observation matrix $A \\in \\mathbb{C}^{nT \\times n}$ is given by $A = (G^* - \\mathbf{1}_T \\otimes I_n) + \\sigma W$, where $\\mathbf{1}_T$ is the all-ones vector, $I_n$ is the identity matrix, and $W$ is a Hermitian noise matrix with complex Gaussian entries. The smoothness of $G^*$ is quantified by a parameter $S_T$ related to the quadratic variation of the signal on a path graph. The proposed estimator $\\hat{G}$ is obtained via matrix denoising: $\\hat{G} = \\mathcal{P}_{\\tau,n} A$, where $\\mathcal{P}_{\\tau,n}$ projects the columns of $A$ onto the subspace spanned by the first $\\tau$ eigenvectors of the path graph Laplacian.", "goal": "Theorem 3.3 establishes a high-probability non-asymptotic bound on the Frobenius norm error $\\|\\hat{G} - \\Gshift^*\\|_F^2$ (where $\\Gshift^*$ is the shifted ground truth), providing an explicit rate depending on the dimension $n$, time horizon $T$, noise level $\\sigma$, smoothness $S_T$, and the optimal frequency cutoff $\\tau^*$."}, "local_context": {"anchor_latex": "s(k) \\Gshift^*(k)= s(k) (g^*(k)\\conj{g^*(k)} - I_n) \\implies \\text{spectral gap of } s(k) \\Gshift^*(k) \\text{ is } s(k) n", "gap_objective": "Bound the deviation of the leading eigenvector $\\est{g}'(k)$ from the ground truth eigenspace spanned by $g^*(k)$ in terms of the perturbation magnitude and spectral gap."}}, "ground_truth": {"target_citation_key": "daviskahan", "target_lemma_latex": "\\left\\|\\Big(I - \\frac{g^*(k) g^*(k)^{H}}{n} \\Big) \\est{g}'(k)\\right\\|_2 \\leq \\frac{4\\|\\est{G}'(k)-s(k)\\Gshift^*(k)\\|_{op}}{s(k) n}", "target_citation_content": "Chandler Davis and W.~M. Kahan. \\newblock The rotation of eigenvectors by a perturbation. iii. \\newblock \\em SIAM Journal on Numerical Analysis, 7(1):1--46, 1970."}}
{"id": "2406.04071v2_gap_4", "arxiv_id": "2406.04071v2", "title": "Dynamic angular synchronization under smoothness constraints", "publication_date": "2024-06-06", "problem_input": {"global_context": {"setup": "The paper considers the problem of recovering a sequence of smooth ground truth vectors $g^*(1), \\dots, g^*(T) \\in \\mathbb{C}^n$ (where each entry has unit modulus) from noisy pairwise measurements. The stacked ground truth matrix is denoted $G^*$. Under the Additive Gaussian Noise (AGN) model, the observation matrix $A \\in \\mathbb{C}^{nT \\times n}$ is given by $A = (G^* - \\mathbf{1}_T \\otimes I_n) + \\sigma W$, where $\\mathbf{1}_T$ is the all-ones vector, $I_n$ is the identity matrix, and $W$ is a Hermitian noise matrix with complex Gaussian entries. The smoothness of $G^*$ is quantified by a parameter $S_T$ related to the quadratic variation of the signal on a path graph. The proposed estimator $\\hat{G}$ is obtained via matrix denoising: $\\hat{G} = \\mathcal{P}_{\\tau,n} A$, where $\\mathcal{P}_{\\tau,n}$ projects the columns of $A$ onto the subspace spanned by the first $\\tau$ eigenvectors of the path graph Laplacian.", "goal": "Theorem 3.3 establishes a high-probability non-asymptotic bound on the Frobenius norm error $\\|\\hat{G} - \\Gshift^*\\|_F^2$ (where $\\Gshift^*$ is the shifted ground truth), providing an explicit rate depending on the dimension $n$, time horizon $T$, noise level $\\sigma$, smoothness $S_T$, and the optimal frequency cutoff $\\tau^*$."}, "local_context": {"anchor_latex": "\\left\\|\\Big(I - \\frac{g^*(k) g^*(k)^{H}}{n} \\Big) \\est{g}'(k)\\right\\|_2 \\leq \\frac{4\\|\\est{G}'(k)-s(k)\\Gshift^*(k)\\|_{op}}{s(k) n}", "gap_objective": "To relate the projection error of the estimated eigenvector onto the subspace orthogonal to the ground truth (bounded by Davis-Kahan) to the Euclidean distance between the eigenvector and the phase-aligned ground truth vector."}}, "ground_truth": {"target_citation_key": "SVDRank", "target_lemma_latex": "\\exists \\phik\\in[0,2\\pi) : \\left\\|\\est{g}'(k)-e^{\\iota \\phik}\\frac{g^*(k)}{\\sqrt n}\\right\\|_2 \\leq 2 \\left\\|\\Big(I - \\frac{g^*(k) (g^*(k))^{H}}{n} \\Big) \\est{g}'(k)\\right\\|_2", "target_citation_content": "Alexandre d'Aspremont, Mihai Cucuringu, and Hemant Tyagi. \\newblock Ranking and synchronization from pairwise measurements via SVD. \\newblock \\em Journal of Machine Learning Research (JMLR), 22(19):1--63, 2021."}}
{"id": "2406.04071v2_gap_5", "arxiv_id": "2406.04071v2", "title": "Dynamic angular synchronization under smoothness constraints", "publication_date": "2024-06-06", "problem_input": {"global_context": {"setup": "The paper considers the problem of recovering a sequence of smooth ground truth vectors $g^*(1), \\dots, g^*(T) \\in \\mathbb{C}^n$ (where each entry has unit modulus) from noisy pairwise measurements. The stacked ground truth matrix is denoted $G^*$. Under the Additive Gaussian Noise (AGN) model, the observation matrix $A \\in \\mathbb{C}^{nT \\times n}$ is given by $A = (G^* - \\mathbf{1}_T \\otimes I_n) + \\sigma W$, where $\\mathbf{1}_T$ is the all-ones vector, $I_n$ is the identity matrix, and $W$ is a Hermitian noise matrix with complex Gaussian entries. The smoothness of $G^*$ is quantified by a parameter $S_T$ related to the quadratic variation of the signal on a path graph. The proposed estimator $\\hat{G}$ is obtained via matrix denoising: $\\hat{G} = \\mathcal{P}_{\\tau,n} A$, where $\\mathcal{P}_{\\tau,n}$ projects the columns of $A$ onto the subspace spanned by the first $\\tau$ eigenvectors of the path graph Laplacian.", "goal": "Theorem 3.3 establishes a high-probability non-asymptotic bound on the Frobenius norm error $\\|\\hat{G} - \\Gshift^*\\|_F^2$ (where $\\Gshift^*$ is the shifted ground truth), providing an explicit rate depending on the dimension $n$, time horizon $T$, noise level $\\sigma$, smoothness $S_T$, and the optimal frequency cutoff $\\tau^*$."}, "local_context": {"anchor_latex": "\\norm{\\est{g}(k) - g^*(k)}_2 = \\left \\|\\calP_{\\calC_n}\\paren{\\sqrt{n}\\est{g}'(k) e^{-\\iota \\teonek}} -g^*(k)\\right\\|_2", "gap_objective": "Bound the distance between the projected vector and the ground truth by the distance between the unprojected vector and the ground truth."}}, "ground_truth": {"target_citation_key": "Liu2017", "target_lemma_latex": "\\norm{\\calP_{\\calC_n}(w) - g}_q \\leq 2 \\norm{w - g}_q", "target_citation_content": "H.~Liu, Man-Chung Yue, and A.~Man-Cho~So. \\newblock On the estimation performance and convergence rate of the generalized power method for phase synchronization. \\newblock \\em SIAM Journal on Optimization, 27(4):2426--2446, 2017."}}
{"id": "2405.01142v2_gap_0", "arxiv_id": "2405.01142v2", "title": "Sharp Bounds for Sequential Federated Learning on Heterogeneous Data", "publication_date": "2024-05-02", "problem_input": {"global_context": {"setup": "The paper analyzes Sequential Federated Learning (SFL) and Parallel Federated Learning (PFL) for optimizing an objective function $F(\\mathbf{x}) = \\frac{1}{M} \\sum_{m=1}^M F_m(\\mathbf{x})$, where $M$ is the number of clients. The algorithms proceed in rounds $r=0, \\dots, R-1$. In SFL, clients update sequentially in a permutation $\\pi$, performing $K$ local steps with learning rate $\\eta$. The setup considers both non-convex and strongly convex assumptions. Key parameters include smoothness constant $L$, strong convexity $\\mu$, stochastic gradient variance $\\sigma^2$, and heterogeneity bound $\\zeta^2$. The analysis involves deriving convergence upper bounds and information-theoretic lower bounds.", "goal": "To prove upper bounds on the convergence rate of SFL (Theorem A.1) and establish lower bounds for SFL that match or differ from SGD with Random Reshuffling (Theorem 3.1, 3.3)."}, "local_context": {"anchor_latex": "\\text{The global update is performed at the end of one training round}", "gap_objective": "Bound the client drift term $\\sum_{m=1}^M\\sum_{k=0}^{K-1}\\mathbb{E}\\|\\rvx_{m,k}^{(r)}-\\rvx^{(r)}\\|^2$"}}, "ground_truth": {"target_citation_key": "li2023convergence", "target_lemma_latex": "\\sum_{m=1}^M\\sum_{k=0}^{K-1}\\mathbb{E}\\|\\rvx_{m,k}^{(r)}-\\rvx^{(r)}\\|^2 \\le \\frac{9}{4}\\eta^2 M^2 K^2 \\sigma^2 + \\frac{9}{4}\\eta^2 M^2 K^3 \\zeta^2", "target_citation_content": "Yipeng Li and Xinchen Lyu. \\newblock Convergence analysis of sequential federated learning on heterogeneous data. \\newblock In \\emphConference on Neural Information Processing Systems (NeurIPS), 2023."}}
{"id": "2405.01142v2_gap_1", "arxiv_id": "2405.01142v2", "title": "Sharp Bounds for Sequential Federated Learning on Heterogeneous Data", "publication_date": "2024-05-02", "problem_input": {"global_context": {"setup": "The paper analyzes Sequential Federated Learning (SFL) and Parallel Federated Learning (PFL) for optimizing an objective function $F(\\mathbf{x}) = \\frac{1}{M} \\sum_{m=1}^M F_m(\\mathbf{x})$, where $M$ is the number of clients. The algorithms proceed in rounds $r=0, \\dots, R-1$. In SFL, clients update sequentially in a permutation $\\pi$, performing $K$ local steps with learning rate $\\eta$. The setup considers both non-convex and strongly convex assumptions. Key parameters include smoothness constant $L$, strong convexity $\\mu$, stochastic gradient variance $\\sigma^2$, and heterogeneity bound $\\zeta^2$. The analysis involves deriving convergence upper bounds and information-theoretic lower bounds.", "goal": "To prove upper bounds on the convergence rate of SFL (Theorem A.1) and establish lower bounds for SFL that match or differ from SGD with Random Reshuffling (Theorem 3.1, 3.3)."}, "local_context": {"anchor_latex": "\\Delta \\rvx = -\\eta\\gamma\\sum_{m=1}^{M} \\sum_{k=0}^{K-1} \\rvg_{\\pi_{m}} (\\rvx_{m,k})", "gap_objective": "Bound the expected change in the objective function value $\\E[F(\\rvx^{(r+1)}) - F(\\rvx^{(r)})]$ for the given update rule."}}, "ground_truth": {"target_citation_key": "li2023convergence", "target_lemma_latex": "\\E\\left[F(\\rvx^{(r+1)}) - F(\\rvx^{(r)})\\right] \\leq-\\frac{1}{6}\\eta MK\\E\\Norm{\\nabla F(\\rvx^{(r)})}^2 + 2\\eta^2 LMK\\sigma^2 + \\frac{5}{6}\\eta L^2\\sum_{m=1}^M\\sum_{k=0}^{K-1}\\E\\Norm{\\rvx_{m,k}^{(r)}-\\rvx^{(r)}}^2", "target_citation_content": "Yipeng Li and Xinchen Lyu. \\newblock Convergence analysis of sequential federated learning on heterogeneous data. \\newblock In \\emphConference on Neural Information Processing Systems (NeurIPS), 2023."}}
{"id": "2405.01142v2_gap_2", "arxiv_id": "2405.01142v2", "title": "Sharp Bounds for Sequential Federated Learning on Heterogeneous Data", "publication_date": "2024-05-02", "problem_input": {"global_context": {"setup": "The paper analyzes Sequential Federated Learning (SFL) and Parallel Federated Learning (PFL) for optimizing an objective function $F(\\mathbf{x}) = \\frac{1}{M} \\sum_{m=1}^M F_m(\\mathbf{x})$, where $M$ is the number of clients. The algorithms proceed in rounds $r=0, \\dots, R-1$. In SFL, clients update sequentially in a permutation $\\pi$, performing $K$ local steps with learning rate $\\eta$. The setup considers both non-convex and strongly convex assumptions. Key parameters include smoothness constant $L$, strong convexity $\\mu$, stochastic gradient variance $\\sigma^2$, and heterogeneity bound $\\zeta^2$. The analysis involves deriving convergence upper bounds and information-theoretic lower bounds.", "goal": "To prove upper bounds on the convergence rate of SFL (Theorem A.1) and establish lower bounds for SFL that match or differ from SGD with Random Reshuffling (Theorem 3.1, 3.3)."}, "local_context": {"anchor_latex": "\\min_{0\\leq r\\leq R} \\E\\left[\\Norm{\\nabla F(\\rvx^{(r)})}^2\\right] \\leq \\frac{10 A}{\\tilde \\eta R} + \\frac{20 \\tilde \\eta L \\sigma^2}{MK} + \\frac{75}{4}\\frac{\\tilde\\eta^2L^2\\sigma^2}{\\gamma^2MK} + \\frac{75}{4}\\frac{\\tilde\\eta^2L^2\\zeta^2}{\\gamma^2M}", "gap_objective": "Tune the effective learning rate \\tilde{\\eta} to minimize the convergence bound subject to the constraint \\eta\\gamma \\leq \\frac{1}{6LMK(1+\\beta^2/M)}."}}, "ground_truth": {"target_citation_key": "li2023convergence", "target_lemma_latex": "\\min_{0\\leq r\\leq R} \\E\\left[\\Norm{\\nabla F(\\rvx^{(r)})}^2\\right] = \\gO\\left(\\frac{ LA\\left(1+\\frac{\\beta^2}{M}\\right) }{R } + \\frac{\\left(L\\sigma^2 A\\right)^{1/2} }{\\sqrt{MKR}} + \\frac{ \\left(L^2\\sigma^2A^2\\right)^{1/3} }{ \\gamma^{2/3}M^{1/3}K^{1/3} R^{2/3}} + \\frac{ \\left(L^2\\zeta^2A^2\\right)^{1/3} }{ \\gamma^{2/3}M^{1/3}R^{2/3}}\\right)", "target_citation_content": "Yipeng Li and Xinchen Lyu. \\newblock Convergence analysis of sequential federated learning on heterogeneous data. \\newblock In \\emphConference on Neural Information Processing Systems (NeurIPS), 2023."}}
{"id": "2405.01142v2_gap_3", "arxiv_id": "2405.01142v2", "title": "Sharp Bounds for Sequential Federated Learning on Heterogeneous Data", "publication_date": "2024-05-02", "problem_input": {"global_context": {"setup": "The paper analyzes Sequential Federated Learning (SFL) and Parallel Federated Learning (PFL) for optimizing an objective function $F(\\mathbf{x}) = \\frac{1}{M} \\sum_{m=1}^M F_m(\\mathbf{x})$, where $M$ is the number of clients. The algorithms proceed in rounds $r=0, \\dots, R-1$. In SFL, clients update sequentially in a permutation $\\pi$, performing $K$ local steps with learning rate $\\eta$. The setup considers both non-convex and strongly convex assumptions. Key parameters include smoothness constant $L$, strong convexity $\\mu$, stochastic gradient variance $\\sigma^2$, and heterogeneity bound $\\zeta^2$. The analysis involves deriving convergence upper bounds and information-theoretic lower bounds.", "goal": "To prove upper bounds on the convergence rate of SFL (Theorem A.1) and establish lower bounds for SFL that match or differ from SGD with Random Reshuffling (Theorem 3.1, 3.3)."}, "local_context": {"anchor_latex": "\\text{Any first-order method which accesses at most } MKR \\text{ stochastic gradients with variance } \\sigma^2 \\text{ for a } \\mu\\text{-strongly convex objective}", "gap_objective": "\\text{Lower bound on the worst-case error}"}}, "ground_truth": {"target_citation_key": "woodworth2020local", "target_lemma_latex": "\\Omega\\left( \\frac{\\sigma^2}{\\mu MKR} \\right)", "target_citation_content": "Blake Woodworth, Kumar~Kshitij Patel, Sebastian Stich, Zhen Dai, Brian Bullins, Brendan Mcmahan, Ohad Shamir, and Nathan Srebro. \\newblock Is local SGD better than minibatch SGD? \\newblock In \\emphInternational Conference on Machine Learning (ICML), 2020\\natexlaba."}}
{"id": "2405.01142v2_gap_4", "arxiv_id": "2405.01142v2", "title": "Sharp Bounds for Sequential Federated Learning on Heterogeneous Data", "publication_date": "2024-05-02", "problem_input": {"global_context": {"setup": "The paper analyzes Sequential Federated Learning (SFL) and Parallel Federated Learning (PFL) for optimizing an objective function $F(\\mathbf{x}) = \\frac{1}{M} \\sum_{m=1}^M F_m(\\mathbf{x})$, where $M$ is the number of clients. The algorithms proceed in rounds $r=0, \\dots, R-1$. In SFL, clients update sequentially in a permutation $\\pi$, performing $K$ local steps with learning rate $\\eta$. The setup considers both non-convex and strongly convex assumptions. Key parameters include smoothness constant $L$, strong convexity $\\mu$, stochastic gradient variance $\\sigma^2$, and heterogeneity bound $\\zeta^2$. The analysis involves deriving convergence upper bounds and information-theoretic lower bounds.", "goal": "To prove upper bounds on the convergence rate of SFL (Theorem A.1) and establish lower bounds for SFL that match or differ from SGD with Random Reshuffling (Theorem 3.1, 3.3)."}, "local_context": {"anchor_latex": "\\E\\left[F(\\bar\\rvx^{(R)})-F(\\rvx^\\ast)\\right] = \\Omega \\left( \\frac{L^{1/3}\\sigma^{2/3}D^{4/3}}{ M^{1/3}K^{1/3} R^{2/3}} + \\frac{L^{1/3}\\zeta^{2/3}D^{4/3}}{ M^{1/3} R^{2/3}}\\right)", "gap_objective": "To incorporate the standard statistical lower bound for stochastic convex optimization, which applies regardless of the specific algorithm's step size or heterogeneity handling, to complete the final lower bound."}}, "ground_truth": {"target_citation_key": "woodworth2020minibatch", "target_lemma_latex": "\\Omega \\left(\\frac{\\sigma D}{\\sqrt{MKR}} \\right)", "target_citation_content": "Blake~E Woodworth, Kumar~Kshitij Patel, and Nati Srebro. \\newblock Minibatch vs local SGD for heterogeneous distributed learning. \\newblock In \\emphConference on Neural Information Processing Systems (NeurIPS), 2020\\natexlabb."}}
{"id": "2405.01142v2_gap_5", "arxiv_id": "2405.01142v2", "title": "Sharp Bounds for Sequential Federated Learning on Heterogeneous Data", "publication_date": "2024-05-02", "problem_input": {"global_context": {"setup": "The paper analyzes Sequential Federated Learning (SFL) and Parallel Federated Learning (PFL) for optimizing an objective function $F(\\mathbf{x}) = \\frac{1}{M} \\sum_{m=1}^M F_m(\\mathbf{x})$, where $M$ is the number of clients. The algorithms proceed in rounds $r=0, \\dots, R-1$. In SFL, clients update sequentially in a permutation $\\pi$, performing $K$ local steps with learning rate $\\eta$. The setup considers both non-convex and strongly convex assumptions. Key parameters include smoothness constant $L$, strong convexity $\\mu$, stochastic gradient variance $\\sigma^2$, and heterogeneity bound $\\zeta^2$. The analysis involves deriving convergence upper bounds and information-theoretic lower bounds.", "goal": "To prove upper bounds on the convergence rate of SFL (Theorem A.1) and establish lower bounds for SFL that match or differ from SGD with Random Reshuffling (Theorem 3.1, 3.3)."}, "local_context": {"anchor_latex": "f_{\\pi_n} (x) = \\frac{1}{2}\\lambda x^2 + \\tau_{n}\\sigma x, \\quad f(x) = \\E \\left[f_{\\pi_n}(x)\\right] = \\frac{1}{2}\\lambda x^2", "gap_objective": "Obtain the closed-form expression for the parameter $x_N$ after $N$ steps of SGD on the 1D quadratic objective with stochastic linear noise."}}, "ground_truth": {"target_citation_key": "cha2023tighter", "target_lemma_latex": "x_N = (1-\\lambda \\eta)^N x_0 - \\eta \\sigma \\sum_{n=1}^{N} (1-\\lambda\\eta)^{N-n} \\tau_{n}", "target_citation_content": "Jaeyoung Cha, Jaewook Lee, and Chulhee Yun. \\newblock Tighter lower bounds for shuffling SGD: Random permutations and beyond. \\newblock In \\emphInternational Conference on Machine Learning (ICML), 2023."}}
{"id": "2405.01142v2_gap_6", "arxiv_id": "2405.01142v2", "title": "Sharp Bounds for Sequential Federated Learning on Heterogeneous Data", "publication_date": "2024-05-02", "problem_input": {"global_context": {"setup": "The paper analyzes Sequential Federated Learning (SFL) and Parallel Federated Learning (PFL) for optimizing an objective function $F(\\mathbf{x}) = \\frac{1}{M} \\sum_{m=1}^M F_m(\\mathbf{x})$, where $M$ is the number of clients. The algorithms proceed in rounds $r=0, \\dots, R-1$. In SFL, clients update sequentially in a permutation $\\pi$, performing $K$ local steps with learning rate $\\eta$. The setup considers both non-convex and strongly convex assumptions. Key parameters include smoothness constant $L$, strong convexity $\\mu$, stochastic gradient variance $\\sigma^2$, and heterogeneity bound $\\zeta^2$. The analysis involves deriving convergence upper bounds and information-theoretic lower bounds.", "goal": "To prove upper bounds on the convergence rate of SFL (Theorem A.1) and establish lower bounds for SFL that match or differ from SGD with Random Reshuffling (Theorem 3.1, 3.3)."}, "local_context": {"anchor_latex": "\\E\\left[x^{(r+1)}\\mid x^{(r)}\\geq 0\\right] \\geq \\left(1-\\frac{2}{3}\\lambda_0 N\\eta\\right)\\E\\left[x^{(r)}\\mid x^{(r)}\\geq 0\\right]+ \\frac{1}{60} \\eta N^{\\frac{3}{2}}\\sigma", "gap_objective": "Lower bound the expectation of the next iterate $x^{(r+1)}$ conditional on the current iterate being negative, i.e., $\\E[x^{(r+1)} \\mid x^{(r)} < 0]$."}}, "ground_truth": {"target_citation_key": "cha2023tighter", "target_lemma_latex": "(x_{m,k})_{F} \\geq (x_{m,k})_{H}", "target_citation_content": "Jaeyoung Cha, Jaewook Lee, and Chulhee Yun. \\newblock Tighter lower bounds for shuffling SGD: Random permutations and beyond. \\newblock In \\emphInternational Conference on Machine Learning (ICML), 2023."}}
{"id": "2405.01142v2_gap_7", "arxiv_id": "2405.01142v2", "title": "Sharp Bounds for Sequential Federated Learning on Heterogeneous Data", "publication_date": "2024-05-02", "problem_input": {"global_context": {"setup": "The paper analyzes Sequential Federated Learning (SFL) and Parallel Federated Learning (PFL) for optimizing an objective function $F(\\mathbf{x}) = \\frac{1}{M} \\sum_{m=1}^M F_m(\\mathbf{x})$, where $M$ is the number of clients. The algorithms proceed in rounds $r=0, \\dots, R-1$. In SFL, clients update sequentially in a permutation $\\pi$, performing $K$ local steps with learning rate $\\eta$. The setup considers both non-convex and strongly convex assumptions. Key parameters include smoothness constant $L$, strong convexity $\\mu$, stochastic gradient variance $\\sigma^2$, and heterogeneity bound $\\zeta^2$. The analysis involves deriving convergence upper bounds and information-theoretic lower bounds.", "goal": "To prove upper bounds on the convergence rate of SFL (Theorem A.1) and establish lower bounds for SFL that match or differ from SGD with Random Reshuffling (Theorem 3.1, 3.3)."}, "local_context": {"anchor_latex": "\\E\\abs{\\gE_{n}} = \\E\\abs{\\gE_{n-1}} + \\mathbbm{1}_{n-1 \\ \\text{is even}} \\frac{{n-1 \\choose n-1/2}}{2^{n-1}}", "gap_objective": "Estimate the central binomial coefficient term to derive a lower bound for the expectation recursion."}}, "ground_truth": {"target_citation_key": "cha2023tighter", "target_lemma_latex": "{n \\choose n/2} \\approx 2^{n} \\cdot \\frac{\\sqrt{2n + \\alpha_n}}{\\sqrt{\\pi} (n + \\alpha_{n/2})}", "target_citation_content": "Jaeyoung Cha, Jaewook Lee, and Chulhee Yun. \\newblock Tighter lower bounds for shuffling SGD: Random permutations and beyond. \\newblock In \\emphInternational Conference on Machine Learning (ICML), 2023."}}
{"id": "2405.01142v2_gap_8", "arxiv_id": "2405.01142v2", "title": "Sharp Bounds for Sequential Federated Learning on Heterogeneous Data", "publication_date": "2024-05-02", "problem_input": {"global_context": {"setup": "The paper analyzes Sequential Federated Learning (SFL) and Parallel Federated Learning (PFL) for optimizing an objective function $F(\\mathbf{x}) = \\frac{1}{M} \\sum_{m=1}^M F_m(\\mathbf{x})$, where $M$ is the number of clients. The algorithms proceed in rounds $r=0, \\dots, R-1$. In SFL, clients update sequentially in a permutation $\\pi$, performing $K$ local steps with learning rate $\\eta$. The setup considers both non-convex and strongly convex assumptions. Key parameters include smoothness constant $L$, strong convexity $\\mu$, stochastic gradient variance $\\sigma^2$, and heterogeneity bound $\\zeta^2$. The analysis involves deriving convergence upper bounds and information-theoretic lower bounds.", "goal": "To prove upper bounds on the convergence rate of SFL (Theorem A.1) and establish lower bounds for SFL that match or differ from SGD with Random Reshuffling (Theorem 3.1, 3.3)."}, "local_context": {"anchor_latex": "\\E\\abs{\\gE_{n}} = \\E\\abs{\\gE_{n-1}} + \\mathbbm{1}_{n-1 \\ \\text{is even}} \\frac{{n-1 \\choose n-1/2}}{2^{n-1}}", "gap_objective": "Estimate the central binomial coefficient to lower bound the expected absolute value of the partial sum."}}, "ground_truth": {"target_citation_key": "mortici2011gospers", "target_lemma_latex": "{n \\choose n/2} \\approx 2^{n} \\cdot \\frac{\\sqrt{2n + \\alpha_n}}{\\sqrt{\\pi} (n + \\alpha_{n/2})} \\quad \\text{with} \\quad 0.333 \\leq \\alpha_{n/2}, \\alpha_n \\leq 0.354", "target_citation_content": "Cristinel Mortici. \\newblock On Gospers formula for the Gamma function. \\newblock \\emphJournal of Mathematical Inequalities, 2011."}}
{"id": "2405.01142v2_gap_9", "arxiv_id": "2405.01142v2", "title": "Sharp Bounds for Sequential Federated Learning on Heterogeneous Data", "publication_date": "2024-05-02", "problem_input": {"global_context": {"setup": "The paper analyzes Sequential Federated Learning (SFL) and Parallel Federated Learning (PFL) for optimizing an objective function $F(\\mathbf{x}) = \\frac{1}{M} \\sum_{m=1}^M F_m(\\mathbf{x})$, where $M$ is the number of clients. The algorithms proceed in rounds $r=0, \\dots, R-1$. In SFL, clients update sequentially in a permutation $\\pi$, performing $K$ local steps with learning rate $\\eta$. The setup considers both non-convex and strongly convex assumptions. Key parameters include smoothness constant $L$, strong convexity $\\mu$, stochastic gradient variance $\\sigma^2$, and heterogeneity bound $\\zeta^2$. The analysis involves deriving convergence upper bounds and information-theoretic lower bounds.", "goal": "To prove upper bounds on the convergence rate of SFL (Theorem A.1) and establish lower bounds for SFL that match or differ from SGD with Random Reshuffling (Theorem 3.1, 3.3)."}, "local_context": {"anchor_latex": "\\text{Let } \\tau=(\\tau_1, \\ldots, \\tau_M) \\text{ be a random permutation of } \\frac{M}{2} \\text{ } +1\\text{'s and } \\frac{M}{2} \\text{ } -1\\text{'s. Define } \\gA_{m,k} \\coloneqq \\sum_{i=1}^{m-1}\\tau_{i} + \\frac{k}{K} \\tau_m. \\text{ For } 2 \\leq m \\leq M \\text{ and } k=0, \\text{ we have } \\gA_{m,0} = \\sum_{i=1}^{m-1}\\tau_{i}.", "gap_objective": "\\text{Lower bound the probability } \\Pr(\\gA_{m,0} > 0)."}}, "ground_truth": {"target_citation_key": "yun2022minibatch", "target_lemma_latex": "\\Pr\\left(\\sum_{i=1}^{n} \\tau_i > 0\\right) \\geq \\frac{1}{6} \\text{ for } 1 \\leq n < M", "target_citation_content": "Chulhee Yun, Shashank Rajput, and Suvrit Sra. \\newblock Minibatch vs local SGD with shuffling: Tight convergence bounds and beyond. \\newblock In \\emphInternational Conference on Learning Representations (ICLR), 2022."}}
{"id": "2405.01142v2_gap_10", "arxiv_id": "2405.01142v2", "title": "Sharp Bounds for Sequential Federated Learning on Heterogeneous Data", "publication_date": "2024-05-02", "problem_input": {"global_context": {"setup": "The paper analyzes Sequential Federated Learning (SFL) and Parallel Federated Learning (PFL) for optimizing an objective function $F(\\mathbf{x}) = \\frac{1}{M} \\sum_{m=1}^M F_m(\\mathbf{x})$, where $M$ is the number of clients. The algorithms proceed in rounds $r=0, \\dots, R-1$. In SFL, clients update sequentially in a permutation $\\pi$, performing $K$ local steps with learning rate $\\eta$. The setup considers both non-convex and strongly convex assumptions. Key parameters include smoothness constant $L$, strong convexity $\\mu$, stochastic gradient variance $\\sigma^2$, and heterogeneity bound $\\zeta^2$. The analysis involves deriving convergence upper bounds and information-theoretic lower bounds.", "goal": "To prove upper bounds on the convergence rate of SFL (Theorem A.1) and establish lower bounds for SFL that match or differ from SGD with Random Reshuffling (Theorem 3.1, 3.3)."}, "local_context": {"anchor_latex": "\\E\\left[\\abs{\\gA_{m,k}}\\right] \\geq \\left(1-\\frac{2}{M}\\right)\\E\\left[\\abs{\\gE_{m-1}}\\right] \\geq \\frac{1}{2}\\E\\left[\\abs{\\gE_{m-1}}\\right]", "gap_objective": "Establish a tighter lower bound for the expectation of the absolute partial sum \\E[|\\gE_m|] (specifically for even m) to refine the bound on \\E[|\\gA_{m,k}|]."}}, "ground_truth": {"target_citation_key": "cha2023tighter", "target_lemma_latex": "\\E\\left[\\abs{\\gE_m}\\right] \\geq \\left(\\frac{M-2}{M-1} \\cdot \\frac{\\sqrt{m}}{\\sqrt{m-2}}\\right) \\cdot \\left(\\frac{M}{M+2m}\\right) \\cdot \\left(\\frac{\\sqrt{m}}{5}\\right)", "target_citation_content": "Jaeyoung Cha, Jaewook Lee, and Chulhee Yun. \\newblock Tighter lower bounds for shuffling SGD: Random permutations and beyond. \\newblock In \\emphInternational Conference on Machine Learning (ICML), 2023."}}
{"id": "2405.01142v2_gap_11", "arxiv_id": "2405.01142v2", "title": "Sharp Bounds for Sequential Federated Learning on Heterogeneous Data", "publication_date": "2024-05-02", "problem_input": {"global_context": {"setup": "The paper analyzes Sequential Federated Learning (SFL) and Parallel Federated Learning (PFL) for optimizing an objective function $F(\\mathbf{x}) = \\frac{1}{M} \\sum_{m=1}^M F_m(\\mathbf{x})$, where $M$ is the number of clients. The algorithms proceed in rounds $r=0, \\dots, R-1$. In SFL, clients update sequentially in a permutation $\\pi$, performing $K$ local steps with learning rate $\\eta$. The setup considers both non-convex and strongly convex assumptions. Key parameters include smoothness constant $L$, strong convexity $\\mu$, stochastic gradient variance $\\sigma^2$, and heterogeneity bound $\\zeta^2$. The analysis involves deriving convergence upper bounds and information-theoretic lower bounds.", "goal": "To prove upper bounds on the convergence rate of SFL (Theorem A.1) and establish lower bounds for SFL that match or differ from SGD with Random Reshuffling (Theorem 3.1, 3.3)."}, "local_context": {"anchor_latex": "\\E\\left[\\left(\\sum_{m=0}^{M-1}(1-\\lambda\\eta)^{mK}\\tau_{m}\\right)^2\\right] =\\sum_{m=0}^{M-1} (1-\\lambda\\eta)^{2mK}\\E\\left[\\tau_m^2\\right] + \\sum_{i=0}^{M-1}\\sum_{j\\neq i}^{M-1}(1-\\lambda\\eta)^{(i+j)K}\\E\\left[\\langle \\tau_{i},\\tau_{j}\\rangle \\right]", "gap_objective": "Evaluate the second moments and cross-correlations $\\E[\\tau_m^2]$ and $\\E[\\langle \\tau_i, \\tau_j \\rangle]$ for a random permutation $\\tau$ of balanced signs"}}, "ground_truth": {"target_citation_key": "safran2020good", "target_lemma_latex": "\\tau_m^2=1 \\quad \\text{and} \\quad \\E\\left[\\langle \\tau_{i},\\tau_{j}\\rangle \\right]=-\\frac{1}{M-1}", "target_citation_content": "Itay Safran and Ohad Shamir. \\newblock How good is SGD with random shuffling? \\newblock In \\emphConference on Learning Theory (COLT), 2020."}}
{"id": "2406.02003v1_gap_0", "arxiv_id": "2406.02003v1", "title": "Laplace Meets Moreau: Smooth Approximation to Infimal Convolutions Using Laplace's Method", "publication_date": "2024-06-04", "problem_input": {"global_context": {"setup": "The paper considers the problem of sampling from a target probability distribution $\\pi(x) \\propto e^{-V(x)}$ on $\\mathbb{R}^d$, where the potential function $V(x)$ admits a composite structure $V(x) = f(x) + g(x)$. Here, $f$ is assumed to be $L$-smooth and convex, while $g$ is convex, lower semicontinuous, and possibly non-smooth but admits an efficiently computable proximal operator. The analysis relies on the connection between the proximal operator and the Moreau envelope.", "goal": "To propose and analyze the Bayesian Proximal Gradient Descent (BPGD) algorithm, providing theoretical guarantees for sampling from the composite distribution by interpreting the algorithm through the lens of Hamilton-Jacobi partial differential equations and the Hopf-Lax formula."}, "local_context": {"anchor_latex": "\\nabla M_{\\lambda f}", "gap_objective": "\\nabla M_{\\lambda f} \\text{ is } 1/\\lambda\\text{-Lipschitz}"}}, "ground_truth": {"target_citation_key": "bauschke2011convex", "target_lemma_latex": "\\text{Let } f \\in \\Gamma_0(H) \\text{ and } \\gamma \\in (0, +\\infty). \\text{ Then } \\nabla ({}^\\gamma f) \\text{ is } 1/\\gamma\\text{-Lipschitz continuous.}", "target_citation_content": "Heinz~H. Bauschke and Patrick~L. Combettes. \\newblock \\emphConvex Analysis and Monotone Operator Theory in Hilbert Spaces. \\newblock Springer, 2011."}}
{"id": "2406.02003v1_gap_3", "arxiv_id": "2406.02003v1", "title": "Laplace Meets Moreau: Smooth Approximation to Infimal Convolutions Using Laplace's Method", "publication_date": "2024-06-04", "problem_input": {"global_context": {"setup": "The paper considers the problem of sampling from a target probability distribution $\\pi(x) \\propto e^{-V(x)}$ on $\\mathbb{R}^d$, where the potential function $V(x)$ admits a composite structure $V(x) = f(x) + g(x)$. Here, $f$ is assumed to be $L$-smooth and convex, while $g$ is convex, lower semicontinuous, and possibly non-smooth but admits an efficiently computable proximal operator. The analysis relies on the connection between the proximal operator and the Moreau envelope.", "goal": "To propose and analyze the Bayesian Proximal Gradient Descent (BPGD) algorithm, providing theoretical guarantees for sampling from the composite distribution by interpreting the algorithm through the lens of Hamilton-Jacobi partial differential equations and the Hopf-Lax formula."}, "local_context": {"anchor_latex": "f \\text{ is continuously differentiable with an } L\\text{-Lipschitz continuous gradient}", "gap_objective": "Quadratic upper bound on the function value f(y) based on f(x)"}}, "ground_truth": {"target_citation_key": "beck2017first", "target_lemma_latex": "f(y) \\le f(x) + \\langle \\nabla f(x), y-x \\rangle + \\frac{L}{2} \\|y-x\\|^2", "target_citation_content": "Amir Beck. \\newblock \\emphFirst-Order Methods in Optimization. \\newblock Society for Industrial and Applied Mathematics, 2017."}}
{"id": "2403.08220v2_gap_0", "arxiv_id": "2403.08220v2", "title": "Derivative-informed neural operator acceleration of geometric MCMC for infinite-dimensional Bayesian inverse problems", "publication_date": "2024-03-13", "problem_input": {"global_context": {"setup": "The setting involves an infinite-dimensional separable Hilbert space $\\mathscr{M}$ endowed with a Gaussian prior measure $\\mu = \\mathcal{N}(0, \\mathcal{C}_{\\text{pr}})$. A parameter-to-observable (PtO) map $\\boldsymbol{\\mathcal{G}}: \\mathscr{M} \\to \\mathscr{Y}$ is defined, along with its approximations $\\widetilde{\\boldsymbol{\\mathcal{G}}}$ (neural operator) and $\\boldsymbol{\\mathcal{G}}_r$ (reduced mapping). The analysis takes place in the context of $L^2_\\mu(\\mathscr{M}; \\mathscr{Y})$ error norms and the properties of Gaussian measures.", "goal": "To derive error bounds for the Derivative-Informed Neural Operator (DINO) surrogate approximation $\\|\\boldsymbol{\\mathcal{G}}-\\widetilde{\\boldsymbol{\\mathcal{G}}}\\|_{L^2_{\\mu}}$ and to prove properties regarding the independence of projected Gaussian random elements."}, "local_context": {"anchor_latex": "\\mathcal{S}\\in H^1_{\\mu}(\\mathscr{M})\\coloneqq H^1_{\\mu}(\\mathscr{M};\\mathbb{R})", "gap_objective": "Bound the variance or L2-norm of a centered function in the Gaussian Sobolev space using its derivative."}}, "ground_truth": {"target_citation_key": "bogachev1998gaussian", "target_lemma_latex": "\\|\\mathcal{S} - \\mathbb{E}[\\mathcal{S}]\\|_{L^2_\\mu}^2 \\le \\|D_{\\mathscr{H}}\\mathcal{S}\\|_{L^2_\\mu}^2", "target_citation_content": "Vladimir~Igorevich Bogachev. \\newblock \\emphGaussian measures, volume~62 of \\emphMathematical Surveys and Monographs. \\newblock American Mathematical Society, 1998."}}
{"id": "2403.08220v2_gap_1", "arxiv_id": "2403.08220v2", "title": "Derivative-informed neural operator acceleration of geometric MCMC for infinite-dimensional Bayesian inverse problems", "publication_date": "2024-03-13", "problem_input": {"global_context": {"setup": "The setting involves an infinite-dimensional separable Hilbert space $\\mathscr{M}$ endowed with a Gaussian prior measure $\\mu = \\mathcal{N}(0, \\mathcal{C}_{\\text{pr}})$. A parameter-to-observable (PtO) map $\\boldsymbol{\\mathcal{G}}: \\mathscr{M} \\to \\mathscr{Y}$ is defined, along with its approximations $\\widetilde{\\boldsymbol{\\mathcal{G}}}$ (neural operator) and $\\boldsymbol{\\mathcal{G}}_r$ (reduced mapping). The analysis takes place in the context of $L^2_\\mu(\\mathscr{M}; \\mathscr{Y})$ error norms and the properties of Gaussian measures.", "goal": "To derive error bounds for the Derivative-Informed Neural Operator (DINO) surrogate approximation $\\|\\boldsymbol{\\mathcal{G}}-\\widetilde{\\boldsymbol{\\mathcal{G}}}\\|_{L^2_{\\mu}}$ and to prove properties regarding the independence of projected Gaussian random elements."}, "local_context": {"anchor_latex": "\\norm{\\calS-\\calS_r}_{L^2_{\\mu}(\\scrM)}^2\\leq \\norm{(\\calI_{\\scrH_{\\mu}}-\\Psi_r\\Psi_r^*)D_{\\scrH}\\calS}_{L^2_{\\mu}(\\scrM;\\scrH_{\\mu})}^2", "gap_objective": "Extend the error bound from scalar functions to the vector-valued operator $\\bdmc{G}$ to obtain an upper bound on $\\norm{\\bdmc{G}-\\bdmc{G}_r}^2_{L^2_{\\mu}(\\scrM;\\scrY)}$."}}, "ground_truth": {"target_citation_key": "zahm2020gradient", "target_lemma_latex": "\\norm{\\bdmc{G}-\\bdmc{G}_r}^2_{L^2_{\\mu}(\\scrM;\\scrY)}\\leq \\text{Tr}_{\\scrH_{\\mu}}(\\calH_A) - \\text{Tr}\\left(\\Psi_r^*\\calH_A\\Psi_r\\right)", "target_citation_content": "Olivier Zahm, Paul~G. Constantine, Cl\\'ementine Prieur, and Youssef~M. Marzouk. \\newblock Gradient-based dimension reduction of multivariate vector-valued functions. \\newblock \\emphSIAM Journal on Scientific Computing, 42\\penalty0 (1):\\penalty0 A534--A558, 2020. \\newblock \\doi10.1137/18M1221837."}}
{"id": "2403.08220v2_gap_2", "arxiv_id": "2403.08220v2", "title": "Derivative-informed neural operator acceleration of geometric MCMC for infinite-dimensional Bayesian inverse problems", "publication_date": "2024-03-13", "problem_input": {"global_context": {"setup": "The setting involves an infinite-dimensional separable Hilbert space $\\mathscr{M}$ endowed with a Gaussian prior measure $\\mu = \\mathcal{N}(0, \\mathcal{C}_{\\text{pr}})$. A parameter-to-observable (PtO) map $\\boldsymbol{\\mathcal{G}}: \\mathscr{M} \\to \\mathscr{Y}$ is defined, along with its approximations $\\widetilde{\\boldsymbol{\\mathcal{G}}}$ (neural operator) and $\\boldsymbol{\\mathcal{G}}_r$ (reduced mapping). The analysis takes place in the context of $L^2_\\mu(\\mathscr{M}; \\mathscr{Y})$ error norms and the properties of Gaussian measures.", "goal": "To derive error bounds for the Derivative-Informed Neural Operator (DINO) surrogate approximation $\\|\\boldsymbol{\\mathcal{G}}-\\widetilde{\\boldsymbol{\\mathcal{G}}}\\|_{L^2_{\\mu}}$ and to prove properties regarding the independence of projected Gaussian random elements."}, "local_context": {"anchor_latex": "\\norm{\\bdmc{G}-\\bdmc{G}_r}^2_{L^2_{\\mu}(\\scrM;\\scrY)} = \\sum_{j=1}^{d_y} \\norm{\\calS^{(j)}-\\calS^{(j)}_r}^2_{L^2_{\\mu}(\\scrM)}", "gap_objective": "Bound the sum of squared errors for each scalar component using the subspace inequality and aggregate these bounds into a trace expression involving the expected Hessian."}}, "ground_truth": {"target_citation_key": "gohberg2012traces", "target_lemma_latex": "\\norm{A}_{HS}^2 = \\text{Tr}(A^* A)", "target_citation_content": "Israel Gohberg, Seymour Goldberg, and Nahum Krupnik. \\newblock \\emphTraces and Determinants of Linear Operators, volume 116 of \\emphOperator Theory: Advances and Applications. \\newblock Birkh\\\"auser Basel, 2012. \\newblock \\doi10.1007/978-3-0348-8401-3."}}
{"id": "2403.08220v2_gap_3", "arxiv_id": "2403.08220v2", "title": "Derivative-informed neural operator acceleration of geometric MCMC for infinite-dimensional Bayesian inverse problems", "publication_date": "2024-03-13", "problem_input": {"global_context": {"setup": "The setting involves an infinite-dimensional separable Hilbert space $\\mathscr{M}$ endowed with a Gaussian prior measure $\\mu = \\mathcal{N}(0, \\mathcal{C}_{\\text{pr}})$. A parameter-to-observable (PtO) map $\\boldsymbol{\\mathcal{G}}: \\mathscr{M} \\to \\mathscr{Y}$ is defined, along with its approximations $\\widetilde{\\boldsymbol{\\mathcal{G}}}$ (neural operator) and $\\boldsymbol{\\mathcal{G}}_r$ (reduced mapping). The analysis takes place in the context of $L^2_\\mu(\\mathscr{M}; \\mathscr{Y})$ error norms and the properties of Gaussian measures.", "goal": "To derive error bounds for the Derivative-Informed Neural Operator (DINO) surrogate approximation $\\|\\boldsymbol{\\mathcal{G}}-\\widetilde{\\boldsymbol{\\mathcal{G}}}\\|_{L^2_{\\mu}}$ and to prove properties regarding the independence of projected Gaussian random elements."}, "local_context": {"anchor_latex": "\\norm{\\bdmc{G}-\\bdmc{G}_r}^2_{L^2_{\\mu}(\\scrM;\\scrY)} \\leq \\text{Tr}_{\\scrH_{\\mu}}\\left((\\calI_{\\scrH_{\\mu}}-\\Psi_r\\Psi_r^*)\\calH_A(\\calI_{\\scrH_{\\mu}}-\\Psi_r\\Psi_r^*)\\right)", "gap_objective": "Bound the approximation error for the KLE reduced mapping by relating the trace term to the operator norm of the Hessian and the tail eigenvalues of the prior covariance."}}, "ground_truth": {"target_citation_key": "zahm2020gradient", "target_lemma_latex": "\\norm{\\bdmc{G}-\\bdmc{G}_r}^2_{L^2_{\\mu}(\\scrM;\\scrY)} \\leq \\norm{\\calH_A}_{B(\\scrH_{\\mu})}\\mathbb{E}_{M\\sim\\mu}\\left[\\norm{\\left(\\calI_{\\scrM}-\\Psi_r^{\\text{KLE}}{\\Psi_r^{\\text{KLE}}}^*\\right)M}_{\\scrM}^2\\right]", "target_citation_content": "Olivier Zahm, Paul~G. Constantine, Cl\\'ementine Prieur, and Youssef~M. Marzouk. \\newblock Gradient-based dimension reduction of multivariate vector-valued functions. \\newblock \\emphSIAM Journal on Scientific Computing, 42\\penalty0 (1):\\penalty0 A534--A558, 2020. \\newblock \\doi10.1137/18M1221837."}}
{"id": "2403.08220v2_gap_4", "arxiv_id": "2403.08220v2", "title": "Derivative-informed neural operator acceleration of geometric MCMC for infinite-dimensional Bayesian inverse problems", "publication_date": "2024-03-13", "problem_input": {"global_context": {"setup": "The setting involves an infinite-dimensional separable Hilbert space $\\mathscr{M}$ endowed with a Gaussian prior measure $\\mu = \\mathcal{N}(0, \\mathcal{C}_{\\text{pr}})$. A parameter-to-observable (PtO) map $\\boldsymbol{\\mathcal{G}}: \\mathscr{M} \\to \\mathscr{Y}$ is defined, along with its approximations $\\widetilde{\\boldsymbol{\\mathcal{G}}}$ (neural operator) and $\\boldsymbol{\\mathcal{G}}_r$ (reduced mapping). The analysis takes place in the context of $L^2_\\mu(\\mathscr{M}; \\mathscr{Y})$ error norms and the properties of Gaussian measures.", "goal": "To derive error bounds for the Derivative-Informed Neural Operator (DINO) surrogate approximation $\\|\\boldsymbol{\\mathcal{G}}-\\widetilde{\\boldsymbol{\\mathcal{G}}}\\|_{L^2_{\\mu}}$ and to prove properties regarding the independence of projected Gaussian random elements."}, "local_context": {"anchor_latex": "Let $M$ be a Gaussian random element in a Hilbert space $\\scrM$, denoted $M \\sim \\mathcal{N}(0, \\cpr)$, and let $\\Psi_r^*$ be a bounded linear operator.", "gap_objective": "Determine the probability distribution of the transformed random element $\\Psi_r^* M$."}}, "ground_truth": {"target_citation_key": "dapratto2002second", "target_lemma_latex": "Let $\\mu = \\mathcal{N}(m, Q)$ be a Gaussian measure on a Hilbert space $H$ and $T: H \\to K$ be a bounded linear operator. Then the image measure $\\mu \\circ T^{-1}$ is a Gaussian measure on $K$ given by $\\mathcal{N}(Tm, TQT^*)$.", "target_citation_content": "Giuseppe Da Prato and Jerzy Zabczyk. \\newblock \\emphSecond order partial differential equations in Hilbert spaces, volume 293. \\newblock Cambridge University Press, 2002."}}
{"id": "2406.02970v3_gap_0", "arxiv_id": "2406.02970v3", "title": "Which exceptional low-dimensional projections of a Gaussian point cloud can be found in polynomial time?", "publication_date": "2024-06-05", "problem_input": {"global_context": {"setup": "Let $(\\mathbf{x}_i)_{i\\le n} \\sim_{\\text{iid}} \\mathcal{N}(\\mathbf{0}, \\mathbf{I}_d)$ be independent standard Gaussian vectors. Consider the proportional asymptotic regime where $n, d \\to \\infty$ with $n/d \\to \\alpha \\in (0, \\infty)$. Let $m \\ge 1$ be fixed. Define the random optimization problem of maximizing the Hamiltonian $H_{n, d}(\\mathbf{W}) := \\frac{1}{n} \\sum_{i=1}^{n} h(\\mathbf{W}^\\top \\mathbf{x}_i)$ subject to $\\mathbf{W} \\in O(d, m)$ (the set of $d \\times m$ orthogonal matrices), where $h: \\mathbb{R}^m \\to \\mathbb{R}$ is a bounded continuous function. The feasible set $\\mathcal{F}_{m,\\alpha}$ is the set of probability distributions on $\\mathbb{R}^m$ approximable by empirical distributions of projections $\\mathbf{W}^\\top \\mathbf{x}_i$. A subset $\\mathcal{F}^{\\text{alg}}_{m,\\alpha}$ denotes distributions realizable by polynomial-time algorithms.", "goal": "Theorem 3.7: A variational formula (Parisi-type) characterizing $\\mathsf{V}^{\\text{AMP}}_{1,\\alpha}(h)$, the optimal value of the Hamiltonian achievable by a specific class of two-stage Approximate Message Passing (AMP) algorithms, in terms of a stochastic optimal control problem and its dual."}, "local_context": {"anchor_latex": "\\cuF_{m,\\alpha}:= \\Big\\{P \\in \\cuP (\\R^{m}):\\, \\exists \\WW = \\WW_n (\\XX,\\omega), \\mbox{ s.t. } \\WW^\\top \\WW = I_m, \\,\\, \\frac{1}{n} \\sum_{i=1}^{n} \\delta_{\\WW^\\top \\xx_i} \\stackrel{w}{\\Rightarrow} P\\, \\mbox{ in probability} \\Big\\}", "gap_objective": "Establish the topological property that the set of feasible distributions \\cuF_{m,\\alpha} is closed under weak convergence."}}, "ground_truth": {"target_citation_key": "montanari2022overparametrized", "target_lemma_latex": "\\cuF_{m,\\alpha} \\text{ is closed under weak convergence.}", "target_citation_content": "Andrea Montanari and Kangjie Zhou. \\newblock Overparametrized linear dimensionality reductions: From projection pursuit to two-layer neural networks. \\newblock \\em arXiv preprint arXiv:2206.06526, 2022."}}
{"id": "2406.02970v3_gap_1", "arxiv_id": "2406.02970v3", "title": "Which exceptional low-dimensional projections of a Gaussian point cloud can be found in polynomial time?", "publication_date": "2024-06-05", "problem_input": {"global_context": {"setup": "Let $(\\mathbf{x}_i)_{i\\le n} \\sim_{\\text{iid}} \\mathcal{N}(\\mathbf{0}, \\mathbf{I}_d)$ be independent standard Gaussian vectors. Consider the proportional asymptotic regime where $n, d \\to \\infty$ with $n/d \\to \\alpha \\in (0, \\infty)$. Let $m \\ge 1$ be fixed. Define the random optimization problem of maximizing the Hamiltonian $H_{n, d}(\\mathbf{W}) := \\frac{1}{n} \\sum_{i=1}^{n} h(\\mathbf{W}^\\top \\mathbf{x}_i)$ subject to $\\mathbf{W} \\in O(d, m)$ (the set of $d \\times m$ orthogonal matrices), where $h: \\mathbb{R}^m \\to \\mathbb{R}$ is a bounded continuous function. The feasible set $\\mathcal{F}_{m,\\alpha}$ is the set of probability distributions on $\\mathbb{R}^m$ approximable by empirical distributions of projections $\\mathbf{W}^\\top \\mathbf{x}_i$. A subset $\\mathcal{F}^{\\text{alg}}_{m,\\alpha}$ denotes distributions realizable by polynomial-time algorithms.", "goal": "Theorem 3.7: A variational formula (Parisi-type) characterizing $\\mathsf{V}^{\\text{AMP}}_{1,\\alpha}(h)$, the optimal value of the Hamiltonian achievable by a specific class of two-stage Approximate Message Passing (AMP) algorithms, in terms of a stochastic optimal control problem and its dual."}, "local_context": {"anchor_latex": "H_{n, d} \\left( \\WW \\right) := \\, \\frac{1}{n} \\sum_{i=1}^{n} h \\left( \\WW^\\top \\xx_i \\right), \\quad \\mbox{subject to} \\ \\WW \\in O(d, m)", "gap_objective": "To characterize the asymptotic limit of the maximum value of the random optimization problem in terms of the feasible set of distributions."}}, "ground_truth": {"target_citation_key": "montanari2022overparametrized", "target_lemma_latex": "\\pliminf_{n, d \\rightarrow \\infty} \\max_{\\WW \\in O(d, m)} H_{n,d} \\left( \\WW \\right) = \\, \\sup_{P \\in \\cuF_{m, \\alpha}} \\left\\{ \\int_{\\R^m} h(z) P(\\d z) \\right\\}", "target_citation_content": "Andrea Montanari and Kangjie Zhou. \\newblock Overparametrized linear dimensionality reductions: From projection pursuit to two-layer neural networks. \\newblock \\em arXiv preprint arXiv:2206.06526, 2022."}}
{"id": "2406.02970v3_gap_2", "arxiv_id": "2406.02970v3", "title": "Which exceptional low-dimensional projections of a Gaussian point cloud can be found in polynomial time?", "publication_date": "2024-06-05", "problem_input": {"global_context": {"setup": "Let $(\\mathbf{x}_i)_{i\\le n} \\sim_{\\text{iid}} \\mathcal{N}(\\mathbf{0}, \\mathbf{I}_d)$ be independent standard Gaussian vectors. Consider the proportional asymptotic regime where $n, d \\to \\infty$ with $n/d \\to \\alpha \\in (0, \\infty)$. Let $m \\ge 1$ be fixed. Define the random optimization problem of maximizing the Hamiltonian $H_{n, d}(\\mathbf{W}) := \\frac{1}{n} \\sum_{i=1}^{n} h(\\mathbf{W}^\\top \\mathbf{x}_i)$ subject to $\\mathbf{W} \\in O(d, m)$ (the set of $d \\times m$ orthogonal matrices), where $h: \\mathbb{R}^m \\to \\mathbb{R}$ is a bounded continuous function. The feasible set $\\mathcal{F}_{m,\\alpha}$ is the set of probability distributions on $\\mathbb{R}^m$ approximable by empirical distributions of projections $\\mathbf{W}^\\top \\mathbf{x}_i$. A subset $\\mathcal{F}^{\\text{alg}}_{m,\\alpha}$ denotes distributions realizable by polynomial-time algorithms.", "goal": "Theorem 3.7: A variational formula (Parisi-type) characterizing $\\mathsf{V}^{\\text{AMP}}_{1,\\alpha}(h)$, the optimal value of the Hamiltonian achievable by a specific class of two-stage Approximate Message Passing (AMP) algorithms, in terms of a stochastic optimal control problem and its dual."}, "local_context": {"anchor_latex": "W_t := \\int_{0}^{t} q(u) \\d B_u, \\quad s(t) := \\int_{0}^{t} q(u)^2 \\d u, \\quad s(0)=0, \\, s(1)=1", "gap_objective": "Conclude that the time-changed process \\{ W_{s^{-1} (t)} \\}_{0 \\le t \\le 1} is a standard Brownian motion"}}, "ground_truth": {"target_citation_key": "le2016brownian", "target_lemma_latex": "Let M be a continuous local martingale vanishing at 0 such that \\langle M \\rangle_{\\infty} = \\infty. Let \\tau_s = \\inf\\{ t \\ge 0 : \\langle M \\rangle_t > s \\}. Then the process (\\beta_s)_{s \\ge 0} defined by \\beta_s = M_{\\tau_s} is a standard Brownian motion.", "target_citation_content": "Jean-Fran\\ccois Le~Gall. \\newblock \\em Brownian motion, martingales, and stochastic calculus. \\newblock Springer, 2016."}}
{"id": "2406.02970v3_gap_3", "arxiv_id": "2406.02970v3", "title": "Which exceptional low-dimensional projections of a Gaussian point cloud can be found in polynomial time?", "publication_date": "2024-06-05", "problem_input": {"global_context": {"setup": "Let $(\\mathbf{x}_i)_{i\\le n} \\sim_{\\text{iid}} \\mathcal{N}(\\mathbf{0}, \\mathbf{I}_d)$ be independent standard Gaussian vectors. Consider the proportional asymptotic regime where $n, d \\to \\infty$ with $n/d \\to \\alpha \\in (0, \\infty)$. Let $m \\ge 1$ be fixed. Define the random optimization problem of maximizing the Hamiltonian $H_{n, d}(\\mathbf{W}) := \\frac{1}{n} \\sum_{i=1}^{n} h(\\mathbf{W}^\\top \\mathbf{x}_i)$ subject to $\\mathbf{W} \\in O(d, m)$ (the set of $d \\times m$ orthogonal matrices), where $h: \\mathbb{R}^m \\to \\mathbb{R}$ is a bounded continuous function. The feasible set $\\mathcal{F}_{m,\\alpha}$ is the set of probability distributions on $\\mathbb{R}^m$ approximable by empirical distributions of projections $\\mathbf{W}^\\top \\mathbf{x}_i$. A subset $\\mathcal{F}^{\\text{alg}}_{m,\\alpha}$ denotes distributions realizable by polynomial-time algorithms.", "goal": "Theorem 3.7: A variational formula (Parisi-type) characterizing $\\mathsf{V}^{\\text{AMP}}_{1,\\alpha}(h)$, the optimal value of the Hamiltonian achievable by a specific class of two-stage Approximate Message Passing (AMP) algorithms, in terms of a stochastic optimal control problem and its dual."}, "local_context": {"anchor_latex": "s(t) := \\int_{0}^{t} q(u)^2 \\d u, \\quad W_t := \\int_{0}^{t} q(u) \\d B_u, \\quad \\text{and } \\{ W_{s^{-1} (t)} \\}_{0 \\le t \\le 1} \\text{ is a standard Brownian motion}", "gap_objective": "Apply the time-change formula to the stochastic integral \\int_{0}^{1} q(t) ( 1 + \\phi_t ) \\d B_t to express it in terms of the time-changed Brownian motion"}}, "ground_truth": {"target_citation_key": "karatzas2012brownian", "target_lemma_latex": "\\int_{0}^{1} q(t) \\left( 1 + \\phi_t \\right) \\d B_t = \\int_{0}^{1} \\left( 1 + \\phi_{s^{-1} (t)} \\right) \\d W_{s^{-1} (t)}", "target_citation_content": "Ioannis Karatzas and Steven Shreve. \\newblock \\em Brownian motion and stochastic calculus, volume 113. \\newblock Springer Science \\& Business Media, 2012."}}
{"id": "2406.02970v3_gap_4", "arxiv_id": "2406.02970v3", "title": "Which exceptional low-dimensional projections of a Gaussian point cloud can be found in polynomial time?", "publication_date": "2024-06-05", "problem_input": {"global_context": {"setup": "Let $(\\mathbf{x}_i)_{i\\le n} \\sim_{\\text{iid}} \\mathcal{N}(\\mathbf{0}, \\mathbf{I}_d)$ be independent standard Gaussian vectors. Consider the proportional asymptotic regime where $n, d \\to \\infty$ with $n/d \\to \\alpha \\in (0, \\infty)$. Let $m \\ge 1$ be fixed. Define the random optimization problem of maximizing the Hamiltonian $H_{n, d}(\\mathbf{W}) := \\frac{1}{n} \\sum_{i=1}^{n} h(\\mathbf{W}^\\top \\mathbf{x}_i)$ subject to $\\mathbf{W} \\in O(d, m)$ (the set of $d \\times m$ orthogonal matrices), where $h: \\mathbb{R}^m \\to \\mathbb{R}$ is a bounded continuous function. The feasible set $\\mathcal{F}_{m,\\alpha}$ is the set of probability distributions on $\\mathbb{R}^m$ approximable by empirical distributions of projections $\\mathbf{W}^\\top \\mathbf{x}_i$. A subset $\\mathcal{F}^{\\text{alg}}_{m,\\alpha}$ denotes distributions realizable by polynomial-time algorithms.", "goal": "Theorem 3.7: A variational formula (Parisi-type) characterizing $\\mathsf{V}^{\\text{AMP}}_{1,\\alpha}(h)$, the optimal value of the Hamiltonian achievable by a specific class of two-stage Approximate Message Passing (AMP) algorithms, in terms of a stochastic optimal control problem and its dual."}, "local_context": {"anchor_latex": "\\P \\Big( \\lim_{n \\to \\infty} \\nu_n (f_u) = \\nu (f_u) \\Big) = 1, \\,\\, \\forall u\\in \\R^{mt}", "gap_objective": "\\nu_n \\stackrel{w}{\\Rightarrow} \\nu \\quad \\text{almost surely}"}}, "ground_truth": {"target_citation_key": "berti2006almost", "target_lemma_latex": "\\text{Let } D \\text{ be a determining class for weak convergence (e.g., characteristic functions). If } \\nu_n(f) \\to \\nu(f) \\text{ almost surely for every } f \\in D, \\text{ then } \\nu_n \\stackrel{w}{\\Rightarrow} \\nu \\text{ almost surely.}", "target_citation_content": "Patrizia Berti, Luca Pratelli, and Pietro Rigo. \\newblock Almost sure weak convergence of random probability measures. \\newblock \\em Stochastics and Stochastics Reports, 78(2):91--97, 2006."}}
{"id": "2406.02970v3_gap_5", "arxiv_id": "2406.02970v3", "title": "Which exceptional low-dimensional projections of a Gaussian point cloud can be found in polynomial time?", "publication_date": "2024-06-05", "problem_input": {"global_context": {"setup": "Let $(\\mathbf{x}_i)_{i\\le n} \\sim_{\\text{iid}} \\mathcal{N}(\\mathbf{0}, \\mathbf{I}_d)$ be independent standard Gaussian vectors. Consider the proportional asymptotic regime where $n, d \\to \\infty$ with $n/d \\to \\alpha \\in (0, \\infty)$. Let $m \\ge 1$ be fixed. Define the random optimization problem of maximizing the Hamiltonian $H_{n, d}(\\mathbf{W}) := \\frac{1}{n} \\sum_{i=1}^{n} h(\\mathbf{W}^\\top \\mathbf{x}_i)$ subject to $\\mathbf{W} \\in O(d, m)$ (the set of $d \\times m$ orthogonal matrices), where $h: \\mathbb{R}^m \\to \\mathbb{R}$ is a bounded continuous function. The feasible set $\\mathcal{F}_{m,\\alpha}$ is the set of probability distributions on $\\mathbb{R}^m$ approximable by empirical distributions of projections $\\mathbf{W}^\\top \\mathbf{x}_i$. A subset $\\mathcal{F}^{\\text{alg}}_{m,\\alpha}$ denotes distributions realizable by polynomial-time algorithms.", "goal": "Theorem 3.7: A variational formula (Parisi-type) characterizing $\\mathsf{V}^{\\text{AMP}}_{1,\\alpha}(h)$, the optimal value of the Hamiltonian achievable by a specific class of two-stage Approximate Message Passing (AMP) algorithms, in terms of a stochastic optimal control problem and its dual."}, "local_context": {"anchor_latex": "\\psi_{H} (t) = \\psi(A + tH)", "gap_objective": "Compute the derivative of the function \\psi_{H}(t) with respect to t to show monotonicity."}}, "ground_truth": {"target_citation_key": "talagrand2010mean", "target_lemma_latex": "\\frac{d}{dt} \\mathbb{E} F(X_t) = \\frac{1}{2} \\sum_{i,j} \\frac{d C_{ij}(t)}{dt} \\mathbb{E} \\frac{\\partial^2 F}{\\partial x_i \\partial x_j}(X_t)", "target_citation_content": "Michel Talagrand. \\newblock \\em Mean field models for spin glasses: Volume I: Basic examples, volume~54. \\newblock Springer Science \\& Business Media, 2010."}}
{"id": "2406.02970v3_gap_6", "arxiv_id": "2406.02970v3", "title": "Which exceptional low-dimensional projections of a Gaussian point cloud can be found in polynomial time?", "publication_date": "2024-06-05", "problem_input": {"global_context": {"setup": "Let $(\\mathbf{x}_i)_{i\\le n} \\sim_{\\text{iid}} \\mathcal{N}(\\mathbf{0}, \\mathbf{I}_d)$ be independent standard Gaussian vectors. Consider the proportional asymptotic regime where $n, d \\to \\infty$ with $n/d \\to \\alpha \\in (0, \\infty)$. Let $m \\ge 1$ be fixed. Define the random optimization problem of maximizing the Hamiltonian $H_{n, d}(\\mathbf{W}) := \\frac{1}{n} \\sum_{i=1}^{n} h(\\mathbf{W}^\\top \\mathbf{x}_i)$ subject to $\\mathbf{W} \\in O(d, m)$ (the set of $d \\times m$ orthogonal matrices), where $h: \\mathbb{R}^m \\to \\mathbb{R}$ is a bounded continuous function. The feasible set $\\mathcal{F}_{m,\\alpha}$ is the set of probability distributions on $\\mathbb{R}^m$ approximable by empirical distributions of projections $\\mathbf{W}^\\top \\mathbf{x}_i$. A subset $\\mathcal{F}^{\\text{alg}}_{m,\\alpha}$ denotes distributions realizable by polynomial-time algorithms.", "goal": "Theorem 3.7: A variational formula (Parisi-type) characterizing $\\mathsf{V}^{\\text{AMP}}_{1,\\alpha}(h)$, the optimal value of the Hamiltonian achievable by a specific class of two-stage Approximate Message Passing (AMP) algorithms, in terms of a stochastic optimal control problem and its dual."}, "local_context": {"anchor_latex": "X_t^M = q(t) (1 + \\phi_t^M) \\text{ is a bounded and progressively measurable stochastic process.}", "gap_objective": "Approximate the process $X_t^M$ in the $L^2([0, 1] \\times \\Omega)$ norm using a sequence of simple adapted processes."}}, "ground_truth": {"target_citation_key": "karatzas2012brownian", "target_lemma_latex": "\\text{Any bounded, progressively measurable process } X \\text{ can be arbitrarily approximated in } L^2([0, 1] \\times \\Omega) \\text{ by a sequence of simple adapted processes.}", "target_citation_content": "Ioannis Karatzas and Steven Shreve. \\newblock \\em Brownian motion and stochastic calculus, volume 113. \\newblock Springer Science \\& Business Media, 2012."}}
{"id": "2406.05811v2_gap_1", "arxiv_id": "2406.05811v2", "title": "Generalized Linear Spectral Statistics of High-dimensional Sample Covariance Matrices and Its Applications", "publication_date": "2024-06-09", "problem_input": {"global_context": {"setup": "Consider a sequence of $p \\times n$ random matrices $X_n = (x_{ij})$ consisting of independent and identically distributed (i.i.d.) complex random variables with mean 0 and variance 1. Let $\\Sigma_n$ be a deterministic $p \\times p$ Hermitian nonnegative definite matrix (population covariance). Define the sample covariance matrix as $S_n = \\frac{1}{n} \\Sigma_n^{1/2} X_n X_n^* \\Sigma_n^{1/2}$. Assume that the dimension $p$ and sample size $n$ grow to infinity such that $p/n \\to c \\in (0, \\infty)$.", "goal": "To establish the Central Limit Theorem (CLT) for general linear spectral statistics (GLSS) associated with the eigenvectors and eigenvalues of the sample covariance matrix $S_n$, specifically analyzing terms involving the resolvent matrix."}, "local_context": {"anchor_latex": "\\|\\mathbf{S}_n\\|_2", "gap_objective": "is bounded almost surely for all large n"}}, "ground_truth": {"target_citation_key": "Bai:2010", "target_lemma_latex": "\\limsup_{n \\to \\infty} \\|\\mathbf{S}_n\\| < \\infty \\quad \\text{a.s.}", "target_citation_content": "\\beginbbook[author] \\bauthor\\bsnmBai,~\\bfnmZ.~D.\\binitsZ.~D. \\AND \\bauthor\\bsnmSilverstein,~\\bfnmJack~W.\\binitsJ.~W. (\\byear2010). \\btitle\\textitSpectral Analysis of Large Dimensional Random Matrices. Second Edtion. \\endbbook \\endbibitem"}}
{"id": "2406.05811v2_gap_2", "arxiv_id": "2406.05811v2", "title": "Generalized Linear Spectral Statistics of High-dimensional Sample Covariance Matrices and Its Applications", "publication_date": "2024-06-09", "problem_input": {"global_context": {"setup": "Consider a sequence of $p \\times n$ random matrices $X_n = (x_{ij})$ consisting of independent and identically distributed (i.i.d.) complex random variables with mean 0 and variance 1. Let $\\Sigma_n$ be a deterministic $p \\times p$ Hermitian nonnegative definite matrix (population covariance). Define the sample covariance matrix as $S_n = \\frac{1}{n} \\Sigma_n^{1/2} X_n X_n^* \\Sigma_n^{1/2}$. Assume that the dimension $p$ and sample size $n$ grow to infinity such that $p/n \\to c \\in (0, \\infty)$.", "goal": "To establish the Central Limit Theorem (CLT) for general linear spectral statistics (GLSS) associated with the eigenvectors and eigenvalues of the sample covariance matrix $S_n$, specifically analyzing terms involving the resolvent matrix."}, "local_context": {"anchor_latex": "employing the resolvent identity and the martingale decomposition technique utilized in [Pan:2008] to handle the trace terms", "gap_objective": "Bound the moments of the trace of the resolvent using the martingale decomposition method"}}, "ground_truth": {"target_citation_key": "Pan:2008", "target_lemma_latex": "\\mathbb{E}\\left|\\text{tr}(\\mathbf{R}) - \\mathbb{E}[\\text{tr}(\\mathbf{R})]\\right|^p \\le C_p", "target_citation_content": "\\beginbarticle[author] \\bauthor\\bsnmPan,~\\bfnmG.~M.\\binitsG.~M. \\AND \\bauthor\\bsnmZhou,~\\bfnmW.\\binitsW. (\\byear2008). \\btitleCentral limit theorem for signal-to-interference ratio of reduced rank linear receiver. \\bjournal\\textitThe Annals of Applied Probability \\bvolume18 \\bpages1232 -- 1270. \\endbarticle \\endbibitem"}}
{"id": "2406.05811v2_gap_3", "arxiv_id": "2406.05811v2", "title": "Generalized Linear Spectral Statistics of High-dimensional Sample Covariance Matrices and Its Applications", "publication_date": "2024-06-09", "problem_input": {"global_context": {"setup": "Consider a sequence of $p \\times n$ random matrices $X_n = (x_{ij})$ consisting of independent and identically distributed (i.i.d.) complex random variables with mean 0 and variance 1. Let $\\Sigma_n$ be a deterministic $p \\times p$ Hermitian nonnegative definite matrix (population covariance). Define the sample covariance matrix as $S_n = \\frac{1}{n} \\Sigma_n^{1/2} X_n X_n^* \\Sigma_n^{1/2}$. Assume that the dimension $p$ and sample size $n$ grow to infinity such that $p/n \\to c \\in (0, \\infty)$.", "goal": "To establish the Central Limit Theorem (CLT) for general linear spectral statistics (GLSS) associated with the eigenvectors and eigenvalues of the sample covariance matrix $S_n$, specifically analyzing terms involving the resolvent matrix."}, "local_context": {"anchor_latex": "Using the truncation argument as in Lemma 1 of", "gap_objective": "replace the entries with truncated variables without altering the limit"}}, "ground_truth": {"target_citation_key": "Yin:1988", "target_lemma_latex": "|\\lambda_k(A) - \\lambda_k(B)| \\le \\|A - B\\|", "target_citation_content": "\\beginbarticle[author] \\bauthor\\bsnmYin,~\\bfnmY.~Q.\\binitsY.~Q., \\bauthor\\bsnmBai,~\\bfnmZ.~D.\\binitsZ.~D. \\AND \\bauthor\\bsnmKrishnaiah,~\\bfnmParuchuri~R.\\binitsP.~R. (\\byear1988). \\btitleOn the limit of the largest eigenvalue of the large dimensional sample covariance matrix. \\bjournal\\textitProbability Theory and Related Fields \\bvolume78 \\bpages509-521. \\endbarticle \\endbibitem"}}
{"id": "2406.05811v2_gap_4", "arxiv_id": "2406.05811v2", "title": "Generalized Linear Spectral Statistics of High-dimensional Sample Covariance Matrices and Its Applications", "publication_date": "2024-06-09", "problem_input": {"global_context": {"setup": "Consider a sequence of $p \\times n$ random matrices $X_n = (x_{ij})$ consisting of independent and identically distributed (i.i.d.) complex random variables with mean 0 and variance 1. Let $\\Sigma_n$ be a deterministic $p \\times p$ Hermitian nonnegative definite matrix (population covariance). Define the sample covariance matrix as $S_n = \\frac{1}{n} \\Sigma_n^{1/2} X_n X_n^* \\Sigma_n^{1/2}$. Assume that the dimension $p$ and sample size $n$ grow to infinity such that $p/n \\to c \\in (0, \\infty)$.", "goal": "To establish the Central Limit Theorem (CLT) for general linear spectral statistics (GLSS) associated with the eigenvectors and eigenvalues of the sample covariance matrix $S_n$, specifically analyzing terms involving the resolvent matrix."}, "local_context": {"anchor_latex": "\\text{estimates for the moments of quadratic forms involving the inverse of the covariance matrix}", "gap_objective": "Bound the moments of quadratic forms of the type $x^T A x$, specifically involving the inverse covariance matrix."}}, "ground_truth": {"target_citation_key": "Bai:2009", "target_lemma_latex": "E|\\mathbf{x}^* A \\mathbf{x} - \\text{tr}A|^p \\le C_p \\left[ (\\text{tr}(AA^*))^{p/2} E|x_1|^4 + E|x_1|^{2p} \\text{tr}((AA^*)^{p/2}) \\right]", "target_citation_content": "\\beginbarticle[author] \\bauthor\\bsnmBai,~\\bfnmZhidong\\binitsZ., \\bauthor\\bsnmJiang,~\\bfnmDandan\\binitsD., \\bauthor\\bsnmYao,~\\bfnmJian-Feng\\binitsJ.-F. \\AND \\bauthor\\bsnmZheng,~\\bfnmShurong\\binitsS. (\\byear2009). \\btitleCorrections to LRT on large-dimensional covariance matrix by RMT. \\bjournal\\textitThe Annals of Statistics \\bvolume37 \\bpages3822 -- 3840. \\endbarticle \\endbibitem"}}
{"id": "2506.11509v2_gap_0", "arxiv_id": "2506.11509v2", "title": "A Two-step Estimating Approach for Heavy-tailed AR Models with Non-zero Median GARCH-type Noises", "publication_date": "2025-06-13", "problem_input": {"global_context": {"setup": "The paper considers an AR(p) model $y_t=\\mu_0+\\sum_{j=1}^{p}{\\phi_{j0} y_{t-j}}+\\varepsilon_{t}$, where the noise $\\varepsilon_{t}=\\eta_{t}\\sigma_{t}$ involves time-varying volatility $\\sigma_{t}=\\sigma(t/n, \\mathcal{F}_{t-1})$ and i.i.d. innovations $\\eta_t$. A key feature is the non-zero median assumption, where $P(\\eta_{t}\\le 0)=\\tau_0$ for some unknown $\\tau_0 \\in (0,1)$. The volatility function $\\sigma(\\cdot)$ allows for non-stationarity. The parameters $\\theta_0 = (\\mu_0, \\phi_{10}, \\dots, \\phi_{p0})^\\top$ and the quantile level $\\tau_0$ are unknown. A two-step estimation procedure is proposed: first calculating the self-weighted quantile regression estimator (SQE) $\\hat{\\theta}_{n}(\\tau)$ for $\\tau \\in (0,1)$, and then estimating $\\tau_0$ by minimizing a moment-based criterion involving weights $\\tilde{w}_{lt}$.", "goal": "To establish the asymptotic normality of the estimated quantile level $\\hat{\\tau}_n$ and the resulting feasible AR parameter estimator $\\hat{\\theta}_n = \\hat{\\theta}_n(\\hat{\\tau}_n)$."}, "local_context": {"anchor_latex": "\\{T_n(\\tau)-ET_n(\\tau)\\}_{\\tau \\in \\mathcal{T}} \\rightsquigarrow T_0(\\tau)", "gap_objective": "Derive the weak convergence of the estimator process \\sqrt{n}(\\hat{\\theta}_n(\\tau)-\\theta_0(\\tau)) from the convergence of the score process using the convexity of the loss function."}}, "ground_truth": {"target_citation_key": "kato2009", "target_lemma_latex": "\\text{If } L_n(\\cdot, \\tau) \\text{ are convex processes converging weakly to } L(\\cdot, \\tau), \\text{ then } \\underset{u}{\\text{argmin }} L_n(u, \\tau) \\rightsquigarrow \\underset{u}{\\text{argmin }} L(u, \\tau) \\text{ in } \\ell^\\infty(\\mathcal{T}).", "target_citation_content": "\\textscKato, K. (2009). Asymptotics for argmin processes: Convexity arguments. \\em J. Multivar. Anal. \\bf 100 1816--1829."}}
{"id": "2506.11509v2_gap_1", "arxiv_id": "2506.11509v2", "title": "A Two-step Estimating Approach for Heavy-tailed AR Models with Non-zero Median GARCH-type Noises", "publication_date": "2025-06-13", "problem_input": {"global_context": {"setup": "The paper considers an AR(p) model $y_t=\\mu_0+\\sum_{j=1}^{p}{\\phi_{j0} y_{t-j}}+\\varepsilon_{t}$, where the noise $\\varepsilon_{t}=\\eta_{t}\\sigma_{t}$ involves time-varying volatility $\\sigma_{t}=\\sigma(t/n, \\mathcal{F}_{t-1})$ and i.i.d. innovations $\\eta_t$. A key feature is the non-zero median assumption, where $P(\\eta_{t}\\le 0)=\\tau_0$ for some unknown $\\tau_0 \\in (0,1)$. The volatility function $\\sigma(\\cdot)$ allows for non-stationarity. The parameters $\\theta_0 = (\\mu_0, \\phi_{10}, \\dots, \\phi_{p0})^\\top$ and the quantile level $\\tau_0$ are unknown. A two-step estimation procedure is proposed: first calculating the self-weighted quantile regression estimator (SQE) $\\hat{\\theta}_{n}(\\tau)$ for $\\tau \\in (0,1)$, and then estimating $\\tau_0$ by minimizing a moment-based criterion involving weights $\\tilde{w}_{lt}$.", "goal": "To establish the asymptotic normality of the estimated quantile level $\\hat{\\tau}_n$ and the resulting feasible AR parameter estimator $\\hat{\\theta}_n = \\hat{\\theta}_n(\\hat{\\tau}_n)$."}, "local_context": {"anchor_latex": "E[\\tilde{w}_0(s,{Y}^{\\top}_{t-1}(s))\\psi_{\\tau}(y_t(s)-Z^{\\top}_{t-1}(s){\\theta}_0(\\tau))\\vert \\{y_{t-1}(s),\\cdots,y_{t-\\tilde{p}(\\tau)}(s)\\}]\\neq 0", "gap_objective": "To transform the non-zero conditional expectation condition into a non-zero unconditional moment condition using a specific class of weighting functions (power series), ensuring the identifiability of the parameter."}}, "ground_truth": {"target_citation_key": "bierens1982", "target_lemma_latex": "\\int_{0}^{1} E\\Big\\{\\tilde{w}_{1t}(\\tau,s)\\psi_{\\tau}(y_t(s)-Z^{\\top}_{t-1}(s){\\theta}_0(\\tau))  \\Big\\} ds\\neq 0", "target_citation_content": "\\textscBierens, H. J. (1982). Consistent model specification tests. \\em J. Econometrics \\bf 20 105--134."}}
{"id": "2506.11509v2_gap_2", "arxiv_id": "2506.11509v2", "title": "A Two-step Estimating Approach for Heavy-tailed AR Models with Non-zero Median GARCH-type Noises", "publication_date": "2025-06-13", "problem_input": {"global_context": {"setup": "The paper considers an AR(p) model $y_t=\\mu_0+\\sum_{j=1}^{p}{\\phi_{j0} y_{t-j}}+\\varepsilon_{t}$, where the noise $\\varepsilon_{t}=\\eta_{t}\\sigma_{t}$ involves time-varying volatility $\\sigma_{t}=\\sigma(t/n, \\mathcal{F}_{t-1})$ and i.i.d. innovations $\\eta_t$. A key feature is the non-zero median assumption, where $P(\\eta_{t}\\le 0)=\\tau_0$ for some unknown $\\tau_0 \\in (0,1)$. The volatility function $\\sigma(\\cdot)$ allows for non-stationarity. The parameters $\\theta_0 = (\\mu_0, \\phi_{10}, \\dots, \\phi_{p0})^\\top$ and the quantile level $\\tau_0$ are unknown. A two-step estimation procedure is proposed: first calculating the self-weighted quantile regression estimator (SQE) $\\hat{\\theta}_{n}(\\tau)$ for $\\tau \\in (0,1)$, and then estimating $\\tau_0$ by minimizing a moment-based criterion involving weights $\\tilde{w}_{lt}$.", "goal": "To establish the asymptotic normality of the estimated quantile level $\\hat{\\tau}_n$ and the resulting feasible AR parameter estimator $\\hat{\\theta}_n = \\hat{\\theta}_n(\\hat{\\tau}_n)$."}, "local_context": {"anchor_latex": "\\sum_{l=1}^{L}{\\Big[\\frac{1}{\\sqrt{n}}\\sum_{t=p+1}^{n}{r_t\\Big(\\tau_0+\\frac{v}{\\sqrt{n}};\\tilde{w}_l\\Big)}\\Big]^2}\\rightsquigarrow \\sum_{l=1}^{L}{\\Big[\\frac{\\partial \\tilde{g}(\\tau_{0};\\tilde{w}_l)}{\\partial \\tau}v+\\tilde{S}_0(\\tau_{0};\\tilde{w}_l)  \\Big]^2}", "gap_objective": "Derive the asymptotic distribution of the estimator \\sqrt{n}(\\hat{\\tau}_n-\\tau_{0}) by showing that the minimizer of the finite-sample objective function converges to the minimizer of the limiting Gaussian process."}}, "ground_truth": {"target_citation_key": "van1996", "target_lemma_latex": "M_n \\rightsquigarrow M \\text{ in } \\ell^{\\infty}(K) \\text{ for every compact } K, \\text{ and } \\hat{h}_n \\text{ is uniformly tight with } M_n(\\hat{h}_n) \\geq \\sup_h M_n(h) - o_p(1) \\implies \\hat{h}_n \\rightsquigarrow \\operatorname{argmax} M", "target_citation_content": "\\textscvan der Vaart, A. W. and \\textscWellner, J. A. (1996). \\em Weak Convergence and Empirical Processes. NewYork: Springer Verlag."}}
{"id": "2407.19613v1_gap_0", "arxiv_id": "2407.19613v1", "title": "Causal effect estimation under network interference with mean-field methods", "publication_date": "2024-07-28", "problem_input": {"global_context": {"setup": "The study considers $n$ units with binary treatments $\\mathbf{t} \\in \\{\\pm 1\\}^n$, covariates $\\mathbf{X}_i \\in [-1,1]^d$, and outcomes $Y_i \\in [-1,1]$. The potential outcomes follow a Markov Random Field model: $f(\\mathbf{y}|\\mathbf{t},\\mathbf{x}) \\propto \\exp\\Big(\\frac{1}{2}\\,\\mathbf{y}^\\top \\mathbf{A}_n \\mathbf{y}+ \\mathbf{y}^\\top (\\tau_0 \\mathbf{t}+ \\mathbf{x} \\btheta_0) \\Big) \\prod_{i=1}^{n}d\\mu (y_i)$, where $\\mathbf{A}_n$ is a known symmetric interaction matrix. Treatments are assigned via a propensity score model $\\bP(\\mathbf{T} = \\mathbf{t} |\\mathbf{x}) \\propto \\exp \\Big(\\frac{1}{2}\\mathbf{t}^\\top \\mathbf{M}_n \\mathbf{t} + \\sum_{i=1}^n t_i \\mathbf{x}^\\top_i \\boldsymbol{\\gamma}_0 \\Big)$. The goal is to estimate the Average Direct Effect (DE) and Indirect Effect (IE) defined by averaging potential outcome differences over a uniform allocation distribution. Two regimes for $\\mathbf{A}_n$ are considered: 'mean-field' matrices where $\\mathrm{Tr}(\\mathbf{A}_n^2)=o(n)$, and Gaussian interaction matrices (Sherrington-Kirkpatrick model).", "goal": " Theorems 2.1 and 2.3: Establish that the proposed iterative algorithms (Mean-field Algorithm 1 and AMP Algorithm 2) provide consistent estimators for DE and IE under high-temperature conditions (bounded operator norm or small $\\beta$). Theorem 2.4: Establish $\\sqrt{n}$-consistency of the maximum pseudo-likelihood estimator for the parameters $(\\tau_0, \\btheta_0)$."}, "local_context": {"anchor_latex": "\\mathbf{A}_n(i,j) \\sim \\mathcal{N}(0, \\beta^2/n) \\text{ i.i.d. for } i<j, \\mathbf{A}_n(i,i)=0, \\text{ and } \\mathbf{A}_n = \\beta \\mathbf{G}_n", "gap_objective": "Determine the asymptotic limit of the operator norm $\\| \\mathbf{G}_n \\|$ as $n \\to \\infty$."}}, "ground_truth": {"target_citation_key": "bai2010spectral", "target_lemma_latex": "\\| \\mathbf{G}_n \\| \\to 2 \\text{ a.s.}", "target_citation_content": "Zhidong Bai and Jack~W Silverstein. \\newblock \\emphSpectral analysis of large dimensional random matrices, volume~20. \\newblock Springer, 2010."}}
{"id": "2407.19613v1_gap_1", "arxiv_id": "2407.19613v1", "title": "Causal effect estimation under network interference with mean-field methods", "publication_date": "2024-07-28", "problem_input": {"global_context": {"setup": "The study considers $n$ units with binary treatments $\\mathbf{t} \\in \\{\\pm 1\\}^n$, covariates $\\mathbf{X}_i \\in [-1,1]^d$, and outcomes $Y_i \\in [-1,1]$. The potential outcomes follow a Markov Random Field model: $f(\\mathbf{y}|\\mathbf{t},\\mathbf{x}) \\propto \\exp\\Big(\\frac{1}{2}\\,\\mathbf{y}^\\top \\mathbf{A}_n \\mathbf{y}+ \\mathbf{y}^\\top (\\tau_0 \\mathbf{t}+ \\mathbf{x} \\btheta_0) \\Big) \\prod_{i=1}^{n}d\\mu (y_i)$, where $\\mathbf{A}_n$ is a known symmetric interaction matrix. Treatments are assigned via a propensity score model $\\bP(\\mathbf{T} = \\mathbf{t} |\\mathbf{x}) \\propto \\exp \\Big(\\frac{1}{2}\\mathbf{t}^\\top \\mathbf{M}_n \\mathbf{t} + \\sum_{i=1}^n t_i \\mathbf{x}^\\top_i \\boldsymbol{\\gamma}_0 \\Big)$. The goal is to estimate the Average Direct Effect (DE) and Indirect Effect (IE) defined by averaging potential outcome differences over a uniform allocation distribution. Two regimes for $\\mathbf{A}_n$ are considered: 'mean-field' matrices where $\\mathrm{Tr}(\\mathbf{A}_n^2)=o(n)$, and Gaussian interaction matrices (Sherrington-Kirkpatrick model).", "goal": " Theorems 2.1 and 2.3: Establish that the proposed iterative algorithms (Mean-field Algorithm 1 and AMP Algorithm 2) provide consistent estimators for DE and IE under high-temperature conditions (bounded operator norm or small $\\beta$). Theorem 2.4: Establish $\\sqrt{n}$-consistency of the maximum pseudo-likelihood estimator for the parameters $(\\tau_0, \\btheta_0)$."}, "local_context": {"anchor_latex": "\\tilde{\\mu}= p \\delta_{1}+ (1-p)\\delta_{-1}, \\quad p \\in (0,1)", "gap_objective": "Establish that the Log Sobolev Inequality (LSI) holds for the two-point measure $\\tilde{\\mu}$."}}, "ground_truth": {"target_citation_key": "latala2000between", "target_lemma_latex": "\\text{LSI holds for } \\tilde{\\mu} = p \\delta_{1}+ (1-p)\\delta_{-1}", "target_citation_content": "Rafa\\l Lata\\la and Krzysztof Oleszkiewicz. \\newblock Between sobolev and poincaré. \\newblock In \\emphGeometric Aspects of Functional Analysis: Israel Seminar 1996--2000, pages 147--168. Springer, 2000."}}
{"id": "2407.19613v1_gap_2", "arxiv_id": "2407.19613v1", "title": "Causal effect estimation under network interference with mean-field methods", "publication_date": "2024-07-28", "problem_input": {"global_context": {"setup": "The study considers $n$ units with binary treatments $\\mathbf{t} \\in \\{\\pm 1\\}^n$, covariates $\\mathbf{X}_i \\in [-1,1]^d$, and outcomes $Y_i \\in [-1,1]$. The potential outcomes follow a Markov Random Field model: $f(\\mathbf{y}|\\mathbf{t},\\mathbf{x}) \\propto \\exp\\Big(\\frac{1}{2}\\,\\mathbf{y}^\\top \\mathbf{A}_n \\mathbf{y}+ \\mathbf{y}^\\top (\\tau_0 \\mathbf{t}+ \\mathbf{x} \\btheta_0) \\Big) \\prod_{i=1}^{n}d\\mu (y_i)$, where $\\mathbf{A}_n$ is a known symmetric interaction matrix. Treatments are assigned via a propensity score model $\\bP(\\mathbf{T} = \\mathbf{t} |\\mathbf{x}) \\propto \\exp \\Big(\\frac{1}{2}\\mathbf{t}^\\top \\mathbf{M}_n \\mathbf{t} + \\sum_{i=1}^n t_i \\mathbf{x}^\\top_i \\boldsymbol{\\gamma}_0 \\Big)$. The goal is to estimate the Average Direct Effect (DE) and Indirect Effect (IE) defined by averaging potential outcome differences over a uniform allocation distribution. Two regimes for $\\mathbf{A}_n$ are considered: 'mean-field' matrices where $\\mathrm{Tr}(\\mathbf{A}_n^2)=o(n)$, and Gaussian interaction matrices (Sherrington-Kirkpatrick model).", "goal": " Theorems 2.1 and 2.3: Establish that the proposed iterative algorithms (Mean-field Algorithm 1 and AMP Algorithm 2) provide consistent estimators for DE and IE under high-temperature conditions (bounded operator norm or small $\\beta$). Theorem 2.4: Establish $\\sqrt{n}$-consistency of the maximum pseudo-likelihood estimator for the parameters $(\\tau_0, \\btheta_0)$."}, "local_context": {"anchor_latex": "\\tilde \\mu \\text{ is the uniform measure on a compact interval}", "gap_objective": "Prove that \\tilde \\mu satisfies the Log Sobolev Inequality (LSI)."}}, "ground_truth": {"target_citation_key": "ghang2014sharp", "target_lemma_latex": "\\text{The uniform measure on a compact interval satisfies the Log Sobolev Inequality (LSI).}", "target_citation_content": "Whan Ghang, Zane Martin, and Steven Waruhiu. \\newblock The sharp log-sobolev inequality on a compact interval. \\newblock \\emphInvolve, 7:\\penalty0 181--186, 2014."}}
{"id": "2406.17069v2_gap_0", "arxiv_id": "2406.17069v2", "title": "Large Deviations of the Schwarzian Field Theory", "publication_date": "2024-06-24", "problem_input": {"global_context": {"setup": "The paper investigates the probabilistic Schwarzian Field Theory, defined via a finite measure $\\mathscr{M}_{\\sigma^2}$ on the quotient space $\\text{Diff}^1(\\mathbb{T})/\\text{PSL}(2, \\mathbb{R})$. This measure is constructed as the push-forward of a Brownian bridge measure $\\mathcal{W}_{\\sigma^2}^{0,1}$ under a specific map $\\mathsf{P}$ involving the exponential integral. The theory involves the 'action' functional $\\mathcal{I}(\\phi) = - \\int_{0}^{1} [\\mathcal{S}_\\phi(\\tau)+2\\pi^2\\phi'^{\\, 2}(\\tau)] d\\tau$ involving the Schwarzian derivative $\\mathcal{S}_\\phi$.", "goal": "To prove that the family of measures $\\{\\mathscr{M}_{\\sigma^2}\\}_{\\sigma>0}$ satisfies the Large Deviations Principle (LDP) as $\\sigma \\to 0$ with the good rate function $\\mathcal{I}(\\cdot)$, and to characterize the minimizers of this action."}, "local_context": {"anchor_latex": "v(t) \\text{ is a solution to the Sturm-Liouville problem } -F''(t)+q(t+a)F(t) = 0 \\text{ with } F(0)=F(1)=0, \\text{ and } v(t)\\neq 0 \\text{ for } t\\in(0, 1)", "gap_objective": "Deduce that the eigenvalue \\lambda=0 associated with v is the smallest eigenvalue (ground state)."}}, "ground_truth": {"target_citation_key": "ODEHartman", "target_lemma_latex": "The eigenfunctions u_n of a Sturm-Liouville problem corresponding to eigenvalues \\lambda_0 < \\lambda_1 < \\dots have exactly n zeros in the open interval.", "target_citation_content": "P.~Hartman. \\newblock \\emphOrdinary Differential Equations. \\newblock Society for Industrial and Applied Mathematics, second edition, 2002."}}
{"id": "2406.17069v2_gap_1", "arxiv_id": "2406.17069v2", "title": "Large Deviations of the Schwarzian Field Theory", "publication_date": "2024-06-24", "problem_input": {"global_context": {"setup": "The paper investigates the probabilistic Schwarzian Field Theory, defined via a finite measure $\\mathscr{M}_{\\sigma^2}$ on the quotient space $\\text{Diff}^1(\\mathbb{T})/\\text{PSL}(2, \\mathbb{R})$. This measure is constructed as the push-forward of a Brownian bridge measure $\\mathcal{W}_{\\sigma^2}^{0,1}$ under a specific map $\\mathsf{P}$ involving the exponential integral. The theory involves the 'action' functional $\\mathcal{I}(\\phi) = - \\int_{0}^{1} [\\mathcal{S}_\\phi(\\tau)+2\\pi^2\\phi'^{\\, 2}(\\tau)] d\\tau$ involving the Schwarzian derivative $\\mathcal{S}_\\phi$.", "goal": "To prove that the family of measures $\\{\\mathscr{M}_{\\sigma^2}\\}_{\\sigma>0}$ satisfies the Large Deviations Principle (LDP) as $\\sigma \\to 0$ with the good rate function $\\mathcal{I}(\\cdot)$, and to characterize the minimizers of this action."}, "local_context": {"anchor_latex": "\\lambda = 0 \\text{ is the lowest eigenvalue for the Sturm-Liouville problem } -F''(t)+q(t+a)F(t) = \\lambda F(t) \\text{ with } F(0)=F(1)=0", "gap_objective": "Relate the lowest eigenvalue to the minimum of the corresponding energy functional (Rayleigh quotient)"}}, "ground_truth": {"target_citation_key": "bookSturmLiouville", "target_lemma_latex": "\\lambda_1 = \\inf_{\\substack{u \\neq 0 \\\\ u(0)=u(1)=0}} \\frac{\\int_0^1 (u'^{\\, 2} + q u^2) \\d t}{\\int_0^1 u^2 \\d t}", "target_citation_content": "H.~F. Weinberger. \\newblock \\emphA First Course in Partial Differential Equations with Complex Variables and Transform Methods. \\newblock 1965. \\newblock ISBN 9780486686400."}}
{"id": "2406.17069v2_gap_2", "arxiv_id": "2406.17069v2", "title": "Large Deviations of the Schwarzian Field Theory", "publication_date": "2024-06-24", "problem_input": {"global_context": {"setup": "The paper investigates the probabilistic Schwarzian Field Theory, defined via a finite measure $\\mathscr{M}_{\\sigma^2}$ on the quotient space $\\text{Diff}^1(\\mathbb{T})/\\text{PSL}(2, \\mathbb{R})$. This measure is constructed as the push-forward of a Brownian bridge measure $\\mathcal{W}_{\\sigma^2}^{0,1}$ under a specific map $\\mathsf{P}$ involving the exponential integral. The theory involves the 'action' functional $\\mathcal{I}(\\phi) = - \\int_{0}^{1} [\\mathcal{S}_\\phi(\\tau)+2\\pi^2\\phi'^{\\, 2}(\\tau)] d\\tau$ involving the Schwarzian derivative $\\mathcal{S}_\\phi$.", "goal": "To prove that the family of measures $\\{\\mathscr{M}_{\\sigma^2}\\}_{\\sigma>0}$ satisfies the Large Deviations Principle (LDP) as $\\sigma \\to 0$ with the good rate function $\\mathcal{I}(\\cdot)$, and to characterize the minimizers of this action."}, "local_context": {"anchor_latex": "\\text{The sets } \\Psi(\\alpha) \\text{ are closed, which follows from the continuity of } \\int_{\\T} \\phi'^{\\, 2}(\\tau)\\d\\tau \\text{ on } \\Diff^1(\\T)", "gap_objective": "\\text{Establish the lower semicontinuity of the remaining term in the action } \\I(\\phi), \\text{ specifically } \\int_{\\T} |(\\log \\phi')'|^2 \\d\\tau"}}, "ground_truth": {"target_citation_key": "bookLDP", "target_lemma_latex": "\\text{The functional } f \\mapsto \\int_{\\T} |f'(\\tau)|^2\\d\\tau \\text{ is lower semicontinuous on } C[0,1]", "target_citation_content": "A.~Dembo and O.~Zeitouni. \\newblock \\emphLarge Deviations Techniques and Applications. \\newblock 1 2009. \\newblock ISBN 978-3-642-03311-7."}}
{"id": "2406.17069v2_gap_3", "arxiv_id": "2406.17069v2", "title": "Large Deviations of the Schwarzian Field Theory", "publication_date": "2024-06-24", "problem_input": {"global_context": {"setup": "The paper investigates the probabilistic Schwarzian Field Theory, defined via a finite measure $\\mathscr{M}_{\\sigma^2}$ on the quotient space $\\text{Diff}^1(\\mathbb{T})/\\text{PSL}(2, \\mathbb{R})$. This measure is constructed as the push-forward of a Brownian bridge measure $\\mathcal{W}_{\\sigma^2}^{0,1}$ under a specific map $\\mathsf{P}$ involving the exponential integral. The theory involves the 'action' functional $\\mathcal{I}(\\phi) = - \\int_{0}^{1} [\\mathcal{S}_\\phi(\\tau)+2\\pi^2\\phi'^{\\, 2}(\\tau)] d\\tau$ involving the Schwarzian derivative $\\mathcal{S}_\\phi$.", "goal": "To prove that the family of measures $\\{\\mathscr{M}_{\\sigma^2}\\}_{\\sigma>0}$ satisfies the Large Deviations Principle (LDP) as $\\sigma \\to 0$ with the good rate function $\\mathcal{I}(\\cdot)$, and to characterize the minimizers of this action."}, "local_context": {"anchor_latex": "\\FMeas{\\sigma^2}(U) =\\frac{1}{\\sqrt{2\\pi}\\sigma} \n\\int_{C[0, 1]}\n\\exp\\left\\{ \\frac{1}{\\sigma^2}F(\\xi)\\right\\}\n\\d\\WS{\\sigma^2}{0}{1}(\\xi)", "gap_objective": "Establish the Large Deviations Principle for the underlying Brownian bridge measure to facilitate the asymptotic analysis of the integral via Varadhan's Lemma."}}, "ground_truth": {"target_citation_key": "Deuschel_Stroock_LDP", "target_lemma_latex": "\\d\\WS{\\sigma^2}{0}{1}(\\xi) \\text{ satisfies Large Deviations Principle with good rate function } \\frac{1}{2}\\int_0^1 |\\xi'(\\tau)|^2\\d\\tau", "target_citation_content": "J.~Deuschel and D.~Stroock. \\newblock \\emphLarge Deviations. \\newblock AMS Chelsea Publishing Series. American Mathematical Society, 2001. \\newblock ISBN 9780821827574."}}
{"id": "2406.17069v2_gap_4", "arxiv_id": "2406.17069v2", "title": "Large Deviations of the Schwarzian Field Theory", "publication_date": "2024-06-24", "problem_input": {"global_context": {"setup": "The paper investigates the probabilistic Schwarzian Field Theory, defined via a finite measure $\\mathscr{M}_{\\sigma^2}$ on the quotient space $\\text{Diff}^1(\\mathbb{T})/\\text{PSL}(2, \\mathbb{R})$. This measure is constructed as the push-forward of a Brownian bridge measure $\\mathcal{W}_{\\sigma^2}^{0,1}$ under a specific map $\\mathsf{P}$ involving the exponential integral. The theory involves the 'action' functional $\\mathcal{I}(\\phi) = - \\int_{0}^{1} [\\mathcal{S}_\\phi(\\tau)+2\\pi^2\\phi'^{\\, 2}(\\tau)] d\\tau$ involving the Schwarzian derivative $\\mathcal{S}_\\phi$.", "goal": "To prove that the family of measures $\\{\\mathscr{M}_{\\sigma^2}\\}_{\\sigma>0}$ satisfies the Large Deviations Principle (LDP) as $\\sigma \\to 0$ with the good rate function $\\mathcal{I}(\\cdot)$, and to characterize the minimizers of this action."}, "local_context": {"anchor_latex": "\\d\\WS{\\sigma^2}{0}{1}(\\xi) \\text{ satisfies Large Deviations Principle with good rate function } \\frac{1}{2}\\int_0^1 |\\xi'(\\tau)|^2\\d\\tau \\text{ and } F(\\xi) \\text{ is lower semicontinuous}", "gap_objective": "Establish the asymptotic lower bound for the integral functional representing the measure of the open set U"}}, "ground_truth": {"target_citation_key": "bookLDP", "target_lemma_latex": "\\liminf_{\\epsilon \\to 0} \\epsilon \\log \\int_G e^{\\phi(x)/\\epsilon} d\\mu_\\epsilon(x) \\ge \\sup_{x \\in G} [\\phi(x) - I(x)]", "target_citation_content": "A.~Dembo and O.~Zeitouni. \\newblock \\emphLarge Deviations Techniques and Applications. \\newblock 1 2009. \\newblock ISBN 978-3-642-03311-7."}}
{"id": "2406.17069v2_gap_5", "arxiv_id": "2406.17069v2", "title": "Large Deviations of the Schwarzian Field Theory", "publication_date": "2024-06-24", "problem_input": {"global_context": {"setup": "The paper investigates the probabilistic Schwarzian Field Theory, defined via a finite measure $\\mathscr{M}_{\\sigma^2}$ on the quotient space $\\text{Diff}^1(\\mathbb{T})/\\text{PSL}(2, \\mathbb{R})$. This measure is constructed as the push-forward of a Brownian bridge measure $\\mathcal{W}_{\\sigma^2}^{0,1}$ under a specific map $\\mathsf{P}$ involving the exponential integral. The theory involves the 'action' functional $\\mathcal{I}(\\phi) = - \\int_{0}^{1} [\\mathcal{S}_\\phi(\\tau)+2\\pi^2\\phi'^{\\, 2}(\\tau)] d\\tau$ involving the Schwarzian derivative $\\mathcal{S}_\\phi$.", "goal": "To prove that the family of measures $\\{\\mathscr{M}_{\\sigma^2}\\}_{\\sigma>0}$ satisfies the Large Deviations Principle (LDP) as $\\sigma \\to 0$ with the good rate function $\\mathcal{I}(\\cdot)$, and to characterize the minimizers of this action."}, "local_context": {"anchor_latex": "\\d\\WS{\\sigma^2}{0}{1}(\\xi) \\text{ satisfies Large Deviations Principle with good rate function } \\frac{1}{2}\\int_0^1 |\\xi'(\\tau)|^2\\d\\tau \\text{ and } F(\\xi) \\text{ is upper semicontinuous and bounded from above.}", "gap_objective": "Bound the limit superior of the logarithmic moment generating function (Laplace integral) for the measure."}}, "ground_truth": {"target_citation_key": "bookLDP", "target_lemma_latex": "\\limsup_{\\sigma \\to 0} \\sigma^2 \\log \\int e^{\\sigma^{-2} F(x)} d\\mu_\\sigma(x) \\leq \\sup_{x} (F(x) - I(x))", "target_citation_content": "A.~Dembo and O.~Zeitouni. \\newblock \\emphLarge Deviations Techniques and Applications. \\newblock 1 2009. \\newblock ISBN 978-3-642-03311-7."}}
{"id": "2502.08799v2_gap_0", "arxiv_id": "2502.08799v2", "title": "Strong completeness of SDEs and non-explosion for RDEs with coefficients having unbounded derivatives", "publication_date": "2025-02-12", "problem_input": {"global_context": {"setup": "Let $V$ be a Banach space and $H$ a Hilbert space. Consider a filtered probability space $(\\Omega, \\mathcal{F}, (\\mathcal{F}_t)_{t \\ge 0}, \\mathbb{P})$. Let $b: H \\to H$ be a drift term having radial linear growth with control $f$ (i.e., $\\langle x/\\|x\\|, b(x)\\rangle \\le f(\\|x\\|)$) and let $\\sigma: H \\to \\CL(V; H)$. Let $\\mathbb{\\Gamma}$ be a rough path on $V$ with regularity $\\alpha \\in (1/3, 1)$ or a standard Brownian motion $W$.", "goal": "Establish the global well-posedness (non-explosion) of the rough differential equation $\\dd x_t = b(x_t) \\dd t + \\sigma(x_t) \\dd \\mathbb{\\Gamma}_t$ and the strong completeness of the corresponding stochastic differential equation under conditions where the coefficients and their derivatives are allowed to be unbounded at infinity."}, "local_context": {"anchor_latex": "\\text{The SDE is strongly complete if it is complete at one point and if the quantity } \\mathbb{E}\\left(\\sup_{s\\le t} \\|D \\phi_s(x)\\|^d\\mathbf{1}_{s<\\zeta(x)}\\right) \\text{ is bounded in } x \\text{ over any compact subsets of } \\mathbb{R}^d", "gap_objective": "To provide a sufficient criterion for the strong completeness of a Stochastic Differential Equation based on its derivative flow."}}, "ground_truth": {"target_citation_key": "Li:94a", "target_lemma_latex": "\\text{Strong } p\\text{-completeness (boundedness of } \\mathbb{E}[\\sup_{s\\le t} \\|D\\phi_s(x)\\|^p] \\text{ for sufficient } p \\ge d\\text{) and completeness at a point implies strong completeness.}", "target_citation_content": "Xue-Mei Li. \\newblock Strong p-completeness of stochastic differential equations and the existence of smooth flows on non-compact manifolds. \\newblock \\em Probability Theory and Related Fields, 100(4):485--511, 1994."}}
{"id": "2502.08799v2_gap_1", "arxiv_id": "2502.08799v2", "title": "Strong completeness of SDEs and non-explosion for RDEs with coefficients having unbounded derivatives", "publication_date": "2025-02-12", "problem_input": {"global_context": {"setup": "Let $V$ be a Banach space and $H$ a Hilbert space. Consider a filtered probability space $(\\Omega, \\mathcal{F}, (\\mathcal{F}_t)_{t \\ge 0}, \\mathbb{P})$. Let $b: H \\to H$ be a drift term having radial linear growth with control $f$ (i.e., $\\langle x/\\|x\\|, b(x)\\rangle \\le f(\\|x\\|)$) and let $\\sigma: H \\to \\CL(V; H)$. Let $\\mathbb{\\Gamma}$ be a rough path on $V$ with regularity $\\alpha \\in (1/3, 1)$ or a standard Brownian motion $W$.", "goal": "Establish the global well-posedness (non-explosion) of the rough differential equation $\\dd x_t = b(x_t) \\dd t + \\sigma(x_t) \\dd \\mathbb{\\Gamma}_t$ and the strong completeness of the corresponding stochastic differential equation under conditions where the coefficients and their derivatives are allowed to be unbounded at infinity."}, "local_context": {"anchor_latex": "\\sup_{x \\in K} {\\mathbb E}\\left(e^{6q^2 \\int_0^{t} g(\\phi_s(x))  {\\bf 1}_{s<\\zeta(x)} \\dd s}\\right)<\\infty", "gap_objective": "To establish strong completeness using the preceding theorem, a specific estimate on the exponential moments of the Lyapunov function along the solution paths is required."}}, "ground_truth": {"target_citation_key": "Li:94a", "target_lemma_latex": "\\frac12 \\sum_{k = 1}^m \\<\\nabla g, \\sigma_k\\>^2 + \\frac12 \\sum_{k = 1}^m \\nabla^2 g (\\sigma_k,\\sigma_k)+\\<\\nabla g, b\\>\\le C \\implies \\mathbb E[ e^{c g(x_t)}]\\le e^{Kt} e^{cg(x_0)}", "target_citation_content": "Xue-Mei Li. \\newblock Strong p-completeness of stochastic differential equations and the existence of smooth flows on non-compact manifolds. \\newblock \\em Probability Theory and Related Fields, 100(4):485--511, 1994."}}
{"id": "2502.08799v2_gap_2", "arxiv_id": "2502.08799v2", "title": "Strong completeness of SDEs and non-explosion for RDEs with coefficients having unbounded derivatives", "publication_date": "2025-02-12", "problem_input": {"global_context": {"setup": "Let $V$ be a Banach space and $H$ a Hilbert space. Consider a filtered probability space $(\\Omega, \\mathcal{F}, (\\mathcal{F}_t)_{t \\ge 0}, \\mathbb{P})$. Let $b: H \\to H$ be a drift term having radial linear growth with control $f$ (i.e., $\\langle x/\\|x\\|, b(x)\\rangle \\le f(\\|x\\|)$) and let $\\sigma: H \\to \\CL(V; H)$. Let $\\mathbb{\\Gamma}$ be a rough path on $V$ with regularity $\\alpha \\in (1/3, 1)$ or a standard Brownian motion $W$.", "goal": "Establish the global well-posedness (non-explosion) of the rough differential equation $\\dd x_t = b(x_t) \\dd t + \\sigma(x_t) \\dd \\mathbb{\\Gamma}_t$ and the strong completeness of the corresponding stochastic differential equation under conditions where the coefficients and their derivatives are allowed to be unbounded at infinity."}, "local_context": {"anchor_latex": "b \\in L^q([0,T]; L^p(\\R^d; \\R^d)) \\text{ where } 2 / q + d / p < 1", "gap_objective": "To establish path-by-path uniqueness and strong completeness for SDEs under this Prodi-Serrin condition."}}, "ground_truth": {"target_citation_key": "Anzeletti:23", "target_lemma_latex": "\\text{Path-by-path uniqueness and strong completeness under a global condition}", "target_citation_content": "Lukas Anzeletti, Khoa L\\^e, and Chengcheng Ling. \\newblock Path-by-path uniqueness for stochastic differential equations under krylov-r\\\"ockner condition, 2023."}}
{"id": "2502.08799v2_gap_3", "arxiv_id": "2502.08799v2", "title": "Strong completeness of SDEs and non-explosion for RDEs with coefficients having unbounded derivatives", "publication_date": "2025-02-12", "problem_input": {"global_context": {"setup": "Let $V$ be a Banach space and $H$ a Hilbert space. Consider a filtered probability space $(\\Omega, \\mathcal{F}, (\\mathcal{F}_t)_{t \\ge 0}, \\mathbb{P})$. Let $b: H \\to H$ be a drift term having radial linear growth with control $f$ (i.e., $\\langle x/\\|x\\|, b(x)\\rangle \\le f(\\|x\\|)$) and let $\\sigma: H \\to \\CL(V; H)$. Let $\\mathbb{\\Gamma}$ be a rough path on $V$ with regularity $\\alpha \\in (1/3, 1)$ or a standard Brownian motion $W$.", "goal": "Establish the global well-posedness (non-explosion) of the rough differential equation $\\dd x_t = b(x_t) \\dd t + \\sigma(x_t) \\dd \\mathbb{\\Gamma}_t$ and the strong completeness of the corresponding stochastic differential equation under conditions where the coefficients and their derivatives are allowed to be unbounded at infinity."}, "local_context": {"anchor_latex": "d \\ge 3, \\quad b \\in L^q([0,T]; L^p_{loc}(\\mathbb{R}^d; \\mathbb{R}^d)) \\quad \\text{with} \\quad \\frac{2}{q} + \\frac{d}{p} = 1", "gap_objective": "Establish the existence of a maximal solution flow (path-by-path uniqueness and strong completeness) to apply the globalization argument via Corollary 3.5."}}, "ground_truth": {"target_citation_key": "Rockner-Zhao-2021", "target_lemma_latex": "\\text{For } b \\in L^q([0,T]; L^p(\\mathbb{R}^d; \\mathbb{R}^d)) \\text{ satisfying the critical condition } \\frac{2}{q} + \\frac{d}{p} = 1, \\text{ the SDE } \\dd x_t = b(t, x_t) \\dd t + \\dd W_t \\text{ admits a unique strong solution for all initial conditions, and the solution flow is strongly complete.}", "target_citation_content": "Michael Rockner and Guohuan Zhao. \\newblock Sdes with critical time dependent drifts: strong solutions. \\newblock 2021."}}
{"id": "2502.08799v2_gap_4", "arxiv_id": "2502.08799v2", "title": "Strong completeness of SDEs and non-explosion for RDEs with coefficients having unbounded derivatives", "publication_date": "2025-02-12", "problem_input": {"global_context": {"setup": "Let $V$ be a Banach space and $H$ a Hilbert space. Consider a filtered probability space $(\\Omega, \\mathcal{F}, (\\mathcal{F}_t)_{t \\ge 0}, \\mathbb{P})$. Let $b: H \\to H$ be a drift term having radial linear growth with control $f$ (i.e., $\\langle x/\\|x\\|, b(x)\\rangle \\le f(\\|x\\|)$) and let $\\sigma: H \\to \\CL(V; H)$. Let $\\mathbb{\\Gamma}$ be a rough path on $V$ with regularity $\\alpha \\in (1/3, 1)$ or a standard Brownian motion $W$.", "goal": "Establish the global well-posedness (non-explosion) of the rough differential equation $\\dd x_t = b(x_t) \\dd t + \\sigma(x_t) \\dd \\mathbb{\\Gamma}_t$ and the strong completeness of the corresponding stochastic differential equation under conditions where the coefficients and their derivatives are allowed to be unbounded at infinity."}, "local_context": {"anchor_latex": "b \\in L^q([0,T]; L^p_{loc}(\\R^d; \\R^d)) \\quad \\text{with} \\quad 2 / q + d / p < 1, \\quad p, q \\in (2, \\infty)", "gap_objective": "Establish local well-posedness and continuity of the solution for the SDE \\eqref{eq:SDEext} under the given regularity conditions on the drift $b$."}}, "ground_truth": {"target_citation_key": "galeati-gerencser2025", "target_lemma_latex": "\\text{Local well-posedness and continuity of the solution for SDEs with drift } b \\in L^q_t L^p_x \\text{ satisfying } 2/q + d/p < 1", "target_citation_content": "Lucio Galeati and M谩t茅 Gerencs茅r. \\newblock Solution theory of fractional sdes in complete subcritical regimes, 2025."}}
{"id": "2502.08799v2_gap_5", "arxiv_id": "2502.08799v2", "title": "Strong completeness of SDEs and non-explosion for RDEs with coefficients having unbounded derivatives", "publication_date": "2025-02-12", "problem_input": {"global_context": {"setup": "Let $V$ be a Banach space and $H$ a Hilbert space. Consider a filtered probability space $(\\Omega, \\mathcal{F}, (\\mathcal{F}_t)_{t \\ge 0}, \\mathbb{P})$. Let $b: H \\to H$ be a drift term having radial linear growth with control $f$ (i.e., $\\langle x/\\|x\\|, b(x)\\rangle \\le f(\\|x\\|)$) and let $\\sigma: H \\to \\CL(V; H)$. Let $\\mathbb{\\Gamma}$ be a rough path on $V$ with regularity $\\alpha \\in (1/3, 1)$ or a standard Brownian motion $W$.", "goal": "Establish the global well-posedness (non-explosion) of the rough differential equation $\\dd x_t = b(x_t) \\dd t + \\sigma(x_t) \\dd \\mathbb{\\Gamma}_t$ and the strong completeness of the corresponding stochastic differential equation under conditions where the coefficients and their derivatives are allowed to be unbounded at infinity."}, "local_context": {"anchor_latex": "\\dd x_t = b(x_t) \\dd t + \\sum_{i = 1}^n \\dd B^{H_i}_t, \\quad b \\in C^\\alpha \\cap L^\\infty", "gap_objective": "Strong completeness and path-by-path uniqueness of the solution"}}, "ground_truth": {"target_citation_key": "Catellier:16", "target_lemma_latex": "\\text{Existence and uniqueness of a global flow for } \\dd x_t = b(x_t) \\dd t + \\dd w_t \\text{ where } b \\in C^\\alpha_b \\text{ and } w \\text{ satisfies averaging conditions.}", "target_citation_content": "R.~Catellier and M.~Gubinelli. \\newblock Averaging along irregular curves and regularisation of odes. \\newblock \\em Stochastic Processes and their Applications, 126(8):2323--2366, 2016."}}
{"id": "2502.08799v2_gap_6", "arxiv_id": "2502.08799v2", "title": "Strong completeness of SDEs and non-explosion for RDEs with coefficients having unbounded derivatives", "publication_date": "2025-02-12", "problem_input": {"global_context": {"setup": "Let $V$ be a Banach space and $H$ a Hilbert space. Consider a filtered probability space $(\\Omega, \\mathcal{F}, (\\mathcal{F}_t)_{t \\ge 0}, \\mathbb{P})$. Let $b: H \\to H$ be a drift term having radial linear growth with control $f$ (i.e., $\\langle x/\\|x\\|, b(x)\\rangle \\le f(\\|x\\|)$) and let $\\sigma: H \\to \\CL(V; H)$. Let $\\mathbb{\\Gamma}$ be a rough path on $V$ with regularity $\\alpha \\in (1/3, 1)$ or a standard Brownian motion $W$.", "goal": "Establish the global well-posedness (non-explosion) of the rough differential equation $\\dd x_t = b(x_t) \\dd t + \\sigma(x_t) \\dd \\mathbb{\\Gamma}_t$ and the strong completeness of the corresponding stochastic differential equation under conditions where the coefficients and their derivatives are allowed to be unbounded at infinity."}, "local_context": {"anchor_latex": "Z \\text{ is a L\\'evy process in } \\R^d \\text{ with L\\'evy triple } (a, \\Sigma, \\nu) \\text{ satisfying } \\int_{\\R^d} (1 \\wedge \\|z\\|^p) \\nu(\\dd z) < \\infty", "gap_objective": "Z \\in C^{\\pvar}_{loc}(\\R_+; \\R^d)"}}, "ground_truth": {"target_citation_key": "Bretagnolle:72", "target_lemma_latex": "Z \\text{ has sample paths in } C^{\\pvar}_{loc}(\\R_+; \\R^d)", "target_citation_content": "Jean Bretagnolle. \\newblock p-variation de fonctions aléatoires 2i\\`eme partie:processus \\`a accroissements indépendants. \\newblock In \\em Séminaire de Probabilités VI Université de Strasbourg, pages 64--71, Berlin, Heidelberg, 1972. Springer Berlin Heidelberg."}}
{"id": "2502.08799v2_gap_7", "arxiv_id": "2502.08799v2", "title": "Strong completeness of SDEs and non-explosion for RDEs with coefficients having unbounded derivatives", "publication_date": "2025-02-12", "problem_input": {"global_context": {"setup": "Let $V$ be a Banach space and $H$ a Hilbert space. Consider a filtered probability space $(\\Omega, \\mathcal{F}, (\\mathcal{F}_t)_{t \\ge 0}, \\mathbb{P})$. Let $b: H \\to H$ be a drift term having radial linear growth with control $f$ (i.e., $\\langle x/\\|x\\|, b(x)\\rangle \\le f(\\|x\\|)$) and let $\\sigma: H \\to \\CL(V; H)$. Let $\\mathbb{\\Gamma}$ be a rough path on $V$ with regularity $\\alpha \\in (1/3, 1)$ or a standard Brownian motion $W$.", "goal": "Establish the global well-posedness (non-explosion) of the rough differential equation $\\dd x_t = b(x_t) \\dd t + \\sigma(x_t) \\dd \\mathbb{\\Gamma}_t$ and the strong completeness of the corresponding stochastic differential equation under conditions where the coefficients and their derivatives are allowed to be unbounded at infinity."}, "local_context": {"anchor_latex": "Let \\alpha \\in (0, 1] \\text{ and } \\beta \\in (1, 1 + \\alpha]. \\text{ Suppose Assumption~\\ref{cond:perp} holds with } \\beta, \\text{ and } \\gamma\\in C^{\\alpha}_{loc}(\\R_+; H). \\text{ Then, any maximal solution } (x_t)_{t \\in [0, \\xi)} \\text{ of } \\eqref{eq:ode-intro} \\text{ is a global solution.}", "gap_objective": "Show that the criterion for non-explosion in Corollary 3.5 is sharp by providing a counterexample where the condition is violated."}}, "ground_truth": {"target_citation_key": "cox:24", "target_lemma_latex": "\\text{Lemma 3.15 in } \\cite{cox:24}", "target_citation_content": "Sonja Cox, Martin Hutzenthaler, and Arnulf Jentzen. \\newblock Local Lipschitz continuity in the initial value and strong completeness for nonlinear stochastic differential equations. \\newblock \\em Mem. Amer. Math. Soc., 296(1481):v+90, 2024."}}
{"id": "2502.08799v2_gap_8", "arxiv_id": "2502.08799v2", "title": "Strong completeness of SDEs and non-explosion for RDEs with coefficients having unbounded derivatives", "publication_date": "2025-02-12", "problem_input": {"global_context": {"setup": "Let $V$ be a Banach space and $H$ a Hilbert space. Consider a filtered probability space $(\\Omega, \\mathcal{F}, (\\mathcal{F}_t)_{t \\ge 0}, \\mathbb{P})$. Let $b: H \\to H$ be a drift term having radial linear growth with control $f$ (i.e., $\\langle x/\\|x\\|, b(x)\\rangle \\le f(\\|x\\|)$) and let $\\sigma: H \\to \\CL(V; H)$. Let $\\mathbb{\\Gamma}$ be a rough path on $V$ with regularity $\\alpha \\in (1/3, 1)$ or a standard Brownian motion $W$.", "goal": "Establish the global well-posedness (non-explosion) of the rough differential equation $\\dd x_t = b(x_t) \\dd t + \\sigma(x_t) \\dd \\mathbb{\\Gamma}_t$ and the strong completeness of the corresponding stochastic differential equation under conditions where the coefficients and their derivatives are allowed to be unbounded at infinity."}, "local_context": {"anchor_latex": "b, \\sigma \\text{ are bounded on bounded sets}", "gap_objective": "Ensure the existence of maximal solutions for the rough differential equation in infinite dimensional spaces."}}, "ground_truth": {"target_citation_key": "Friz:20", "target_lemma_latex": "\\text{Existence of maximal solutions for RDEs in Banach spaces requires vector fields to be bounded on bounded sets}", "target_citation_content": "Peter~K. Friz and Martin Hairer. \\newblock \\em A Course on Rough Paths: With an Introduction to Regularity Structures. \\newblock Springer International Publishing, second edition, 2020."}}
{"id": "2407.09286v3_gap_0", "arxiv_id": "2407.09286v3", "title": "Adaptive Bayesian Regression on Data with Low Intrinsic Dimensionality", "publication_date": "2024-07-12", "problem_input": {"global_context": {"setup": "The paper considers a nonparametric regression model $Y_i = f^*(X_i)+w_i$ with $w_i \\sim \\mathcal{N}(0, \\sigma^2)$ and $X_i \\in \\mathcal{X} \\subset [0,1]^D$. The estimator is based on a Gaussian Process (GP) prior with a squared exponential kernel $h_t(x,x') = \\exp(-\\|x-x'\\|^2/2t)$ and a prior $p(t)$ on the bandwidth $t$. The analysis relies on three main assumptions: (A1) The data domain $\\mathcal{X}$ has intrinsic low-dimensionality characterized by the covering number $\\mathcal{N}(r, \\mathcal{X}, \\|\\cdot\\|_\\infty) \\le C_{\\mathcal{X}} r^{-\\varrho}$; (A2) The true function $f^*$ can be approximated by functions in the RKHS $\\mathbb{H}_{\\epsilon}(\\mathcal{X})$ with error $\nu_1 \\epsilon^{s/2}$ and norm $\nu_2 \\epsilon^{-\\varrho/2}$; and (A3) The prior $p(t)$ satisfies specific lower and upper bound conditions related to $\\varrho$ and $s$.", "goal": "Theorem 3.3: Establish that the posterior contraction rate with respect to the empirical norm $\\|\\cdot\\|_n$ is at least $\\bar{\\varepsilon}_n \\lesssim n^{-s/(2s+\\varrho)}(\\log n)^{D+1}$."}, "local_context": {"anchor_latex": "\\nabla^k f(x) \\text{ is represented by the real symmetric tensor } D^k \\tilde f (0 ) \\text{ on } T_x \\calM", "gap_objective": "Relate the operator norm (supremum over multiple unit vectors) of a symmetric tensor to the supremum over a single repeated unit vector"}}, "ground_truth": {"target_citation_key": "banach1938homogene", "target_lemma_latex": "\\sup_{v_1, \\cdots, v_k \\in S^{d-1} \\subset T_x \\calM } | \\nabla^k f(x)( v_1, \\cdots, v_k) | = \\sup_{v \\in S^{d-1} \\subset T_x \\calM } | \\nabla^k f(x)( v, \\cdots, v) |", "target_citation_content": "Stefan Banach. \\newblock \\\"Uber homogene polynome in ($l^2$). \\newblock \\em Studia Mathematica, 7(1):36--44, 1938."}}
{"id": "2502.05730v2_gap_0", "arxiv_id": "2502.05730v2", "title": "Attainability of Two-Point Testing Rates for Finite-Sample Location Estimation", "publication_date": "2025-02-09", "problem_input": {"global_context": {"setup": "The paper considers the problem of estimating the location parameter (mean) $\\mu$ given $n$ i.i.d. samples $X_1, \\dots, X_n$ from a distribution $p_\\mu(x) = p(x - \\mu)$. The distribution $p$ is assumed to be a symmetric mixture of $k$ log-concave distributions on $\\mathbb{R}$.", "goal": "To provide a near-linear time algorithm for estimating \\mu with high probability, achieving a guarantee in terms of the Hellinger modulus, and to establish a lower bound showing that two-point testing rates are not attainable for general symmetric unimodal distributions."}, "local_context": {"anchor_latex": "\\mathcal{T}^{\\operatorname{thresh}} \\triangleq \\{\\mathbbm{1}_{p(x)/q(x) \\ge \\tau}(x) : \\tau \\ge 0 \\}", "gap_objective": "Determine the factor by which the squared Hellinger distance is preserved (or reduced) when projecting distributions through an optimal thresholding channel from $\\mathcal{T}^{\\operatorname{thresh}}$."}}, "ground_truth": {"target_citation_key": "pensia2023communication", "target_lemma_latex": "1 \\le \\frac{\\dhsq(p,q)}{\\dhsq(\\tstar p, \\tstar q)} \\le 1800 \\min\\{k, \\log(4/\\dhsq(p,q)) \\}", "target_citation_content": "Ankit Pensia, Varun Jog, and Po-Ling Loh. \\newblock Communication-constrained hypothesis testing: Optimality, robustness, and reverse data processing inequalities. \\newblock \\em IEEE Transactions on Information Theory, 2023."}}
{"id": "2502.05730v2_gap_1", "arxiv_id": "2502.05730v2", "title": "Attainability of Two-Point Testing Rates for Finite-Sample Location Estimation", "publication_date": "2025-02-09", "problem_input": {"global_context": {"setup": "The paper considers the problem of estimating the location parameter (mean) $\\mu$ given $n$ i.i.d. samples $X_1, \\dots, X_n$ from a distribution $p_\\mu(x) = p(x - \\mu)$. The distribution $p$ is assumed to be a symmetric mixture of $k$ log-concave distributions on $\\mathbb{R}$.", "goal": "To provide a near-linear time algorithm for estimating \\mu with high probability, achieving a guarantee in terms of the Hellinger modulus, and to establish a lower bound showing that two-point testing rates are not attainable for general symmetric unimodal distributions."}, "local_context": {"anchor_latex": "\\frac{\\alpha^2 \\beta}{36} \\cdot \\Pr[X^2 \\ge \\delta^2] \\delta^2", "gap_objective": "Lower bound the quantity $\\delta^2 \\Pr[X^2 \\ge \\delta^2]$ (where $\\delta$ maximizes this product) in terms of the expectation $\\Ex[X^2]$."}}, "ground_truth": {"target_citation_key": "pensia2023communication", "target_lemma_latex": "\\max_{\\delta} \\delta^2 \\Pr[X^2 \\ge \\delta^2] \\ge \\frac{\\Ex[X^2]}{13 \\cdot (1 + \\log(1/\\Ex[X^2]))}", "target_citation_content": "Ankit Pensia, Varun Jog, and Po-Ling Loh. \\newblock Communication-constrained hypothesis testing: Optimality, robustness, and reverse data processing inequalities. \\newblock \\em IEEE Transactions on Information Theory, 2023."}}
{"id": "2502.05730v2_gap_2", "arxiv_id": "2502.05730v2", "title": "Attainability of Two-Point Testing Rates for Finite-Sample Location Estimation", "publication_date": "2025-02-09", "problem_input": {"global_context": {"setup": "The paper considers the problem of estimating the location parameter (mean) $\\mu$ given $n$ i.i.d. samples $X_1, \\dots, X_n$ from a distribution $p_\\mu(x) = p(x - \\mu)$. The distribution $p$ is assumed to be a symmetric mixture of $k$ log-concave distributions on $\\mathbb{R}$.", "goal": "To provide a near-linear time algorithm for estimating \\mu with high probability, achieving a guarantee in terms of the Hellinger modulus, and to establish a lower bound showing that two-point testing rates are not attainable for general symmetric unimodal distributions."}, "local_context": {"anchor_latex": "q \\text{ is a log-concave distribution over } \\mathbb{R}, \\quad 0 < \\delta \\le \\frac{1}{2}", "gap_objective": "Construct a piecewise-constant approximation \\tilde{q} of q using O(\\log(1/\\delta)) pieces that bounds q multiplicatively on a set of measure 1-\\delta."}}, "ground_truth": {"target_citation_key": "chan2014efficient", "target_lemma_latex": "\\exists \\tilde{q} \\text{ piecewise-constant with } O(\\log(\\frac{1}{\\delta})) \\text{ pieces s.t. } \\tilde{q}(x) \\le q(x) \\, \\forall x, \\quad \\tilde{q}(x) \\ge \\frac{1}{2} q(x) \\text{ whenever } \\tilde{q}(x) > 0, \\quad \\Pr_{x \\sim q}[\\tilde{q}(x)>0] \\ge 1 -\\delta", "target_citation_content": "Siu-On Chan, Ilias Diakonikolas, Rocco~A Servedio, and Xiaorui Sun. \\newblock Efficient density estimation via piecewise polynomial approximation. \\newblock In \\em Proceedings of the forty-sixth annual ACM symposium on Theory of computing, pages 604--613, 2014."}}
{"id": "2502.05730v2_gap_3", "arxiv_id": "2502.05730v2", "title": "Attainability of Two-Point Testing Rates for Finite-Sample Location Estimation", "publication_date": "2025-02-09", "problem_input": {"global_context": {"setup": "The paper considers the problem of estimating the location parameter (mean) $\\mu$ given $n$ i.i.d. samples $X_1, \\dots, X_n$ from a distribution $p_\\mu(x) = p(x - \\mu)$. The distribution $p$ is assumed to be a symmetric mixture of $k$ log-concave distributions on $\\mathbb{R}$.", "goal": "To provide a near-linear time algorithm for estimating \\mu with high probability, achieving a guarantee in terms of the Hellinger modulus, and to establish a lower bound showing that two-point testing rates are not attainable for general symmetric unimodal distributions."}, "local_context": {"anchor_latex": "\\Delta^* \\triangleq \\omega_p \\left(\\cdist \\cdot \\frac{k}{n} \\cdot \\log(2n/\\delta) \\cdot \\log^2(2n) \\right)", "gap_objective": "Establish a normalized uniform convergence bound for a class of functions with finite VC dimension, where the deviation bound depends on the expected sum of the functions."}}, "ground_truth": {"target_citation_key": "dasgupta2007general", "target_lemma_latex": "\\left|\\sum_{i = 1}^n(f(X_i) - \\Ex[ f(X_i)])\\right| \\le C \\cdot \\left(\\sqrt{\\left(\\sum_{i = 1}^n\\Ex[f(X_i)]\\right)\\left(d\\log(n) + \\log\\left(\\frac{2}{\\delta}\\right)\\right)}+ d\\log(n) + \\log\\left(\\frac{2}{\\delta}\\right)\\right)", "target_citation_content": "Sanjoy Dasgupta, Daniel~J Hsu, and Claire Monteleoni. \\newblock A general agnostic active learning algorithm. \\newblock \\em Advances in neural information processing systems, 20, 2007."}}
{"id": "2502.05730v2_gap_4", "arxiv_id": "2502.05730v2", "title": "Attainability of Two-Point Testing Rates for Finite-Sample Location Estimation", "publication_date": "2025-02-09", "problem_input": {"global_context": {"setup": "The paper considers the problem of estimating the location parameter (mean) $\\mu$ given $n$ i.i.d. samples $X_1, \\dots, X_n$ from a distribution $p_\\mu(x) = p(x - \\mu)$. The distribution $p$ is assumed to be a symmetric mixture of $k$ log-concave distributions on $\\mathbb{R}$.", "goal": "To provide a near-linear time algorithm for estimating \\mu with high probability, achieving a guarantee in terms of the Hellinger modulus, and to establish a lower bound showing that two-point testing rates are not attainable for general symmetric unimodal distributions."}, "local_context": {"anchor_latex": "\\Delta^* \\triangleq \\omega_p \\left(\\cdist \\cdot \\frac{k}{n} \\cdot \\log(2n/\\delta) \\cdot \\log^2(2n) \\right)", "gap_objective": "Bound the growth function (or shattering number) of a hypothesis class with finite VC dimension to justify the uniform convergence bound."}}, "ground_truth": {"target_citation_key": "bousquet2003introduction", "target_lemma_latex": "\\Pi_{\\mathcal{F}}(n) \\le \\sum_{i=0}^d \\binom{n}{i} \\le \\left(\\frac{en}{d}\\right)^d", "target_citation_content": "Olivier Bousquet, Stéphane Boucheron, and Gábor Lugosi. \\newblock Introduction to statistical learning theory. \\newblock In \\em Summer school on machine learning, pages 169--207. Springer, 2003."}}
{"id": "2410.05634v3_gap_0", "arxiv_id": "2410.05634v3", "title": "Identification and estimation for matrix time series CP-factor models", "publication_date": "2024-10-08", "problem_input": {"global_context": {"setup": "Consider the matrix CP-factor model for a $p \\times q$ matrix time series $\\bY_t$: $\\bY_t = \\bA \\bX_{t} \\bB^{\\top} + \\beps_t$, where $\\bX_t={\\rm diag}(\\bx_t)$ is a $d \\times d$ diagonal matrix of latent factors, and $\\bA, \\bB$ are factor loading matrices with ${\\rm rank}(\\bA)=d_1$ and ${\\rm rank}(\\bB)=d_2$. We define cumulative autocovariance matrices $\\bM_1=\\sum_{k=1}^{K}\\bSigma_{\\bY, \\xi}(k)\\bSigma_{\\bY, \\xi}(k)^{\\top}$ and $\\bM_2$ similarly. We assume regularity conditions (Conditions 1-6) regarding the ranks, noise properties, eigenvalue boundedness, and mixing coefficients.", "goal": "Theorem 1: Prove the consistency of the estimators for the dimensions $\\hat{d}_1, \\hat{d}_2, \\hat{d}$ (i.e., $\\mathbb{P}(\\hat{d}=d) \\to 1$) and Proposition 6: Establish the convergence rates for the estimators of the factor loading spaces $\\hat{\\bP}, \\hat{\\bQ}$ and $\\hat{\\bW}$."}, "local_context": {"anchor_latex": "\\text{For matrices } \\bD=(d_{i,j}) \\text{ and } \\bF=(f_{i,j}), \\text{ the tensor } \\bPsi(\\bD, \\bF) \\text{ is defined with entries } (\\bPsi(\\bD, \\bF))_{i,j,k,\\ell} = d_{i,k}f_{j,\\ell} + d_{j,\\ell}f_{i,k} - d_{i,\\ell} f_{j,k} - d_{j,k}f_{i,\\ell}", "gap_objective": "To establish an algebraic condition using the tensor \\bPsi that characterizes when a non-zero matrix has rank 1, allowing the rank-1 property of \\bC_\\ell to be formulated as a system of equations."}}, "ground_truth": {"target_citation_key": "de2006link", "target_lemma_latex": "\\text{For any matrix } \\bD\\ne \\bf0, {\\rm rank}(\\bD)=1 \\text{ if and only if } \\bPsi(\\bD, \\bD)= \\bf0", "target_citation_content": "De~Lathauwer, L. (2006). \\newblock A link between the canonical decomposition in multilinear algebra and simultaneous matrix diagonalization. \\newblock \\em SIAM Journal on Matrix Analysis and Applications\\/, 28, 642--666."}}
{"id": "2410.05634v3_gap_1", "arxiv_id": "2410.05634v3", "title": "Identification and estimation for matrix time series CP-factor models", "publication_date": "2024-10-08", "problem_input": {"global_context": {"setup": "Consider the matrix CP-factor model for a $p \\times q$ matrix time series $\\bY_t$: $\\bY_t = \\bA \\bX_{t} \\bB^{\\top} + \\beps_t$, where $\\bX_t={\\rm diag}(\\bx_t)$ is a $d \\times d$ diagonal matrix of latent factors, and $\\bA, \\bB$ are factor loading matrices with ${\\rm rank}(\\bA)=d_1$ and ${\\rm rank}(\\bB)=d_2$. We define cumulative autocovariance matrices $\\bM_1=\\sum_{k=1}^{K}\\bSigma_{\\bY, \\xi}(k)\\bSigma_{\\bY, \\xi}(k)^{\\top}$ and $\\bM_2$ similarly. We assume regularity conditions (Conditions 1-6) regarding the ranks, noise properties, eigenvalue boundedness, and mixing coefficients.", "goal": "Theorem 1: Prove the consistency of the estimators for the dimensions $\\hat{d}_1, \\hat{d}_2, \\hat{d}$ (i.e., $\\mathbb{P}(\\hat{d}=d) \\to 1$) and Proposition 6: Establish the convergence rates for the estimators of the factor loading spaces $\\hat{\\bP}, \\hat{\\bQ}$ and $\\hat{\\bW}$."}, "local_context": {"anchor_latex": "\\bH_m= \\bTheta \\,{\\rm diag}(\\gamma_{1,m} , \\ldots, \\gamma_{d,m}) \\,\\bTheta^\\T, ~~~~ m\\in[d]", "gap_objective": "Determine the convergence rate bound for the estimator of \\bTheta obtained via the fast Frobenius diagonalization algorithm"}}, "ground_truth": {"target_citation_key": "afsari2008sensitivity", "target_lemma_latex": "\\frac{\\eta({\\bh_1}, \\ldots, \\bh_d)}{1-\\rho^2({\\bh}_1, \\ldots, \\bh_d) } \\times K_n(d,\\bTheta)", "target_citation_content": "Afsari, B. (2008). \\newblock Sensitivity analysis for the problem of matrix joint diagonalization. \\newblock \\em SIAM Journal on Matrix Analysis and Applications\\/, 30, 1148--1171."}}
{"id": "2410.05634v3_gap_2", "arxiv_id": "2410.05634v3", "title": "Identification and estimation for matrix time series CP-factor models", "publication_date": "2024-10-08", "problem_input": {"global_context": {"setup": "Consider the matrix CP-factor model for a $p \\times q$ matrix time series $\\bY_t$: $\\bY_t = \\bA \\bX_{t} \\bB^{\\top} + \\beps_t$, where $\\bX_t={\\rm diag}(\\bx_t)$ is a $d \\times d$ diagonal matrix of latent factors, and $\\bA, \\bB$ are factor loading matrices with ${\\rm rank}(\\bA)=d_1$ and ${\\rm rank}(\\bB)=d_2$. We define cumulative autocovariance matrices $\\bM_1=\\sum_{k=1}^{K}\\bSigma_{\\bY, \\xi}(k)\\bSigma_{\\bY, \\xi}(k)^{\\top}$ and $\\bM_2$ similarly. We assume regularity conditions (Conditions 1-6) regarding the ranks, noise properties, eigenvalue boundedness, and mixing coefficients.", "goal": "Theorem 1: Prove the consistency of the estimators for the dimensions $\\hat{d}_1, \\hat{d}_2, \\hat{d}$ (i.e., $\\mathbb{P}(\\hat{d}=d) \\to 1$) and Proposition 6: Establish the convergence rates for the estimators of the factor loading spaces $\\hat{\\bP}, \\hat{\\bQ}$ and $\\hat{\\bW}$."}, "local_context": {"anchor_latex": "\\sum_{j_1=1}^{q}|\\sigma_{y,\\xi,i_1,j_1}^{(k)}|^{\\iota} \\le s_1, \\quad \\sum_{i_1=1}^{p}|\\sigma_{y,\\xi,i_1,j_1}^{(k)}|^{\\iota}  \\le s_2, \\quad \\sum_{j_2=1}^{pq}|\\sigma_{i_2,j_2}^{(k)}|^{\\iota} \\le s_3, \\quad \\sum_{i_2=1}^{pq}|\\sigma_{i_2,j_2}^{(k)}|^{\\iota} \\le s_4", "gap_objective": "Justify that the sparsity requirements in Condition 6(ii) hold under certain sparsity conditions on the factor loading matrices \\mathbf{A} and \\mathbf{B}"}}, "ground_truth": {"target_citation_key": "Chang2018", "target_lemma_latex": "Lemma 5 of Chang, J., Guo, B., and Yao, Q. (2018)", "target_citation_content": "Chang, J., Guo, B., and Yao, Q. (2018). \\newblock Principal component analysis for second-order stationary vector time series. \\newblock \\em The Annals of Statistics\\/, 46, 2094--2124."}}
{"id": "2405.06474v1_gap_0", "arxiv_id": "2405.06474v1", "title": "The Fyodorov-Hiary-Keating Conjecture on Mesoscopic Intervals", "publication_date": "2024-05-10", "problem_input": {"global_context": {"setup": "Let $T$ be large and $\\tau$ be uniformly distributed on $[T, 2T]$. Let $t = \\log \\log T$ and $\\theta \\in (-1, 0]$. Define the Dirichlet sum approximations $S_k(h) = \\sum_{\\log p \\leq e^k} \\Re(p^{-(1/2+i(\\tau+h))} + \\frac{1}{2}p^{-(1+2i(\\tau+h))})$. Define the shifted random walk $\\mathscr{S}_k = S_{t_\\theta + k} - S_{t_\\theta}$ where $t_\\theta = |\\theta|t$.", "goal": "Derive precise upper bounds for the maximum $\\max_{|h|\\leq \\log^\\theta T}|\\zeta(\\frac{1}{2}+i(\\tau+h))|$ and the second moment $\\int_{|h|\\leq \\log^\\theta T} |\\zeta(\\frac{1}{2}+i(\\tau+h))|^2 dh$ on mesoscopic intervals."}, "local_context": {"anchor_latex": "\\P{\\max_{|h|\\leq \\log^\\theta T}|\\zeta_\\tau(h)|>V}\\leq \\P{\\max_{h\\in \\mathcal{T}_t^\\theta}|\\zeta_\\tau(h)|>V/C}+O_A(e^{-At})", "gap_objective": "Prove the discretization inequality for the maximum of the zeta function over a short interval, relating the continuous maximum to a discrete one."}}, "ground_truth": {"target_citation_key": "FHK1", "target_lemma_latex": "\\max_{|h|\\leq \\log^\\theta T} \\bigg(\\sum_{i\\in \\mathcal{I}}|D_i(\\tfrac{1}{2}+i\\tau+ih)|^2\\bigg) \\ll_A \\sum_{{|j|\\leq 16\\log^{\\theta}T \\log N} }\\bigg(\\sum_{i\\in \\mathcal{I}} \\Big|D_i\\Big(\\frac{1}{2}+i\\tau+\\frac{2\\pi i j}{8\\log N}\\Big)\\Big|^2 \\bigg) +\\sum_{{|j|> 16\\log^{\\theta}T \\log N} } \\frac{1}{1+|j|^A} \\bigg(\\sum_{i\\in \\mathcal{I}} \\Big|D_i\\Big(\\frac{1}{2}+i\\tau+\\frac{2\\pi i j}{8\\log N}\\Big)\\Big|^2 \\bigg)", "target_citation_content": "L.-P. Arguin, P.~Bourgade, and M.~Radziwi艂艂. \\newblock The Fyodorov-Hiary-Keating conjecture. I. \\newblock \\em arXiv:2007.00988, 2020."}}
{"id": "2405.06474v1_gap_1", "arxiv_id": "2405.06474v1", "title": "The Fyodorov-Hiary-Keating Conjecture on Mesoscopic Intervals", "publication_date": "2024-05-10", "problem_input": {"global_context": {"setup": "Let $T$ be large and $\\tau$ be uniformly distributed on $[T, 2T]$. Let $t = \\log \\log T$ and $\\theta \\in (-1, 0]$. Define the Dirichlet sum approximations $S_k(h) = \\sum_{\\log p \\leq e^k} \\Re(p^{-(1/2+i(\\tau+h))} + \\frac{1}{2}p^{-(1+2i(\\tau+h))})$. Define the shifted random walk $\\mathscr{S}_k = S_{t_\\theta + k} - S_{t_\\theta}$ where $t_\\theta = |\\theta|t$.", "goal": "Derive precise upper bounds for the maximum $\\max_{|h|\\leq \\log^\\theta T}|\\zeta(\\frac{1}{2}+i(\\tau+h))|$ and the second moment $\\int_{|h|\\leq \\log^\\theta T} |\\zeta(\\frac{1}{2}+i(\\tau+h))|^2 dh$ on mesoscopic intervals."}, "local_context": {"anchor_latex": "\\E{|\\tilde{S}_k(h)-\\tilde{S}_j(h)|^{2q}}\\ll q!(k-j+1)^q", "gap_objective": "Bound the 2q-th moment of the difference of the Dirichlet polynomials \\tilde{S}_k and \\tilde{S}_j for 2q <= e^{t-k}."}}, "ground_truth": {"target_citation_key": "SoundMoments", "target_lemma_latex": "Lemma 3 in \\cite{SoundMoments}", "target_citation_content": "K.~Soundararajan. \\newblock Moments of the Riemann zeta function. \\newblock \\em Annals of Mathematics, 170(2):981--993, 2009."}}
{"id": "2405.06474v1_gap_2", "arxiv_id": "2405.06474v1", "title": "The Fyodorov-Hiary-Keating Conjecture on Mesoscopic Intervals", "publication_date": "2024-05-10", "problem_input": {"global_context": {"setup": "Let $T$ be large and $\\tau$ be uniformly distributed on $[T, 2T]$. Let $t = \\log \\log T$ and $\\theta \\in (-1, 0]$. Define the Dirichlet sum approximations $S_k(h) = \\sum_{\\log p \\leq e^k} \\Re(p^{-(1/2+i(\\tau+h))} + \\frac{1}{2}p^{-(1+2i(\\tau+h))})$. Define the shifted random walk $\\mathscr{S}_k = S_{t_\\theta + k} - S_{t_\\theta}$ where $t_\\theta = |\\theta|t$.", "goal": "Derive precise upper bounds for the maximum $\\max_{|h|\\leq \\log^\\theta T}|\\zeta(\\frac{1}{2}+i(\\tau+h))|$ and the second moment $\\int_{|h|\\leq \\log^\\theta T} |\\zeta(\\frac{1}{2}+i(\\tau+h))|^2 dh$ on mesoscopic intervals."}, "local_context": {"anchor_latex": "\\P{|\\tilde{S}_k(h)-\\tilde{S}_j|>V}\\ll \\frac{V}{(k-j+1)^{1/2}}\\exp\\left(-\\frac{V^2}{k-j+1}\\right)", "gap_objective": "Estimates for the moments of the increments of the real part of the Dirichlet sum $S_k(h)$."}}, "ground_truth": {"target_citation_key": "FHK1", "target_lemma_latex": "\\E{|S_k(h)-S_{j}(h)|^{2q}} \\ll \\frac{(2q)!}{2^qq!}\\left(\\frac{k-j}{2}\\right)^{q}", "target_citation_content": "L.-P. Arguin, P.~Bourgade, and M.~Radziwi艂艂. \\newblock The Fyodorov-Hiary-Keating conjecture. I. \\newblock \\em arXiv:2007.00988, 2020."}}
{"id": "2405.06474v1_gap_3", "arxiv_id": "2405.06474v1", "title": "The Fyodorov-Hiary-Keating Conjecture on Mesoscopic Intervals", "publication_date": "2024-05-10", "problem_input": {"global_context": {"setup": "Let $T$ be large and $\\tau$ be uniformly distributed on $[T, 2T]$. Let $t = \\log \\log T$ and $\\theta \\in (-1, 0]$. Define the Dirichlet sum approximations $S_k(h) = \\sum_{\\log p \\leq e^k} \\Re(p^{-(1/2+i(\\tau+h))} + \\frac{1}{2}p^{-(1+2i(\\tau+h))})$. Define the shifted random walk $\\mathscr{S}_k = S_{t_\\theta + k} - S_{t_\\theta}$ where $t_\\theta = |\\theta|t$.", "goal": "Derive precise upper bounds for the maximum $\\max_{|h|\\leq \\log^\\theta T}|\\zeta(\\frac{1}{2}+i(\\tau+h))|$ and the second moment $\\int_{|h|\\leq \\log^\\theta T} |\\zeta(\\frac{1}{2}+i(\\tau+h))|^2 dh$ on mesoscopic intervals."}, "local_context": {"anchor_latex": "A(s)=\\sum_{\\substack{n\\leq N \\\\ p|n\\implies p\\leq w}} \\frac{a(n)}{n^s}\\text{ and } B(s)=\\sum_{\\substack{n\\leq N \\\\ p|n\\implies p> w}}\\frac{b(n)}{n^s} \\quad \\text{with } N\\leq T^{1/4}", "gap_objective": "Prove that the expectation of the product of the squared magnitudes of Dirichlet polynomials supported on disjoint sets of primes factorizes (decouples), i.e., $\\mathbb{E}[|A|^2|B|^2] \\approx \\mathbb{E}[|A|^2]\\mathbb{E}[|B|^2]$."}}, "ground_truth": {"target_citation_key": "MVMV", "target_lemma_latex": "\\int_0^T \\bigg|\\sum_{n=1}^N a_n n^{-it}\\bigg|^2 dt = \\sum_{n=1}^N |a_n|^2 (T + O(N))", "target_citation_content": "H.~L. Montgomery and R.~C. Vaughan. \\newblock Hilbert鈥檚 inequality. \\newblock \\em Journal of The London Mathematical Society-second Series, pages 73--82, 1974."}}
{"id": "2405.06474v1_gap_4", "arxiv_id": "2405.06474v1", "title": "The Fyodorov-Hiary-Keating Conjecture on Mesoscopic Intervals", "publication_date": "2024-05-10", "problem_input": {"global_context": {"setup": "Let $T$ be large and $\\tau$ be uniformly distributed on $[T, 2T]$. Let $t = \\log \\log T$ and $\\theta \\in (-1, 0]$. Define the Dirichlet sum approximations $S_k(h) = \\sum_{\\log p \\leq e^k} \\Re(p^{-(1/2+i(\\tau+h))} + \\frac{1}{2}p^{-(1+2i(\\tau+h))})$. Define the shifted random walk $\\mathscr{S}_k = S_{t_\\theta + k} - S_{t_\\theta}$ where $t_\\theta = |\\theta|t$.", "goal": "Derive precise upper bounds for the maximum $\\max_{|h|\\leq \\log^\\theta T}|\\zeta(\\frac{1}{2}+i(\\tau+h))|$ and the second moment $\\int_{|h|\\leq \\log^\\theta T} |\\zeta(\\frac{1}{2}+i(\\tau+h))|^2 dh$ on mesoscopic intervals."}, "local_context": {"anchor_latex": "S_{k}(h)=\\sum_{\\log p\\leq e^{k}} \\Re\\left(\\frac{1}{p^{1/2+i(\\tau+h)}}+\\frac{1}{2}\\frac{1}{p^{1+2i(\\tau+h)}}\\right), \\quad k\\leq t", "gap_objective": "Compute the covariance $\\mathbb{E}[S_k(h)S_k(h')]$ of the process approximating the logarithm of the zeta function."}}, "ground_truth": {"target_citation_key": "AOR", "target_lemma_latex": "\\E{S_k(h)S_k(h')}= \\frac{1}{2}\\sum_{\\log p\\leq e^k} \\frac{\\cos(|h-h'|\\log p)}{p}+O\\left(\\frac{\\exp(e^{k})}{T}\\right)", "target_citation_content": "L.-P. Arguin, F.~Ouimet, and M.~Radziwi艂艂. \\newblock Moments of the Riemann zeta function on short intervals of the critical line. \\newblock \\em The Annals of Probability, 49(6):3106 -- 3141, 2021."}}
{"id": "2405.06474v1_gap_5", "arxiv_id": "2405.06474v1", "title": "The Fyodorov-Hiary-Keating Conjecture on Mesoscopic Intervals", "publication_date": "2024-05-10", "problem_input": {"global_context": {"setup": "Let $T$ be large and $\\tau$ be uniformly distributed on $[T, 2T]$. Let $t = \\log \\log T$ and $\\theta \\in (-1, 0]$. Define the Dirichlet sum approximations $S_k(h) = \\sum_{\\log p \\leq e^k} \\Re(p^{-(1/2+i(\\tau+h))} + \\frac{1}{2}p^{-(1+2i(\\tau+h))})$. Define the shifted random walk $\\mathscr{S}_k = S_{t_\\theta + k} - S_{t_\\theta}$ where $t_\\theta = |\\theta|t$.", "goal": "Derive precise upper bounds for the maximum $\\max_{|h|\\leq \\log^\\theta T}|\\zeta(\\frac{1}{2}+i(\\tau+h))|$ and the second moment $\\int_{|h|\\leq \\log^\\theta T} |\\zeta(\\frac{1}{2}+i(\\tau+h))|^2 dh$ on mesoscopic intervals."}, "local_context": {"anchor_latex": "\\int_{0}^{M} e^{2V}\\mathbb{P}\\left\\{\\log |\\zeta_\\tau(h)|>V\\right\\} \\mathrm{d}V", "gap_objective": "Bound the integrand \\( e^{2V}\\mathbb{P}\\{\\log |\\zeta_\\tau(h)|>V\\} \\) using a large deviation estimate for the Riemann zeta function."}}, "ground_truth": {"target_citation_key": "arguinbailey1", "target_lemma_latex": "\\frac{1}{T}\\textrm{meas}\\{t\\in [T,2T]: \\log|\\zeta(1/2+ \\textrm{i} t)|>V\\}\\ll \\frac{1}{\\sqrt{\\log\\log T}} e^{-V^2/\\log\\log T}", "target_citation_content": "L.-P. Arguin and E.~Bailey. \\newblock Large Deviation Estimates of Selberg鈥檚 Central Limit Theorem and Applications. \\newblock \\em International Mathematics Research Notices, 2023(23):20574--20612, 07 2023."}}
{"id": "2405.06474v1_gap_6", "arxiv_id": "2405.06474v1", "title": "The Fyodorov-Hiary-Keating Conjecture on Mesoscopic Intervals", "publication_date": "2024-05-10", "problem_input": {"global_context": {"setup": "Let $T$ be large and $\\tau$ be uniformly distributed on $[T, 2T]$. Let $t = \\log \\log T$ and $\\theta \\in (-1, 0]$. Define the Dirichlet sum approximations $S_k(h) = \\sum_{\\log p \\leq e^k} \\Re(p^{-(1/2+i(\\tau+h))} + \\frac{1}{2}p^{-(1+2i(\\tau+h))})$. Define the shifted random walk $\\mathscr{S}_k = S_{t_\\theta + k} - S_{t_\\theta}$ where $t_\\theta = |\\theta|t$.", "goal": "Derive precise upper bounds for the maximum $\\max_{|h|\\leq \\log^\\theta T}|\\zeta(\\frac{1}{2}+i(\\tau+h))|$ and the second moment $\\int_{|h|\\leq \\log^\\theta T} |\\zeta(\\frac{1}{2}+i(\\tau+h))|^2 dh$ on mesoscopic intervals."}, "local_context": {"anchor_latex": "\\mathbb{P}\\big\\{\\mathscr{S}_{t_1}>\\kappa t_1+\\mathcal{B}-\\log t,\\, \n\\mathscr{S}_k<U_A(k)\\,\\forall k\\leq t_1\\big\\} \\ll \n        \\frac{A\\big(U_A(t_1)-V\\big(\\tfrac{t_1}{t(1+\\theta)}\\big)\\big)}{t_1}\\frac{e^{-V^2/t(1+\\theta)}}{\\sqrt{t(1+\\theta)}}\\big(t(1+\\theta)\\big)^{-\\delta}", "gap_objective": "Bound the probability that the random walk $\\mathscr{S}_{t_1}$ ends in a specific region while staying below the barrier $U_A(k)$ for all steps $k \\le t_1$."}}, "ground_truth": {"target_citation_key": "FHK1", "target_lemma_latex": "\\P{S_n \\in [y, y+1], \\max_{k\\le n} (S_k - \\frac{k}{n} y) \\le b} \\ll \\frac{(1+b)(1+b+y)}{n} \\frac{e^{-y^2/2n}}{\\sqrt{n}}", "target_citation_content": "L.-P. Arguin, P.~Bourgade, and M.~Radziwi艂艂. \\newblock The Fyodorov-Hiary-Keating conjecture. I. \\newblock \\em arXiv:2007.00988, 2020."}}
{"id": "2405.06474v1_gap_7", "arxiv_id": "2405.06474v1", "title": "The Fyodorov-Hiary-Keating Conjecture on Mesoscopic Intervals", "publication_date": "2024-05-10", "problem_input": {"global_context": {"setup": "Let $T$ be large and $\\tau$ be uniformly distributed on $[T, 2T]$. Let $t = \\log \\log T$ and $\\theta \\in (-1, 0]$. Define the Dirichlet sum approximations $S_k(h) = \\sum_{\\log p \\leq e^k} \\Re(p^{-(1/2+i(\\tau+h))} + \\frac{1}{2}p^{-(1+2i(\\tau+h))})$. Define the shifted random walk $\\mathscr{S}_k = S_{t_\\theta + k} - S_{t_\\theta}$ where $t_\\theta = |\\theta|t$.", "goal": "Derive precise upper bounds for the maximum $\\max_{|h|\\leq \\log^\\theta T}|\\zeta(\\frac{1}{2}+i(\\tau+h))|$ and the second moment $\\int_{|h|\\leq \\log^\\theta T} |\\zeta(\\frac{1}{2}+i(\\tau+h))|^2 dh$ on mesoscopic intervals."}, "local_context": {"anchor_latex": "\\P{H^\\theta\\cap G_A\\cap G_\\ell\\setminus G_{\\ell+1}} \\ll \\frac{A\\big(U_A(t_1)-V\\big(\\tfrac{t_1}{t(1+\\theta)}\\big)\\big)}{t_1}\\frac{e^{-V^2/t(1+\\theta)}}{\\sqrt{t(1+\\theta)}}\\big(\\log_\\ell t(1+\\theta)\\big)^{-\\delta} \\quad \\text{and} \\quad \\P{H\\cap G_A \\cap G_\\mathcal{L}}\\ll \\frac{A\\big(U_A(t_1)-V\\big(\\tfrac{t_1}{t(1+\\theta)}\\big)\\big)}{t_1}\\frac{e^{-V^2/t(1+\\theta)}}{\\sqrt{t(1+\\theta)}}", "gap_objective": "Prove the large deviation estimates for the intermediate and final recursive steps in the presence of the barrier event $G_A$."}}, "ground_truth": {"target_citation_key": "arguinbailey1", "target_lemma_latex": "Propositions 2.2 and 2.3 in \\cite{arguinbailey1}", "target_citation_content": "L.-P. Arguin and E.~Bailey. \\newblock Large Deviation Estimates of Selberg鈥檚 Central Limit Theorem and Applications. \\newblock \\em International Mathematics Research Notices, 2023(23):20574--20612, 07 2023."}}
{"id": "2410.05220v1_gap_0", "arxiv_id": "2410.05220v1", "title": "Cutoff phenomenon for asymmetric zero range process with monotone rates", "publication_date": "2024-10-07", "problem_input": {"global_context": {"setup": "The Asymmetric Zero Range Process (ZRP) is defined on the segment $I_N = \\llbracket 1,N \\rrbracket$ with $k$ particles. The generator is given by $\\mathcal{A}_N J(\\eta) = \\sum_{i=1}^{N-1} p g(\\eta(i)) (J(\\eta^{i,i+1})-J(\\eta)) + \\sum_{i=2}^{N} q g(\\eta(i)) (J(\\eta^{i,i-1})-J(\\eta))$, where $g$ is a non-decreasing Lipschitz rate function with $g(0)=0 < g(1)$. The macroscopic density is $\\alpha = \\lim_{N \\to \\infty} k/N$. The macroscopic equilibrium time is defined as $T_{eq,p,\\alpha} = \\frac{1}{p-q} \\inf\\{t >0, U^\\alpha(t,dx) \\leq \\alpha \\ind_{x>1}\\}$ where $U^\\alpha$ is the solution to the associated Hamilton-Jacobi equation.", "goal": "Theorem 3: Under strict convexity (with $p=1, g^\\star=g(1)$) or strict concavity (with strong asymmetry condition) of the flux $\\Phi$, the mixing time satisfies $\\lim_{N \\to \\infty, k/N \\to \\alpha} \\frac{T_{\\text{mix}}^{N, k}(\\theta)}{N} = T_{eq,p,\\alpha}$ for any precision $\\theta \\in (0,1)$."}, "local_context": {"anchor_latex": "\\partial_t \\varphi(t_0,x_0) + \\Phi(\\partial_x \\varphi (t_0,x_0)) =0", "gap_objective": "Uniqueness of the Barron-Jensen viscosity solution for the Hamilton-Jacobi equation"}}, "ground_truth": {"target_citation_key": "Barles1994SolutionsDV", "target_lemma_latex": "Assume that U_0 is a l.s.c bounded function. There exists at most one l.s.c function U which satisfies both (BJ) and u(x, 0)=u_0 \\quad \\text { on } \\mathbb{R}^N.", "target_citation_content": "G.~Barles. \\newblock \\em Solutions de viscosité des équations de Hamilton-Jacobi, volume~17 of \\em Mathématiques \\& Applications. \\newblock Springer-Verlag, Paris, 1994."}}
{"id": "2410.05220v1_gap_1", "arxiv_id": "2410.05220v1", "title": "Cutoff phenomenon for asymmetric zero range process with monotone rates", "publication_date": "2024-10-07", "problem_input": {"global_context": {"setup": "The Asymmetric Zero Range Process (ZRP) is defined on the segment $I_N = \\llbracket 1,N \\rrbracket$ with $k$ particles. The generator is given by $\\mathcal{A}_N J(\\eta) = \\sum_{i=1}^{N-1} p g(\\eta(i)) (J(\\eta^{i,i+1})-J(\\eta)) + \\sum_{i=2}^{N} q g(\\eta(i)) (J(\\eta^{i,i-1})-J(\\eta))$, where $g$ is a non-decreasing Lipschitz rate function with $g(0)=0 < g(1)$. The macroscopic density is $\\alpha = \\lim_{N \\to \\infty} k/N$. The macroscopic equilibrium time is defined as $T_{eq,p,\\alpha} = \\frac{1}{p-q} \\inf\\{t >0, U^\\alpha(t,dx) \\leq \\alpha \\ind_{x>1}\\}$ where $U^\\alpha$ is the solution to the associated Hamilton-Jacobi equation.", "goal": "Theorem 3: Under strict convexity (with $p=1, g^\\star=g(1)$) or strict concavity (with strong asymmetry condition) of the flux $\\Phi$, the mixing time satisfies $\\lim_{N \\to \\infty, k/N \\to \\alpha} \\frac{T_{\\text{mix}}^{N, k}(\\theta)}{N} = T_{eq,p,\\alpha}$ for any precision $\\theta \\in (0,1)$."}, "local_context": {"anchor_latex": "U(t,x)=\\inf _{y \\in \\mathbb{R}}\\left(U_0(y)+t \\Psi\\left(\\frac{x-y}{t}\\right)\\right)", "gap_objective": "The stability of the Hopf-Lax formula under vague convergence of the initial data is required to extend the solution concept to measure-valued initial data."}}, "ground_truth": {"target_citation_key": "demengelserredoi:10.1080/03605309108820758", "target_lemma_latex": "\\text{Given a sequence } (u_{0,n}) \\text{ bounded in } L^1(\\mathbb{R}) \\text{ and converging vaguely to a measure } u_{0,\\infty}, \\text{ let } \\forall n\\in \\mathbb{N} \\cup \\{\\infty\\}, \\qquad U_n(t,x)=\\inf _{y \\in \\mathbb{R}}\\left(\\int_{(-\\infty,y)} u_{0,n}(z)dz+t \\Psi\\left(\\frac{x-y}{t}\\right)\\right). \\text{ Then, for any } t\\geq 0, x \\in \\operatorname{Cont}(U(t)), (U_n(t,x)) \\text{ converge to } U_\\infty(t,x) \\text{ defined by the Hopf--Lax formula.}", "target_citation_content": "F.~Demengel and D.~Serre. \\newblock Nonvanishing singular parts of measure valued solutions for scalar hyperbolic equations. \\newblock \\em Comm. Partial Differential Equations, 16(2-3):221--254, 1991."}}
{"id": "2410.05220v1_gap_2", "arxiv_id": "2410.05220v1", "title": "Cutoff phenomenon for asymmetric zero range process with monotone rates", "publication_date": "2024-10-07", "problem_input": {"global_context": {"setup": "The Asymmetric Zero Range Process (ZRP) is defined on the segment $I_N = \\llbracket 1,N \\rrbracket$ with $k$ particles. The generator is given by $\\mathcal{A}_N J(\\eta) = \\sum_{i=1}^{N-1} p g(\\eta(i)) (J(\\eta^{i,i+1})-J(\\eta)) + \\sum_{i=2}^{N} q g(\\eta(i)) (J(\\eta^{i,i-1})-J(\\eta))$, where $g$ is a non-decreasing Lipschitz rate function with $g(0)=0 < g(1)$. The macroscopic density is $\\alpha = \\lim_{N \\to \\infty} k/N$. The macroscopic equilibrium time is defined as $T_{eq,p,\\alpha} = \\frac{1}{p-q} \\inf\\{t >0, U^\\alpha(t,dx) \\leq \\alpha \\ind_{x>1}\\}$ where $U^\\alpha$ is the solution to the associated Hamilton-Jacobi equation.", "goal": "Theorem 3: Under strict convexity (with $p=1, g^\\star=g(1)$) or strict concavity (with strong asymmetry condition) of the flux $\\Phi$, the mixing time satisfies $\\lim_{N \\to \\infty, k/N \\to \\alpha} \\frac{T_{\\text{mix}}^{N, k}(\\theta)}{N} = T_{eq,p,\\alpha}$ for any precision $\\theta \\in (0,1)$."}, "local_context": {"anchor_latex": "\\forall t\\geq 0, x \\in \\operatorname{Cont}(U(t)), \\quad (U_n(t,x)) \\text{ converge to } U_\\infty(t,x) \\text{ defined by the Hopf--Lax formula}", "gap_objective": "Prove that the function defined by the Hopf-Lax formula for measure-valued initial data is the unique Barron-Jensen viscosity solution."}}, "ground_truth": {"target_citation_key": "BarronJensen", "target_lemma_latex": "Stability of Barron-Jensen viscosity solutions", "target_citation_content": "E.~N. Barron and R.~Jensen. \\newblock Semicontinuous viscosity solutions for Hamilton-Jacobi equations with convex Hamiltonians. \\newblock \\em Comm. Partial Differential Equations, 15(12):1713--1742, 1990."}}
{"id": "2410.05220v1_gap_3", "arxiv_id": "2410.05220v1", "title": "Cutoff phenomenon for asymmetric zero range process with monotone rates", "publication_date": "2024-10-07", "problem_input": {"global_context": {"setup": "The Asymmetric Zero Range Process (ZRP) is defined on the segment $I_N = \\llbracket 1,N \\rrbracket$ with $k$ particles. The generator is given by $\\mathcal{A}_N J(\\eta) = \\sum_{i=1}^{N-1} p g(\\eta(i)) (J(\\eta^{i,i+1})-J(\\eta)) + \\sum_{i=2}^{N} q g(\\eta(i)) (J(\\eta^{i,i-1})-J(\\eta))$, where $g$ is a non-decreasing Lipschitz rate function with $g(0)=0 < g(1)$. The macroscopic density is $\\alpha = \\lim_{N \\to \\infty} k/N$. The macroscopic equilibrium time is defined as $T_{eq,p,\\alpha} = \\frac{1}{p-q} \\inf\\{t >0, U^\\alpha(t,dx) \\leq \\alpha \\ind_{x>1}\\}$ where $U^\\alpha$ is the solution to the associated Hamilton-Jacobi equation.", "goal": "Theorem 3: Under strict convexity (with $p=1, g^\\star=g(1)$) or strict concavity (with strong asymmetry condition) of the flux $\\Phi$, the mixing time satisfies $\\lim_{N \\to \\infty, k/N \\to \\alpha} \\frac{T_{\\text{mix}}^{N, k}(\\theta)}{N} = T_{eq,p,\\alpha}$ for any precision $\\theta \\in (0,1)$."}, "local_context": {"anchor_latex": "\\bar \\xi_0^\\varepsilon \\sim \\otimes_{i \\in\\Z} \\nu\\left(N \\left[ \\bar U_{0,\\frac{i}{N}+\\frac{1}{2N}}^\\varepsilon - \\bar U_{0,{\\frac{i}{N}-\\frac{1}{2N}}}^\\varepsilon \\right]\\right) \\quad \\text{and} \\quad \\underline \\xi_0^\\varepsilon \\sim \\otimes_{i \\in\\Z} \\nu\\left(N \\left[ \\underline U_{0,\\frac{i}{N}+\\frac{1}{2N}}^\\varepsilon - \\underline U_{0,\\frac{i}{N}-\\frac{1}{2N}}^\\varepsilon\\right]\\right)", "gap_objective": "Determine the hydrodynamic limit of the processes \\underline{\\xi}^\\varepsilon and \\bar{\\xi}^\\varepsilon, which are initialized with regular (Lipschitz/bounded density) profiles."}}, "ground_truth": {"target_citation_key": "Rezakhanlou1991HydrodynamicLF", "target_lemma_latex": "\\text{Hydrodynamic limit for attractive particle systems on } \\mathbf{Z}^d: \\text{ If the initial configuration is sampled according to a local equilibrium } \\otimes_{i \\in\\Z} \\nu\\left(u_{i, N}\\right) \\text{ where } \\lim _{N \\rightarrow \\infty} \\int_{|x| \\leq \\ell}\\left|u_{[x N], N}-u_0(x)\\right| d x=0 \\text{ and } u_0 \\text{ has a bounded density, the limit corresponds to the solution of the associated conservation law/Hamilton-Jacobi equation.}", "target_citation_content": "F.~Rezakhanlou. \\newblock Hydrodynamic limit for attractive particle systems on $\\bf Z^d$. \\newblock \\em Comm. Math. Phys., 140(3):417--448, 1991."}}
{"id": "2410.05220v1_gap_4", "arxiv_id": "2410.05220v1", "title": "Cutoff phenomenon for asymmetric zero range process with monotone rates", "publication_date": "2024-10-07", "problem_input": {"global_context": {"setup": "The Asymmetric Zero Range Process (ZRP) is defined on the segment $I_N = \\llbracket 1,N \\rrbracket$ with $k$ particles. The generator is given by $\\mathcal{A}_N J(\\eta) = \\sum_{i=1}^{N-1} p g(\\eta(i)) (J(\\eta^{i,i+1})-J(\\eta)) + \\sum_{i=2}^{N} q g(\\eta(i)) (J(\\eta^{i,i-1})-J(\\eta))$, where $g$ is a non-decreasing Lipschitz rate function with $g(0)=0 < g(1)$. The macroscopic density is $\\alpha = \\lim_{N \\to \\infty} k/N$. The macroscopic equilibrium time is defined as $T_{eq,p,\\alpha} = \\frac{1}{p-q} \\inf\\{t >0, U^\\alpha(t,dx) \\leq \\alpha \\ind_{x>1}\\}$ where $U^\\alpha$ is the solution to the associated Hamilton-Jacobi equation.", "goal": "Theorem 3: Under strict convexity (with $p=1, g^\\star=g(1)$) or strict concavity (with strong asymmetry condition) of the flux $\\Phi$, the mixing time satisfies $\\lim_{N \\to \\infty, k/N \\to \\alpha} \\frac{T_{\\text{mix}}^{N, k}(\\theta)}{N} = T_{eq,p,\\alpha}$ for any precision $\\theta \\in (0,1)$."}, "local_context": {"anchor_latex": "\\text{The sequence } (\\mathcal{Q}_N)_N, \\text{ defined as the law of } t \\rightarrow \\rho_{N,\\frac{N}{p-q}t}, \\text{ is to be shown tight in } \\mathbb{D}(\\mathbb{R}_+, \\mathcal{M}_+([0,1])).", "gap_objective": "Reduce the problem of proving tightness for a sequence of measure-valued processes to verifying tightness for scalar-valued processes obtained by integrating against test functions."}}, "ground_truth": {"target_citation_key": "kipnis1999sli", "target_lemma_latex": "\\text{The sequence } (\\rho_N)_N \\text{ is tight in } \\mathbb{D}(\\mathbb{R}_+, \\mathcal{M}_+) \\text{ if for any } J \\in \\mathcal{C}^\\infty([0,1]), \\text{ the sequence } (\\langle \\rho_N, J \\rangle)_N \\text{ is tight in } \\mathbb{D}(\\mathbb{R}_+, \\mathbb{R}).", "target_citation_content": "C.~Kipnis and C.~Landim. \\newblock \\em Scaling limits of interacting particle systems, volume 320 of \\em Grundlehren der mathematischen Wissenschaften. \\newblock Springer-Verlag, Berlin, 1999."}}
{"id": "2409.18744v3_gap_0", "arxiv_id": "2409.18744v3", "title": "$p$-Brownian motion and the $p$-Laplacian", "publication_date": "2024-09-27", "problem_input": {"global_context": {"setup": "The paper investigates the parabolic $p$-Laplace equation $\\partial_t u = \\text{div}(|\\nabla u|^{p-2} \\nabla u)$ for $p>2$ on $(0,\\infty)\\times\\mathbb{R}^d$. This equation is formulated as a nonlinear Fokker-Planck equation $\\partial_t u = \\partial_{x_i}\\partial_{x_j}(a_{ij}(u)u) - \\partial_{x_i}(b_i(u)u)$. The authors utilize the explicit Barenblatt fundamental solutions $w^y(t,x)$ and associate them with a McKean-Vlasov Stochastic Differential Equation (SDE) $dX(t) = \\nabla(|\\nabla u|^{p-2})dt + \\sqrt{2}|\\nabla u|^{\\frac{p-2}{2}}dW(t)$.", "goal": "To construct a nonlinear Markov process $(P_y)_{y\\in\\mathbb{R}^d}$, termed '$p$-Brownian motion', consisting of the path laws of solutions to the associated McKean-Vlasov SDE, where the time marginals correspond to the Barenblatt solutions of the $p$-Laplace equation."}, "local_context": {"anchor_latex": "u \\text{ is a nonnegative solution to } \\eqref{e1.2} \\text{ with initial condition } \\nu \\in \\Mscr^+_b, \\; \\esssup_{t>0}|u(t)|_{L^1(\\rrd)} <\\infty, \\text{ and } \\nabla u \\in L^{p-1}_{\\textup{loc}}([0,\\infty);L^{p-1}_{\\textup{loc}}(\\R^d;\\R^d))", "gap_objective": "Establish that u admits a unique vaguely continuous representative on [0,\\infty)"}}, "ground_truth": {"target_citation_key": "36a", "target_lemma_latex": "\\text{Every nonnegative distributional solution } u \\text{ (with suitable integrability conditions on the flux) has a unique vaguely continuous } dt\\text{-version } \\tilde{u} \\text{ on } [0,\\infty).", "target_citation_content": "Rehmeier, M., Flow selections for (nonlinear) Fokker--Planck--Kolmogorov equations, \\it J.~Differential Equations, 328 (2022), 105-132."}}
{"id": "2409.18744v3_gap_1", "arxiv_id": "2409.18744v3", "title": "$p$-Brownian motion and the $p$-Laplacian", "publication_date": "2024-09-27", "problem_input": {"global_context": {"setup": "The paper investigates the parabolic $p$-Laplace equation $\\partial_t u = \\text{div}(|\\nabla u|^{p-2} \\nabla u)$ for $p>2$ on $(0,\\infty)\\times\\mathbb{R}^d$. This equation is formulated as a nonlinear Fokker-Planck equation $\\partial_t u = \\partial_{x_i}\\partial_{x_j}(a_{ij}(u)u) - \\partial_{x_i}(b_i(u)u)$. The authors utilize the explicit Barenblatt fundamental solutions $w^y(t,x)$ and associate them with a McKean-Vlasov Stochastic Differential Equation (SDE) $dX(t) = \\nabla(|\\nabla u|^{p-2})dt + \\sqrt{2}|\\nabla u|^{\\frac{p-2}{2}}dW(t)$.", "goal": "To construct a nonlinear Markov process $(P_y)_{y\\in\\mathbb{R}^d}$, termed '$p$-Brownian motion', consisting of the path laws of solutions to the associated McKean-Vlasov SDE, where the time marginals correspond to the Barenblatt solutions of the $p$-Laplace equation."}, "local_context": {"anchor_latex": "u(t,x)dx \\text{ solves the linear FP equation with coefficients } a_{ij}(t,x)=\\delta_{ij}|\\nabla u(t,x)|^{p-2}, b_i(t,x)=\\frac{\\partial}{\\partial x_i}(|\\nabla u(t,x)|^{p-2}) \\text{ in the sense of Definition } \\ref{dD.1}", "gap_objective": "Existence of a stochastic process X solving the corresponding SDE such that its time marginals match the solution u"}}, "ground_truth": {"target_citation_key": "43a", "target_lemma_latex": "\\text{Let } (\\mu_t)_{t\\ge0} \\text{ be a solution to the linear Fokker-Planck equation with coefficients } a, b. \\text{ Then there exists a solution } X=(X(t))_{t\\ge0} \\text{ to the corresponding SDE } dX_t = b(t,X_t)dt + \\sqrt{2}\\sigma(t,X_t)dW_t \\text{ such that } \\mathcal{L}_{X(t)}=\\mu_t.", "target_citation_content": "Trevisan, D., Well-posedness of multidimensional diffusion processes with weakly differentiable coefficients, \\it Electron. J. Probab., (2016), 21-41."}}
{"id": "2409.18744v3_gap_2", "arxiv_id": "2409.18744v3", "title": "$p$-Brownian motion and the $p$-Laplacian", "publication_date": "2024-09-27", "problem_input": {"global_context": {"setup": "The paper investigates the parabolic $p$-Laplace equation $\\partial_t u = \\text{div}(|\\nabla u|^{p-2} \\nabla u)$ for $p>2$ on $(0,\\infty)\\times\\mathbb{R}^d$. This equation is formulated as a nonlinear Fokker-Planck equation $\\partial_t u = \\partial_{x_i}\\partial_{x_j}(a_{ij}(u)u) - \\partial_{x_i}(b_i(u)u)$. The authors utilize the explicit Barenblatt fundamental solutions $w^y(t,x)$ and associate them with a McKean-Vlasov Stochastic Differential Equation (SDE) $dX(t) = \\nabla(|\\nabla u|^{p-2})dt + \\sqrt{2}|\\nabla u|^{\\frac{p-2}{2}}dW(t)$.", "goal": "To construct a nonlinear Markov process $(P_y)_{y\\in\\mathbb{R}^d}$, termed '$p$-Brownian motion', consisting of the path laws of solutions to the associated McKean-Vlasov SDE, where the time marginals correspond to the Barenblatt solutions of the $p$-Laplace equation."}, "local_context": {"anchor_latex": "w^y \\text{ is the unique nonnegative vaguely continuous solution to } \\eqref{e1.2} \\text{ in the sense of Definition \\ref{d2.1} with initial condition } \\delta_y", "gap_objective": "Prove the uniqueness of the nonnegative solution to the parabolic p-Laplace equation with a Dirac mass as initial condition."}}, "ground_truth": {"target_citation_key": "24a", "target_lemma_latex": "The solution to the Cauchy problem for the equation $u_t = \\text{div}(|\\nabla u|^{p-2}\\nabla u)$ with initial datum a Dirac mass is unique.", "target_citation_content": "Kamin, S., Vázquez, J.L., Fundamental solutions and asymptotic behaviour for the $p$-Laplacian equation, \\it Revista Matemática Iberoamericana, 4 (2) (1988), 339-354."}}
{"id": "2409.18744v3_gap_3", "arxiv_id": "2409.18744v3", "title": "$p$-Brownian motion and the $p$-Laplacian", "publication_date": "2024-09-27", "problem_input": {"global_context": {"setup": "The paper investigates the parabolic $p$-Laplace equation $\\partial_t u = \\text{div}(|\\nabla u|^{p-2} \\nabla u)$ for $p>2$ on $(0,\\infty)\\times\\mathbb{R}^d$. This equation is formulated as a nonlinear Fokker-Planck equation $\\partial_t u = \\partial_{x_i}\\partial_{x_j}(a_{ij}(u)u) - \\partial_{x_i}(b_i(u)u)$. The authors utilize the explicit Barenblatt fundamental solutions $w^y(t,x)$ and associate them with a McKean-Vlasov Stochastic Differential Equation (SDE) $dX(t) = \\nabla(|\\nabla u|^{p-2})dt + \\sqrt{2}|\\nabla u|^{\\frac{p-2}{2}}dW(t)$.", "goal": "To construct a nonlinear Markov process $(P_y)_{y\\in\\mathbb{R}^d}$, termed '$p$-Brownian motion', consisting of the path laws of solutions to the associated McKean-Vlasov SDE, where the time marginals correspond to the Barenblatt solutions of the $p$-Laplace equation."}, "local_context": {"anchor_latex": "(\\mu^{s,\\zeta}_t)_{t\\ge s} \\text{ is a weakly continuous probability solution to the nonlinear FPE \\eqref{e1.13} for each } (s,\\zeta)\\in[0,\\infty)\\times\\mathcal{P}_0 \\text{... Moreover, by Theorem \\ref{t5.10} below, condition (ii) of Theorem \\ref{t52} holds for all } (\\mu^{s,\\zeta}_t)_{t\\ge s} \\text{ with } (s,\\zeta)\\in[0,\\infty)\\times\\mathfrak{P_0}. \\text{ Since also the final condition of Corollary \\ref{c5.3} is satisfied}", "gap_objective": "To construct a unique nonlinear Markov process associated with the fundamental solutions of the p-Laplace equation by applying an abstract existence and uniqueness result."}}, "ground_truth": {"target_citation_key": "37a", "target_lemma_latex": "Let \\mathfrak{P}_0 \\subseteq \\Pscr_0 \\subseteq \\Pscr \\text{ and suppose } (\\mu^{s,\\zeta}_t)_{0\\leq s \\leq t, \\zeta \\in \\Pscr_0} \\text{ satisfies (i) ... but (ii) only for } (s,\\zeta) \\in [0,\\infty)\\times \\mathfrak{P}_0. \\text{ Further, assume } \\mu^{s,\\zeta}_t \\in \\mathfrak{P}_0 \\text{ for all triples } (s,t,\\zeta) \\text{ such that either } s \\leq t, \\zeta \\in \\mathfrak{P}_0 \\text{ or } s < t, \\zeta \\in \\Pscr_0. \\text{ Then, there is a nonlinear Markov process } (P_{s,\\zeta})_{s\\geq 0, \\zeta \\in \\Pscr_0} \\text{ with } (\\pi^s_t)_* P_{s,\\zeta} = \\mu^{s,\\zeta}_t, \\quad \\forall 0\\leq s \\leq t, \\zeta \\in \\Pscr_0, \\text{ consisting of solution path laws to \\eqref{e1.5}, \\eqref{e1.6}. The uniqueness-assertion for } P_{s,\\zeta} \\text{ of Theorem \\ref{t52} remains true for initial data } (s,\\zeta) \\text{ with } \\zeta\\in\\mathfrak{P}_0.", "target_citation_content": "Rehmeier, M., R\\\"ockner, M., On nonlinear Markov processes in the sense of McKean, \\it arXiv preprint 2212.12424, 2022."}}
{"id": "2409.18744v3_gap_4", "arxiv_id": "2409.18744v3", "title": "$p$-Brownian motion and the $p$-Laplacian", "publication_date": "2024-09-27", "problem_input": {"global_context": {"setup": "The paper investigates the parabolic $p$-Laplace equation $\\partial_t u = \\text{div}(|\\nabla u|^{p-2} \\nabla u)$ for $p>2$ on $(0,\\infty)\\times\\mathbb{R}^d$. This equation is formulated as a nonlinear Fokker-Planck equation $\\partial_t u = \\partial_{x_i}\\partial_{x_j}(a_{ij}(u)u) - \\partial_{x_i}(b_i(u)u)$. The authors utilize the explicit Barenblatt fundamental solutions $w^y(t,x)$ and associate them with a McKean-Vlasov Stochastic Differential Equation (SDE) $dX(t) = \\nabla(|\\nabla u|^{p-2})dt + \\sqrt{2}|\\nabla u|^{\\frac{p-2}{2}}dW(t)$.", "goal": "To construct a nonlinear Markov process $(P_y)_{y\\in\\mathbb{R}^d}$, termed '$p$-Brownian motion', consisting of the path laws of solutions to the associated McKean-Vlasov SDE, where the time marginals correspond to the Barenblatt solutions of the $p$-Laplace equation."}, "local_context": {"anchor_latex": "\\frac{\\pp\\vf_\\vp}{\\pp t}+(\\rho_\\vp+\\vp)\\Delta\\vf_\\vp=f-g_\\vp\\in L^{\\gamma_1}(Q_T)", "gap_objective": "To establish the Sobolev regularity $\\vf_\\vp \\in W^{2,\\gamma_1}(Q_T)$ (integrability of second spatial and first time derivatives) from the integrability of the source term."}}, "ground_truth": {"target_citation_key": "31a", "target_lemma_latex": "\\text{If } u \\text{ solves } \\frac{\\partial u}{\\partial t} + a(t,x)\\Delta u = F \\text{ with } F \\in L^q(Q_T) \\text{ and } a(t,x) \\ge \\lambda > 0, \\text{ then } u \\in W^{2,q}(Q_T).", "target_citation_content": "Lindqvist, P., \\it Notes on the $p$-Laplace Equation, Rep. Univ. Jyv\\\"askyl\\\"a Dep. Math. Stat., 102, University of Jyv\\\"askyl\\\"a, 2006, ii+90~pp."}}
{"id": "2405.05597v3_gap_0", "arxiv_id": "2405.05597v3", "title": "The empirical copula process in high dimensions: Stute's representation and applications", "publication_date": "2024-05-09", "problem_input": {"global_context": {"setup": "Let $\\bm X_1, \\dots, \\bm X_n$ be an i.i.d. sample from a $d$-dimensional random vector $\\bm X$ with continuous marginal cdfs $F_1, \\dots, F_d$ and unique copula $C$. The dimension $d=d_n$ is allowed to depend on $n$. The empirical copula is $\\hat C_n(\\bm u) = n^{-1} \\sum_{i=1}^n \\prod_{j=1}^d \\bm 1(\\hat U_{ij} \\le u_j)$, where $\\hat U_{ij}$ are the rescaled ranks. The empirical copula process is $\\Cb_n(\\bm u) = \\sqrt n \\{ \\hat C_n(\\bm u) - C(\\bm u) \\}$. Let $\\bar \\Cb_n(\\bm u) = \\alpha_{n}(\\bm u) - \\sum_{j=1}^d \\dot C_j(\\bm u) \\alpha_{nj}(u_j)$ be the linearized process, where $\\alpha_n$ is the standard empirical process based on the unobservable sample. We assume Condition 2.3 (Second-order regularity of $k$-variate margins), which controls the second-order partial derivatives of $C$ on $k$-variate margins. Let $W_k = \\{ \\bm u \\in [0,1]^d: |\\{j: u_j < 1\\}| \\le k \\}$.", "goal": "Theorem 2.4: Under the regularity conditions and if $\\log d = o(n^{1/3})$, then $\\sup_{\\bm u \\in W_k} |\\Cb_n(\\bm u)- \\bar \\Cb_n(\\bm u)| = O_\\as(n^{-1/4} (\\log (nd))^{3/4})$, providing a uniform linearization (Stute's representation) of the high-dimensional empirical copula process."}, "local_context": {"anchor_latex": "\\max_{I \\in \\mathcal I_2(d)} |\\sqrt{n} \\{ \\hat \\gamma_{n,I} - \\gamma_I\\} - S_{n,I}^\\gamma| = O_\\as(n^{-1/4}(\\log(nd))^{3/4})", "gap_objective": "To establish the distributional approximation (Kolmogorov distance) of the test statistic $T_n^\\gamma$ by the maximum of a Gaussian vector $Z_n^\\gamma$, using the fact that $T_n^\\gamma$ is approximated by the maximum of sums of independent variables $S_{n,I}^\\gamma$."}}, "ground_truth": {"target_citation_key": "Che22", "target_lemma_latex": "\\sup_{t \\in \\mathbb{R}} \\left| \\mathbb{P}\\left(\\max_{1 \\le j \\le p} \\frac{1}{\\sqrt{n}} \\sum_{i=1}^n X_{ij} \\le t\\right) - \\mathbb{P}\\left(\\max_{1 \\le j \\le p} Y_j \\le t\\right) \\right| \\to 0", "target_citation_content": "Chernozhuokov, V., Chetverikov, D., Kato, K., and Koike, Y. (2022). \\newblock Improved central limit theorem and bootstrap approximations in high dimensions. \\newblock \\em Ann. Statist., 50(5):2562--2586."}}
{"id": "2405.05597v3_gap_1", "arxiv_id": "2405.05597v3", "title": "The empirical copula process in high dimensions: Stute's representation and applications", "publication_date": "2024-05-09", "problem_input": {"global_context": {"setup": "Let $\\bm X_1, \\dots, \\bm X_n$ be an i.i.d. sample from a $d$-dimensional random vector $\\bm X$ with continuous marginal cdfs $F_1, \\dots, F_d$ and unique copula $C$. The dimension $d=d_n$ is allowed to depend on $n$. The empirical copula is $\\hat C_n(\\bm u) = n^{-1} \\sum_{i=1}^n \\prod_{j=1}^d \\bm 1(\\hat U_{ij} \\le u_j)$, where $\\hat U_{ij}$ are the rescaled ranks. The empirical copula process is $\\Cb_n(\\bm u) = \\sqrt n \\{ \\hat C_n(\\bm u) - C(\\bm u) \\}$. Let $\\bar \\Cb_n(\\bm u) = \\alpha_{n}(\\bm u) - \\sum_{j=1}^d \\dot C_j(\\bm u) \\alpha_{nj}(u_j)$ be the linearized process, where $\\alpha_n$ is the standard empirical process based on the unobservable sample. We assume Condition 2.3 (Second-order regularity of $k$-variate margins), which controls the second-order partial derivatives of $C$ on $k$-variate margins. Let $W_k = \\{ \\bm u \\in [0,1]^d: |\\{j: u_j < 1\\}| \\le k \\}$.", "goal": "Theorem 2.4: Under the regularity conditions and if $\\log d = o(n^{1/3})$, then $\\sup_{\\bm u \\in W_k} |\\Cb_n(\\bm u)- \\bar \\Cb_n(\\bm u)| = O_\\as(n^{-1/4} (\\log (nd))^{3/4})$, providing a uniform linearization (Stute's representation) of the high-dimensional empirical copula process."}, "local_context": {"anchor_latex": "\\lim_{n\\to\\infty}\\sup_{t \\in \\R} | \\Prob(T_n^\\gamma \\le t) - \\Prob(Z_n^\\gamma \\le t) | = 0, \\quad Z_n^\\gamma=\\max_{I \\in \\mathcal I_2(d)} |Y_{d,I}^\\gamma|", "gap_objective": "Derive the specific Gumbel limit distribution (Equation 3.3) for the maximum of the absolute values of the independent Gaussian variables $Y_{d,I}^\\gamma$."}}, "ground_truth": {"target_citation_key": "Deo72", "target_lemma_latex": "\\lim_{n \\to \\infty}\\Prob\\Big[ a_n \\Big( \\max_{1\\le i \\le n} |\\xi_i| - b_n \\Big) \\le t \\Big] = e^{-e^{-t}}", "target_citation_content": "Deo, C.~M. (1972). \\newblock Some limit theorems for maxima of absolute values of gaussian sequences. \\newblock \\em Sankhy膩: The Indian Journal of Statistics, Series A (1961-2002), 34(3):289--292."}}
{"id": "2405.05597v3_gap_2", "arxiv_id": "2405.05597v3", "title": "The empirical copula process in high dimensions: Stute's representation and applications", "publication_date": "2024-05-09", "problem_input": {"global_context": {"setup": "Let $\\bm X_1, \\dots, \\bm X_n$ be an i.i.d. sample from a $d$-dimensional random vector $\\bm X$ with continuous marginal cdfs $F_1, \\dots, F_d$ and unique copula $C$. The dimension $d=d_n$ is allowed to depend on $n$. The empirical copula is $\\hat C_n(\\bm u) = n^{-1} \\sum_{i=1}^n \\prod_{j=1}^d \\bm 1(\\hat U_{ij} \\le u_j)$, where $\\hat U_{ij}$ are the rescaled ranks. The empirical copula process is $\\Cb_n(\\bm u) = \\sqrt n \\{ \\hat C_n(\\bm u) - C(\\bm u) \\}$. Let $\\bar \\Cb_n(\\bm u) = \\alpha_{n}(\\bm u) - \\sum_{j=1}^d \\dot C_j(\\bm u) \\alpha_{nj}(u_j)$ be the linearized process, where $\\alpha_n$ is the standard empirical process based on the unobservable sample. We assume Condition 2.3 (Second-order regularity of $k$-variate margins), which controls the second-order partial derivatives of $C$ on $k$-variate margins. Let $W_k = \\{ \\bm u \\in [0,1]^d: |\\{j: u_j < 1\\}| \\le k \\}$.", "goal": "Theorem 2.4: Under the regularity conditions and if $\\log d = o(n^{1/3})$, then $\\sup_{\\bm u \\in W_k} |\\Cb_n(\\bm u)- \\bar \\Cb_n(\\bm u)| = O_\\as(n^{-1/4} (\\log (nd))^{3/4})$, providing a uniform linearization (Stute's representation) of the high-dimensional empirical copula process."}, "local_context": {"anchor_latex": "\\beta_n(\\bm u) = \\sum_{j=1}^d \\left( \\prod_{\\ell \\ne j} u_\\ell\\right) \\alpha_{nj}(u_j) \\quad \\text{so that} \\quad \\bar \\Cb_n = \\alpha_n - \\beta_n", "gap_objective": "Evaluate the modified Moebius transform \\widebar \\Mc_I of the process \\beta_n for indices |I| \\ge 2 to simplify the decomposition of \\bar \\Cb_n."}}, "ground_truth": {"target_citation_key": "GenRem04", "target_lemma_latex": "\\widebar \\Mc_I(\\beta_n)=0 \\quad \\text{for all } I \\text{ with } |I| \\ge 2", "target_citation_content": "Genest, C. and Rémillard, B. (2004). \\newblock Tests of independence and randomness based on the empirical copula process. \\newblock \\em Test, 13(2):335--370."}}
{"id": "2405.05597v3_gap_3", "arxiv_id": "2405.05597v3", "title": "The empirical copula process in high dimensions: Stute's representation and applications", "publication_date": "2024-05-09", "problem_input": {"global_context": {"setup": "Let $\\bm X_1, \\dots, \\bm X_n$ be an i.i.d. sample from a $d$-dimensional random vector $\\bm X$ with continuous marginal cdfs $F_1, \\dots, F_d$ and unique copula $C$. The dimension $d=d_n$ is allowed to depend on $n$. The empirical copula is $\\hat C_n(\\bm u) = n^{-1} \\sum_{i=1}^n \\prod_{j=1}^d \\bm 1(\\hat U_{ij} \\le u_j)$, where $\\hat U_{ij}$ are the rescaled ranks. The empirical copula process is $\\Cb_n(\\bm u) = \\sqrt n \\{ \\hat C_n(\\bm u) - C(\\bm u) \\}$. Let $\\bar \\Cb_n(\\bm u) = \\alpha_{n}(\\bm u) - \\sum_{j=1}^d \\dot C_j(\\bm u) \\alpha_{nj}(u_j)$ be the linearized process, where $\\alpha_n$ is the standard empirical process based on the unobservable sample. We assume Condition 2.3 (Second-order regularity of $k$-variate margins), which controls the second-order partial derivatives of $C$ on $k$-variate margins. Let $W_k = \\{ \\bm u \\in [0,1]^d: |\\{j: u_j < 1\\}| \\le k \\}$.", "goal": "Theorem 2.4: Under the regularity conditions and if $\\log d = o(n^{1/3})$, then $\\sup_{\\bm u \\in W_k} |\\Cb_n(\\bm u)- \\bar \\Cb_n(\\bm u)| = O_\\as(n^{-1/4} (\\log (nd))^{3/4})$, providing a uniform linearization (Stute's representation) of the high-dimensional empirical copula process."}, "local_context": {"anchor_latex": "U_{n,I} = \\frac1{n}\\sum_{1 \\le i_1 \ne i_2 \\le n} h_I(\\bm U_{i_1}, \\bm U_{i_2})", "gap_objective": "Derive the asymptotic distribution of the maximum of the degenerate U-statistics, \\max_{I \\in \\mathcal{I}_2(d)} U_{n,I}, in the high-dimensional regime."}}, "ground_truth": {"target_citation_key": "Drt20", "target_lemma_latex": "Theorem 4.2 in [Drt20]: \\lim_{n\\to\\infty}\\Prob\\Big( a_n \\max_{I\\in \\mathcal I_k(d)}U_{n,I} - b_n \\le y \\Big) = \\exp\\Big\\{ - C \\exp\\Big(-\\frac{y}2\\Big) \\Big\\}", "target_citation_content": "Drton, M., Han, F., and Shi, H. (2020). \\newblock High-dimensional consistent independence testing with maxima of rank correlations. \\newblock \\em The Annals of Statistics, 48(6):3206 -- 3227."}}
{"id": "2405.05597v3_gap_4", "arxiv_id": "2405.05597v3", "title": "The empirical copula process in high dimensions: Stute's representation and applications", "publication_date": "2024-05-09", "problem_input": {"global_context": {"setup": "Let $\\bm X_1, \\dots, \\bm X_n$ be an i.i.d. sample from a $d$-dimensional random vector $\\bm X$ with continuous marginal cdfs $F_1, \\dots, F_d$ and unique copula $C$. The dimension $d=d_n$ is allowed to depend on $n$. The empirical copula is $\\hat C_n(\\bm u) = n^{-1} \\sum_{i=1}^n \\prod_{j=1}^d \\bm 1(\\hat U_{ij} \\le u_j)$, where $\\hat U_{ij}$ are the rescaled ranks. The empirical copula process is $\\Cb_n(\\bm u) = \\sqrt n \\{ \\hat C_n(\\bm u) - C(\\bm u) \\}$. Let $\\bar \\Cb_n(\\bm u) = \\alpha_{n}(\\bm u) - \\sum_{j=1}^d \\dot C_j(\\bm u) \\alpha_{nj}(u_j)$ be the linearized process, where $\\alpha_n$ is the standard empirical process based on the unobservable sample. We assume Condition 2.3 (Second-order regularity of $k$-variate margins), which controls the second-order partial derivatives of $C$ on $k$-variate margins. Let $W_k = \\{ \\bm u \\in [0,1]^d: |\\{j: u_j < 1\\}| \\le k \\}$.", "goal": "Theorem 2.4: Under the regularity conditions and if $\\log d = o(n^{1/3})$, then $\\sup_{\\bm u \\in W_k} |\\Cb_n(\\bm u)- \\bar \\Cb_n(\\bm u)| = O_\\as(n^{-1/4} (\\log (nd))^{3/4})$, providing a uniform linearization (Stute's representation) of the high-dimensional empirical copula process."}, "local_context": {"anchor_latex": "\\sup_{\\bm u \\in W_k} |S_{n2}(\\bm u) | \\le \\frac{k}{\\sqrt n} + k \\max_{j=1}^d \\omega_{\\alpha_{nj}}(r), \\quad \\text{with } r \\le 1/2", "gap_objective": "Bound the tail probability of the modulus of continuity $\\omega_{\\alpha_{nj}}(r)$ for the univariate uniform empirical process to control the term $S_{n2}$."}}, "ground_truth": {"target_citation_key": "ShoWel09", "target_lemma_latex": "\\Prob\\Big( \\omega_{\\alpha_{n1}}(r) > \\lambda\\Big) \\le \\frac{160}{r} \\exp\\Big( - \\frac{\\lambda^2}{32r} \\psi\\Big(\\frac{\\lambda}{n^{1/2}r}\\Big)\\Big)", "target_citation_content": "Shorack, G.~R. and Wellner, J.~A. (2009). \\newblock \\em Empirical processes with applications to statistics, volume~59 of \\em Classics in Applied Mathematics. \\newblock Society for Industrial and Applied Mathematics (SIAM), Philadelphia, PA. \\newblock Reprint of the 1986 original [ MR0838963]."}}
{"id": "2405.05597v3_gap_5", "arxiv_id": "2405.05597v3", "title": "The empirical copula process in high dimensions: Stute's representation and applications", "publication_date": "2024-05-09", "problem_input": {"global_context": {"setup": "Let $\\bm X_1, \\dots, \\bm X_n$ be an i.i.d. sample from a $d$-dimensional random vector $\\bm X$ with continuous marginal cdfs $F_1, \\dots, F_d$ and unique copula $C$. The dimension $d=d_n$ is allowed to depend on $n$. The empirical copula is $\\hat C_n(\\bm u) = n^{-1} \\sum_{i=1}^n \\prod_{j=1}^d \\bm 1(\\hat U_{ij} \\le u_j)$, where $\\hat U_{ij}$ are the rescaled ranks. The empirical copula process is $\\Cb_n(\\bm u) = \\sqrt n \\{ \\hat C_n(\\bm u) - C(\\bm u) \\}$. Let $\\bar \\Cb_n(\\bm u) = \\alpha_{n}(\\bm u) - \\sum_{j=1}^d \\dot C_j(\\bm u) \\alpha_{nj}(u_j)$ be the linearized process, where $\\alpha_n$ is the standard empirical process based on the unobservable sample. We assume Condition 2.3 (Second-order regularity of $k$-variate margins), which controls the second-order partial derivatives of $C$ on $k$-variate margins. Let $W_k = \\{ \\bm u \\in [0,1]^d: |\\{j: u_j < 1\\}| \\le k \\}$.", "goal": "Theorem 2.4: Under the regularity conditions and if $\\log d = o(n^{1/3})$, then $\\sup_{\\bm u \\in W_k} |\\Cb_n(\\bm u)- \\bar \\Cb_n(\\bm u)| = O_\\as(n^{-1/4} (\\log (nd))^{3/4})$, providing a uniform linearization (Stute's representation) of the high-dimensional empirical copula process."}, "local_context": {"anchor_latex": "\\sup_{\\bm u \\in W_k} |S_{n1}(\\bm u)| \\le \\max_{I \\subset \\{1, \\dots, d\\}: |I|\\le k} \\omega_{\\alpha_{n,I}} (r)", "gap_objective": "Obtain an exponential tail bound for the modulus of continuity of the empirical process margins \\alpha_{n,I} to control the probability of the supremum deviation."}}, "ground_truth": {"target_citation_key": "Seg12", "target_lemma_latex": "\\Prob \\Big(\\omega_{\\alpha_{n,I}} (r) > \\lambda\\Big) \\le \\frac{M_1}{r} \\exp\\Big( - \\frac{M_2 \\lambda^2}{r} \\psi\\Big( \\frac{\\lambda}{n^{1/2}r}\\Big)\\Big)", "target_citation_content": "Segers, J. (2012). \\newblock Asymptotics of empirical copula processes under non-restrictive smoothness assumptions. \\newblock \\em Bernoulli, 18(3):764--782."}}
{"id": "2405.05597v3_gap_6", "arxiv_id": "2405.05597v3", "title": "The empirical copula process in high dimensions: Stute's representation and applications", "publication_date": "2024-05-09", "problem_input": {"global_context": {"setup": "Let $\\bm X_1, \\dots, \\bm X_n$ be an i.i.d. sample from a $d$-dimensional random vector $\\bm X$ with continuous marginal cdfs $F_1, \\dots, F_d$ and unique copula $C$. The dimension $d=d_n$ is allowed to depend on $n$. The empirical copula is $\\hat C_n(\\bm u) = n^{-1} \\sum_{i=1}^n \\prod_{j=1}^d \\bm 1(\\hat U_{ij} \\le u_j)$, where $\\hat U_{ij}$ are the rescaled ranks. The empirical copula process is $\\Cb_n(\\bm u) = \\sqrt n \\{ \\hat C_n(\\bm u) - C(\\bm u) \\}$. Let $\\bar \\Cb_n(\\bm u) = \\alpha_{n}(\\bm u) - \\sum_{j=1}^d \\dot C_j(\\bm u) \\alpha_{nj}(u_j)$ be the linearized process, where $\\alpha_n$ is the standard empirical process based on the unobservable sample. We assume Condition 2.3 (Second-order regularity of $k$-variate margins), which controls the second-order partial derivatives of $C$ on $k$-variate margins. Let $W_k = \\{ \\bm u \\in [0,1]^d: |\\{j: u_j < 1\\}| \\le k \\}$.", "goal": "Theorem 2.4: Under the regularity conditions and if $\\log d = o(n^{1/3})$, then $\\sup_{\\bm u \\in W_k} |\\Cb_n(\\bm u)- \\bar \\Cb_n(\\bm u)| = O_\\as(n^{-1/4} (\\log (nd))^{3/4})$, providing a uniform linearization (Stute's representation) of the high-dimensional empirical copula process."}, "local_context": {"anchor_latex": "S_{n3}^c(\\bm u) = \\sum_{j \\in I_{\\bm u}} D_{n,j}(\\bm u) \\bm 1 (u_j \\notin J_r), \\quad \\text{where } D_{n,j}(\\bm u) = \\big\\{ \\dot C_j(\\bm u) - \\dot C_j(\\bm u + t^*(\\bm v_n(\\bm u)- \\bm u)) \\big\\} \\alpha_{nj}(u_j)", "gap_objective": "Bound the difference of the partial derivatives of the copula inside $D_{nj}(\\bm u)$ in terms of the distance between the arguments and a boundary weight function, using the smoothness condition."}}, "ground_truth": {"target_citation_key": "Seg12", "target_lemma_latex": "|\\dot C_j(\\bm v) - \\dot C_j(\\bm u)| \\le K \\max \\left( \\frac{1}{u_j(1-u_j)}, \\frac{1}{v_j(1-v_j)} \\right) \\sum_{i=1}^d |v_i - u_i|", "target_citation_content": "Segers, J. (2012). \\newblock Asymptotics of empirical copula processes under non-restrictive smoothness assumptions. \\newblock \\em Bernoulli, 18(3):764--782."}}
{"id": "2405.05597v3_gap_7", "arxiv_id": "2405.05597v3", "title": "The empirical copula process in high dimensions: Stute's representation and applications", "publication_date": "2024-05-09", "problem_input": {"global_context": {"setup": "Let $\\bm X_1, \\dots, \\bm X_n$ be an i.i.d. sample from a $d$-dimensional random vector $\\bm X$ with continuous marginal cdfs $F_1, \\dots, F_d$ and unique copula $C$. The dimension $d=d_n$ is allowed to depend on $n$. The empirical copula is $\\hat C_n(\\bm u) = n^{-1} \\sum_{i=1}^n \\prod_{j=1}^d \\bm 1(\\hat U_{ij} \\le u_j)$, where $\\hat U_{ij}$ are the rescaled ranks. The empirical copula process is $\\Cb_n(\\bm u) = \\sqrt n \\{ \\hat C_n(\\bm u) - C(\\bm u) \\}$. Let $\\bar \\Cb_n(\\bm u) = \\alpha_{n}(\\bm u) - \\sum_{j=1}^d \\dot C_j(\\bm u) \\alpha_{nj}(u_j)$ be the linearized process, where $\\alpha_n$ is the standard empirical process based on the unobservable sample. We assume Condition 2.3 (Second-order regularity of $k$-variate margins), which controls the second-order partial derivatives of $C$ on $k$-variate margins. Let $W_k = \\{ \\bm u \\in [0,1]^d: |\\{j: u_j < 1\\}| \\le k \\}$.", "goal": "Theorem 2.4: Under the regularity conditions and if $\\log d = o(n^{1/3})$, then $\\sup_{\\bm u \\in W_k} |\\Cb_n(\\bm u)- \\bar \\Cb_n(\\bm u)| = O_\\as(n^{-1/4} (\\log (nd))^{3/4})$, providing a uniform linearization (Stute's representation) of the high-dimensional empirical copula process."}, "local_context": {"anchor_latex": "\\Prob\\Big(\\sup_{\\bm u \\in W_k} |S_{n3}^c(\\bm u)| > \\lambda \\Big)\n\\le\n2 d \\times \\Prob \\Big(  \\sup_{u \\in [2r, \\frac12]} \\frac{| \\alpha_{n1}(u)|}{u^{1/2}} > \\frac{\\lambda}{8Kk^2 \\sqrt r} \\Big)", "gap_objective": "Derive an exponential concentration inequality for the tail probability of the supremum of the weighted univariate empirical process on a specific interval to bound the error term."}}, "ground_truth": {"target_citation_key": "ShoWel09", "target_lemma_latex": "\\Prob\\Big( \\sup_{\\eta \\le u \\le 1/2} \\frac{\\alpha_{n1}^\\pm(u)}{\\sqrt u} \\ge \\eps \\Big)\n\\le 6 \\log\\Big(\\frac1{2\\eta} \\Big) \\exp\\Big( - \\frac18 \\gamma_{\\pm} \\eps^2\\Big)", "target_citation_content": "Shorack, G.~R. and Wellner, J.~A. (2009). \\newblock \\em Empirical processes with applications to statistics, volume~59 of \\em Classics in Applied Mathematics. \\newblock Society for Industrial and Applied Mathematics (SIAM), Philadelphia, PA. \\newblock Reprint of the 1986 original [ MR0838963]."}}
{"id": "2310.01784v2_gap_0", "arxiv_id": "2310.01784v2", "title": "On Squared-Variable Formulations", "publication_date": "2023-10-03", "problem_input": {"global_context": {"setup": "The paper investigates the relationship between inequality constrained optimization problems $\\min_x f(x)$ subject to $c(x) \\ge 0$ (or $x \\ge 0$) and their squared-variable reformulations. The reformulations are the Squared-Slack Variable (SSV) form $\\min_{x,v} f(x)$ subject to $c(x) - v \\odot v = 0$, and the Direct Squared Substitution (DSS) form $\\min_v f(v \\odot v)$. The analysis assumes $f$ and $c$ are smooth. For algorithmic convergence results, the objective function $h$ is assumed to be semialgebraic and have compact sublevel sets (denoted $h \\in \\mathcal{F}_s$).", "goal": "To prove that second-order necessary (2N) and sufficient (2S) points of the squared-variable reformulations correspond to 2N and 2S points of the original inequality-constrained problems, and to show that gradient descent on the reformulation converges to such points."}, "local_context": {"anchor_latex": "h \\in \\mathcal{F}_s \\implies h \\text{ is semialgebraic}", "gap_objective": "\\text{Establish that the Kurdyka-{\\L}ojasiewicz inequality holds for } h"}}, "ground_truth": {"target_citation_key": "bolte2014proximal", "target_lemma_latex": "\\text{Let } f: \\mathbb{R}^n \\to \\mathbb{R} \\cup \\{+\\infty\\} \\text{ be a proper lower semicontinuous function. If } f \\text{ is semialgebraic, then } f \\text{ satisfies the Kurdyka-{\\L}ojasiewicz inequality at any point of its domain.}", "target_citation_content": "\\sc J.~Bolte, S.~Sabach, and M.~Teboulle, \\em Proximal alternating linearized minimization for nonconvex and nonsmooth problems, Mathematical Programming, 146 (2014), pp.~459--494."}}
{"id": "2310.01784v2_gap_1", "arxiv_id": "2310.01784v2", "title": "On Squared-Variable Formulations", "publication_date": "2023-10-03", "problem_input": {"global_context": {"setup": "The paper investigates the relationship between inequality constrained optimization problems $\\min_x f(x)$ subject to $c(x) \\ge 0$ (or $x \\ge 0$) and their squared-variable reformulations. The reformulations are the Squared-Slack Variable (SSV) form $\\min_{x,v} f(x)$ subject to $c(x) - v \\odot v = 0$, and the Direct Squared Substitution (DSS) form $\\min_v f(v \\odot v)$. The analysis assumes $f$ and $c$ are smooth. For algorithmic convergence results, the objective function $h$ is assumed to be semialgebraic and have compact sublevel sets (denoted $h \\in \\mathcal{F}_s$).", "goal": "To prove that second-order necessary (2N) and sufficient (2S) points of the squared-variable reformulations correspond to 2N and 2S points of the original inequality-constrained problems, and to show that gradient descent on the reformulation converges to such points."}, "local_context": {"anchor_latex": "h \\text{ is semialgebraic implies } h \\text{ satisfies the Kurdyka-{\\L}ojasiewicz inequality}, \\text{ and the gradient descent iterates } \\{x_k\\} \\text{ initialized in } B_\\alpha \\text{ with stepsize } \\eta \\in (0, 1/L_{r_\\alpha}) \\text{ are bounded within } B_\\alpha.", "gap_objective": "To conclude that the sequence of iterates \\{x_k\\} converges to a critical point (1P) of h."}}, "ground_truth": {"target_citation_key": "bolte2014proximal", "target_lemma_latex": "\\text{Let } f \\text{ be a function satisfying the Kurdyka-{\\L}ojasiewicz inequality. If a bounded sequence } \\{x_k\\} \\text{ is generated by a gradient descent algorithm satisfying sufficient decrease and relative error conditions (ensured by the stepsize bound), then } \\{x_k\\} \\text{ converges to a critical point of } f.", "target_citation_content": "\\sc J.~Bolte, S.~Sabach, and M.~Teboulle, \\em Proximal alternating linearized minimization for nonconvex and nonsmooth problems, Mathematical Programming, 146 (2014), pp.~459--494."}}
{"id": "2310.01784v2_gap_2", "arxiv_id": "2310.01784v2", "title": "On Squared-Variable Formulations", "publication_date": "2023-10-03", "problem_input": {"global_context": {"setup": "The paper investigates the relationship between inequality constrained optimization problems $\\min_x f(x)$ subject to $c(x) \\ge 0$ (or $x \\ge 0$) and their squared-variable reformulations. The reformulations are the Squared-Slack Variable (SSV) form $\\min_{x,v} f(x)$ subject to $c(x) - v \\odot v = 0$, and the Direct Squared Substitution (DSS) form $\\min_v f(v \\odot v)$. The analysis assumes $f$ and $c$ are smooth. For algorithmic convergence results, the objective function $h$ is assumed to be semialgebraic and have compact sublevel sets (denoted $h \\in \\mathcal{F}_s$).", "goal": "To prove that second-order necessary (2N) and sufficient (2S) points of the squared-variable reformulations correspond to 2N and 2S points of the original inequality-constrained problems, and to show that gradient descent on the reformulation converges to such points."}, "local_context": {"anchor_latex": "\\text{(iii) For any smooth function } g \\text{ with domain } \\mathbb{R}^n \\text{ and bounded Hessian, defining } \\hat{L}_{g} = \\max_{x\\in \\mathbb{R}^n} \\| \\nabla ^2 g(x)\\|_2, \\text{ for almost all } x_0\\in\\mathbb{R}^n, \\text{ GD for } g \\text{ initialized at } x_0 \\text{ with stepsize } \\eta  \\in (0,{1}/{\\hat{L}_g}) \\text{ will {\\em not} converge to a point that is a 1P but not a 2NP of } g.", "gap_objective": "Justification that gradient descent with small constant step size almost surely avoids strict saddle points (points satisfying first-order but not second-order necessary conditions)."}}, "ground_truth": {"target_citation_key": "panageas2016gradient", "target_lemma_latex": "\\text{Theorem 2 from [panageas2016gradient]: Gradient descent with step size } \\eta < 1/L \\text{ converges to second-order necessary points for almost all initializations, specifically avoiding strict saddle points.}", "target_citation_content": "\\sc I.~Panageas and G.~Piliouras, \\em Gradient descent only converges to minimizers: Non-isolated critical points and invariant regions, arXiv preprint arXiv:1605.00405, (2016)."}}
{"id": "2310.01784v2_gap_3", "arxiv_id": "2310.01784v2", "title": "On Squared-Variable Formulations", "publication_date": "2023-10-03", "problem_input": {"global_context": {"setup": "The paper investigates the relationship between inequality constrained optimization problems $\\min_x f(x)$ subject to $c(x) \\ge 0$ (or $x \\ge 0$) and their squared-variable reformulations. The reformulations are the Squared-Slack Variable (SSV) form $\\min_{x,v} f(x)$ subject to $c(x) - v \\odot v = 0$, and the Direct Squared Substitution (DSS) form $\\min_v f(v \\odot v)$. The analysis assumes $f$ and $c$ are smooth. For algorithmic convergence results, the objective function $h$ is assumed to be semialgebraic and have compact sublevel sets (denoted $h \\in \\mathcal{F}_s$).", "goal": "To prove that second-order necessary (2N) and sufficient (2S) points of the squared-variable reformulations correspond to 2N and 2S points of the original inequality-constrained problems, and to show that gradient descent on the reformulation converges to such points."}, "local_context": {"anchor_latex": "F(v) := f(v \\odot v) \\text{ where } f \\text{ is a semialgebraic function}", "gap_objective": "Justify that the function F is semialgebraic"}}, "ground_truth": {"target_citation_key": "bolte2014proximal", "target_lemma_latex": "\\text{The composition of semialgebraic functions is semialgebraic}", "target_citation_content": "\\sc J.~Bolte, S.~Sabach, and M.~Teboulle, \\em Proximal alternating linearized minimization for nonconvex and nonsmooth problems, Mathematical Programming, 146 (2014), pp.~459--494."}}
{"id": "2310.01784v2_gap_4", "arxiv_id": "2310.01784v2", "title": "On Squared-Variable Formulations", "publication_date": "2023-10-03", "problem_input": {"global_context": {"setup": "The paper investigates the relationship between inequality constrained optimization problems $\\min_x f(x)$ subject to $c(x) \\ge 0$ (or $x \\ge 0$) and their squared-variable reformulations. The reformulations are the Squared-Slack Variable (SSV) form $\\min_{x,v} f(x)$ subject to $c(x) - v \\odot v = 0$, and the Direct Squared Substitution (DSS) form $\\min_v f(v \\odot v)$. The analysis assumes $f$ and $c$ are smooth. For algorithmic convergence results, the objective function $h$ is assumed to be semialgebraic and have compact sublevel sets (denoted $h \\in \\mathcal{F}_s$).", "goal": "To prove that second-order necessary (2N) and sufficient (2S) points of the squared-variable reformulations correspond to 2N and 2S points of the original inequality-constrained problems, and to show that gradient descent on the reformulation converges to such points."}, "local_context": {"anchor_latex": "\\text{If } (x,v,s) \\text{ is a 2N point of } \\eqref{eq:ssv} \\text{ then } (x,s) \\text{ is a weak 2N point for } \\eqref{eq:f}", "gap_objective": "Proof of the implication that second-order necessary conditions for the squared-slack formulation imply weak second-order necessary conditions for the original inequality-constrained problem"}}, "ground_truth": {"target_citation_key": "Ber99", "target_lemma_latex": "\\text{When the primal-dual solution } (x^*,v^*,s^*) \\text{ of } \\eqref{eq:ssv} \\text{ satisfies second-order necessary conditions with } v^*\\ge 0, \\text{ then } (x^*,s^*) \\text{ satisfies the first- and a weak form of second-order necessary conditions for } \\eqref{eq:f}", "target_citation_content": "\\sc D.~P. Bertsekas, \\em Nonlinear Programming, Athena Scientific, second~ed., 1999."}}
{"id": "2310.01784v2_gap_5", "arxiv_id": "2310.01784v2", "title": "On Squared-Variable Formulations", "publication_date": "2023-10-03", "problem_input": {"global_context": {"setup": "The paper investigates the relationship between inequality constrained optimization problems $\\min_x f(x)$ subject to $c(x) \\ge 0$ (or $x \\ge 0$) and their squared-variable reformulations. The reformulations are the Squared-Slack Variable (SSV) form $\\min_{x,v} f(x)$ subject to $c(x) - v \\odot v = 0$, and the Direct Squared Substitution (DSS) form $\\min_v f(v \\odot v)$. The analysis assumes $f$ and $c$ are smooth. For algorithmic convergence results, the objective function $h$ is assumed to be semialgebraic and have compact sublevel sets (denoted $h \\in \\mathcal{F}_s$).", "goal": "To prove that second-order necessary (2N) and sufficient (2S) points of the squared-variable reformulations correspond to 2N and 2S points of the original inequality-constrained problems, and to show that gradient descent on the reformulation converges to such points."}, "local_context": {"anchor_latex": "\\text{The algorithm ProximalAL takes the augmented Lagrangian approach and uses the Newton-CG procedure as a subroutine to solve the SSV formulation } \\min_{x,v} f(x) \\text{ s.t. } c(x) - v \\odot v = 0.", "gap_objective": "Determine the worst-case computational complexity of the ProximalAL algorithm in terms of the total number of inner Newton-CG iterations required to find an approximate second-order stationary point."}}, "ground_truth": {"target_citation_key": "xie2021complexity", "target_lemma_latex": "\\text{The total number of iterations of the Newton-CG procedure to find an } \\epsilon\\text{-approximate second-order necessary point is } \\mathcal{O}(\\epsilon^{-7}).", "target_citation_content": "\\sc Y.~Xie and S.~J. Wright, \\em Complexity of proximal augmented Lagrangian for nonconvex optimization with nonlinear equality constraints, Journal of Scientific Computing, 86 (2021), pp.~1--30."}}
{"id": "2404.10372v4_gap_0", "arxiv_id": "2404.10372v4", "title": "Consensus-based algorithms for stochastic optimization problems", "publication_date": "2024-04-16", "problem_input": {"global_context": {"setup": "The paper addresses the minimization of $f(x) := \\mathbb{E}_\\mathbb{P}[F(x,\\mathbf{Y})]$ where $x \\in \\mathbb{R}^d$ and $\\mathbf{Y}$ is a random variable on $(\\Omega, \\mathcal{A}, \\mathbb{P})$. The problem is tackled using Consensus-Based Optimization (CBO) algorithms via two approaches: Sample Average Approximation (SAA) defining $\\hat{f}_M$, and Quadrature defining $\\tilde{f}_N$. The dynamics are governed by systems of Stochastic Differential Equations (SDEs) involving a drift towards a weighted mean (consensus point) $x^{\\alpha, \\#}_t$ and a diffusion term. The analysis relies on the mean-field limit ($N \\to \\infty$) described by non-linear Fokker-Planck equations. Key assumptions include Lipschitz continuity of $F$ (Assumption 2.1), growth and smoothness conditions for the mean-field limit (Assumption 2.2), and tractability conditions of the landscape around minimizers (Assumption 2.3).", "goal": "Theorem 2.4: To prove that the Euclidean distance between the consensus point of the mean-field formulation for the true objective $f$ and the consensus point for the SAA approximation $\\hat{f}_M$ converges to zero as $M, \\alpha, t \\to \\infty$ with probability 1."}, "local_context": {"anchor_latex": "\\begin{cases} |F(x_1,\\mathbf{y}) - F(x_2,\\mathbf{y})| \\le J_F (1+ |x_1|+|x_2|)|x_1-x_2| \\\\ F(x,\\mathbf{y}) - \\underline{F}(\\mathbf{y}) \\le c_u (1+|x|^2) \\\\ F(x,\\mathbf{y}) \\text{ bounded above OR } F(x,\\mathbf{y}) - \\underline{F}(\\mathbf{y}) \\ge c_l(\\mathbf{y}) |x|^2 \\text{ for } |x| \\ge \\bar{c_l} \\end{cases}", "gap_objective": "Existence of a weak solution to the mean-field equations"}}, "ground_truth": {"target_citation_key": "carrillo2018analytical", "target_lemma_latex": "\\text{Theorems 3.1, 3.2 guarantee the existence of a weak solution } h(t,x)dx \\in \\mathcal{P}_4(\\mathbb{R}^d) \\text{ of } \\eqref{eq2: mf eq complete for EF} \\text{ and } h(t,x)(\\mathbf{Y}(\\omega))dx \\in \\mathcal{P}_4(\\mathbb{R}^d) \\text{ of } \\eqref{eq2: mf eq complete for fM} \\text{ for } t \\in [0,T]", "target_citation_content": "J.~A. Carrillo, Y.~P. Choi, C.~Totzeck, and O.~Tse. \\newblock An analytical framework for consensus-based global optimization method. \\newblock \\em Mathematical Models and Methods in Applied Sciences, 28(06):1037--1066, 2018."}}
{"id": "2404.10372v4_gap_1", "arxiv_id": "2404.10372v4", "title": "Consensus-based algorithms for stochastic optimization problems", "publication_date": "2024-04-16", "problem_input": {"global_context": {"setup": "The paper addresses the minimization of $f(x) := \\mathbb{E}_\\mathbb{P}[F(x,\\mathbf{Y})]$ where $x \\in \\mathbb{R}^d$ and $\\mathbf{Y}$ is a random variable on $(\\Omega, \\mathcal{A}, \\mathbb{P})$. The problem is tackled using Consensus-Based Optimization (CBO) algorithms via two approaches: Sample Average Approximation (SAA) defining $\\hat{f}_M$, and Quadrature defining $\\tilde{f}_N$. The dynamics are governed by systems of Stochastic Differential Equations (SDEs) involving a drift towards a weighted mean (consensus point) $x^{\\alpha, \\#}_t$ and a diffusion term. The analysis relies on the mean-field limit ($N \\to \\infty$) described by non-linear Fokker-Planck equations. Key assumptions include Lipschitz continuity of $F$ (Assumption 2.1), growth and smoothness conditions for the mean-field limit (Assumption 2.2), and tractability conditions of the landscape around minimizers (Assumption 2.3).", "goal": "Theorem 2.4: To prove that the Euclidean distance between the consensus point of the mean-field formulation for the true objective $f$ and the consensus point for the SAA approximation $\\hat{f}_M$ converges to zero as $M, \\alpha, t \\to \\infty$ with probability 1."}, "local_context": {"anchor_latex": "F(\\cdot,\\mathbf{y}) \\in \\mathcal{C}(\\mathbb{R}^d) \\text{ for any } \\mathbf{y} \\in E, \\quad x_\\star, \\hat{x}_M(\\mathbf{Y}(\\cdot)) \\in C, \\quad \\text{and } \\lim_{M \\to \\infty} \\sup_{x \\in C} |\\hat{f}_M(x, \\mathbf{Y}(\\cdot)) - f(x)| = 0 \\text{ w.p.1}", "gap_objective": "Establish the consistency of the sample average approximation estimator, specifically the almost sure convergence of the approximate minimizers to the true minimizer."}}, "ground_truth": {"target_citation_key": "shapiro2021lectures", "target_lemma_latex": "\\hat{x}_M(\\mathbf{Y}(\\cdot)) \\to x_\\star \\text{ as } M \\to \\infty \\text{ w.p.1}", "target_citation_content": "A.~Shapiro, D.~Dentcheva, and A.~Ruszczynski. \\newblock \\em Lectures on stochastic programming: modeling and theory. \\newblock SIAM, 2021."}}
{"id": "2404.10372v4_gap_2", "arxiv_id": "2404.10372v4", "title": "Consensus-based algorithms for stochastic optimization problems", "publication_date": "2024-04-16", "problem_input": {"global_context": {"setup": "The paper addresses the minimization of $f(x) := \\mathbb{E}_\\mathbb{P}[F(x,\\mathbf{Y})]$ where $x \\in \\mathbb{R}^d$ and $\\mathbf{Y}$ is a random variable on $(\\Omega, \\mathcal{A}, \\mathbb{P})$. The problem is tackled using Consensus-Based Optimization (CBO) algorithms via two approaches: Sample Average Approximation (SAA) defining $\\hat{f}_M$, and Quadrature defining $\\tilde{f}_N$. The dynamics are governed by systems of Stochastic Differential Equations (SDEs) involving a drift towards a weighted mean (consensus point) $x^{\\alpha, \\#}_t$ and a diffusion term. The analysis relies on the mean-field limit ($N \\to \\infty$) described by non-linear Fokker-Planck equations. Key assumptions include Lipschitz continuity of $F$ (Assumption 2.1), growth and smoothness conditions for the mean-field limit (Assumption 2.2), and tractability conditions of the landscape around minimizers (Assumption 2.3).", "goal": "Theorem 2.4: To prove that the Euclidean distance between the consensus point of the mean-field formulation for the true objective $f$ and the consensus point for the SAA approximation $\\hat{f}_M$ converges to zero as $M, \\alpha, t \\to \\infty$ with probability 1."}, "local_context": {"anchor_latex": "\\xs \\in \\tn{supp}(\\mu_0), f \\in \\C(\\Rd), 2\\lambda > d\\sigma^2, \\text{Assumption 2.3.1}", "gap_objective": "Convergence of the mean-field distribution $h(t,x)$ to the Dirac measure $\\delta_{\\xs}$"}}, "ground_truth": {"target_citation_key": "fornasier2021consensus", "target_lemma_latex": "W_2(h(t,x)dx, \\delta_{\\xs}) \\xrightarrow[]{} 0 \\quad {\\tn{for $\\alpha,t$ sufficiently big}}", "target_citation_content": "M.~Fornasier, T.~Klock, and K.~Riedl. \\newblock Consensus-based optimization methods converge globally. \\newblock \\em SIAM Journal on Optimization, 34(3):2973--3004, 2024."}}
{"id": "2404.10372v4_gap_3", "arxiv_id": "2404.10372v4", "title": "Consensus-based algorithms for stochastic optimization problems", "publication_date": "2024-04-16", "problem_input": {"global_context": {"setup": "The paper addresses the minimization of $f(x) := \\mathbb{E}_\\mathbb{P}[F(x,\\mathbf{Y})]$ where $x \\in \\mathbb{R}^d$ and $\\mathbf{Y}$ is a random variable on $(\\Omega, \\mathcal{A}, \\mathbb{P})$. The problem is tackled using Consensus-Based Optimization (CBO) algorithms via two approaches: Sample Average Approximation (SAA) defining $\\hat{f}_M$, and Quadrature defining $\\tilde{f}_N$. The dynamics are governed by systems of Stochastic Differential Equations (SDEs) involving a drift towards a weighted mean (consensus point) $x^{\\alpha, \\#}_t$ and a diffusion term. The analysis relies on the mean-field limit ($N \\to \\infty$) described by non-linear Fokker-Planck equations. Key assumptions include Lipschitz continuity of $F$ (Assumption 2.1), growth and smoothness conditions for the mean-field limit (Assumption 2.2), and tractability conditions of the landscape around minimizers (Assumption 2.3).", "goal": "Theorem 2.4: To prove that the Euclidean distance between the consensus point of the mean-field formulation for the true objective $f$ and the consensus point for the SAA approximation $\\hat{f}_M$ converges to zero as $M, \\alpha, t \\to \\infty$ with probability 1."}, "local_context": {"anchor_latex": "dW_t = \\Delta(t,W_t) dt + \\Sigma(t,W_t) dB_t, \\; \\textnormal{for } t \\in [0,T], \\quad \\textnormal{and} \\quad W_0 \\sim \\mu_0 \\in \\mathcal{P}_4(\\mathbb{R}^d), \\quad \\textnormal{where } \\Delta, \\Sigma \\textnormal{ are uniformly Lipschitz continuous in the second variable with constant } L > 0", "gap_objective": "Estimate the fourth-order moment of the probability distribution $\\mu_t$ of the process $W_t$"}}, "ground_truth": {"target_citation_key": "arnold1974stochastic", "target_lemma_latex": "\\int_{\\mathbb{R}^d} |x|^4 \\mu_t(dx) \\le \\left(1 + \\int_{\\mathbb{R}^d} |x|^4 \\mu_0(dx)\\right) e^{20 L^2 t}", "target_citation_content": "L.~Arnold. \\newblock \\em Stochastic Differential Equations: Theory and Applications. \\newblock 1974."}}
{"id": "2404.10372v4_gap_4", "arxiv_id": "2404.10372v4", "title": "Consensus-based algorithms for stochastic optimization problems", "publication_date": "2024-04-16", "problem_input": {"global_context": {"setup": "The paper addresses the minimization of $f(x) := \\mathbb{E}_\\mathbb{P}[F(x,\\mathbf{Y})]$ where $x \\in \\mathbb{R}^d$ and $\\mathbf{Y}$ is a random variable on $(\\Omega, \\mathcal{A}, \\mathbb{P})$. The problem is tackled using Consensus-Based Optimization (CBO) algorithms via two approaches: Sample Average Approximation (SAA) defining $\\hat{f}_M$, and Quadrature defining $\\tilde{f}_N$. The dynamics are governed by systems of Stochastic Differential Equations (SDEs) involving a drift towards a weighted mean (consensus point) $x^{\\alpha, \\#}_t$ and a diffusion term. The analysis relies on the mean-field limit ($N \\to \\infty$) described by non-linear Fokker-Planck equations. Key assumptions include Lipschitz continuity of $F$ (Assumption 2.1), growth and smoothness conditions for the mean-field limit (Assumption 2.2), and tractability conditions of the landscape around minimizers (Assumption 2.3).", "goal": "Theorem 2.4: To prove that the Euclidean distance between the consensus point of the mean-field formulation for the true objective $f$ and the consensus point for the SAA approximation $\\hat{f}_M$ converges to zero as $M, \\alpha, t \\to \\infty$ with probability 1."}, "local_context": {"anchor_latex": "\\mathcal{F}: \\mathbb{R}^d \\to \\mathbb{R}, \\inf \\mathcal{F} > -\\infty, \\quad |\\mathcal{F}(x_1) -\\mathcal{F}(x_2)| \\le J_{\\mathcal{F}} (1+ |x_1|+|x_2|)|x_1-x_2|, \\quad \\mathcal{F}(x) - \\underline{\\mathcal{F}} \\le c_{u,\\mathcal{F}} (1+|x|^2), \\quad \\mu, \\tilde{\\mu} \\in \\mathcal{P}_2(\\mathbb{R}^d) \\text{ with } 4\\text{-th moment bounded by } k_4 < \\infty", "gap_objective": "Stability estimate for the consensus point difference |x^{\\alpha,\\mathcal{F}}[\\mu] - x^{\\alpha,\\mathcal{F}}[\\tilde{\\mu}]|"}}, "ground_truth": {"target_citation_key": "carrillo2018analytical", "target_lemma_latex": "|x^{\\alpha,\\mathcal{F}}[\\mu] - x^{\\alpha,\\mathcal{F}}[\\tilde{\\mu}] | \\le c_0 W_2(\\mu, \\tilde{\\mu})", "target_citation_content": "J.~A. Carrillo, Y.~P. Choi, C.~Totzeck, and O.~Tse. \\newblock An analytical framework for consensus-based global optimization method. \\newblock \\em Mathematical Models and Methods in Applied Sciences, 28(06):1037--1066, 2018."}}
{"id": "2502.10336v1_gap_0", "arxiv_id": "2502.10336v1", "title": "Euclidean distance degree in manifold optimization", "publication_date": "2025-02-14", "problem_input": {"global_context": {"setup": "The paper investigates the Euclidean Distance Degree (ED degree) of three Riemannian manifolds embedded in matrix spaces: the flag manifold, the Grassmann manifold, and the Stiefel manifold. We define the complex locus of a real affine variety $\\mathcal{M} \\subseteq \\mathbb{R}^{m \\times n}$ as $\\mathcal{M}^{\\mathbb{C}}$. The Euclidean distance degree $\\ED(\\mathcal{M})$ is defined as the number of stationary points of the function $\\delta_A : \\mathcal{M}^{\\mathbb{C}} \\to \\mathbb{C}, X \\mapsto \\frac{1}{2} \\lVert X - A \\rVert^2$ for a generic matrix $A$. The specific algebraic models used are: \n1. The isospectral model of the flag manifold $\\Flag_{b_1,\\dots, b_{p+1}} \\subseteq \\Sym^2(\\mathbb{R}^n)$.\n2. The quadratic model of the Grassmann manifold $\\Gr_{a,b}(k,n) \\subseteq \\Sym^2(\\mathbb{R}^n)$.\n3. The Cholesky model of the Stiefel manifold $\\V_B(k,n) \\subseteq \\mathbb{R}^{n \\times k}$.", "goal": "To determine the exact Euclidean distance degrees (number of complex stationary points of $\\delta_A$) for the defined models of the flag, Grassmann, and Stiefel manifolds."}, "local_context": {"anchor_latex": "\\binom{n}{k_1, k_2-k_1,\\dots,  n-k_p}", "gap_objective": "A canonical factorization for complex symmetric matrices using complex orthogonal matrices (rather than unitary ones) is required to determine the Euclidean distance degree in the complex locus."}}, "ground_truth": {"target_citation_key": "Gantmacher59", "target_lemma_latex": "Let A\\in \\Sym^2(\\mathbb{C}^n). Then there exists Q\\in \\O_n(\\mathbb{C}) so that A = Q\\diag(\\lambda_1 I_{k_1} + S_1, \\dots, \\lambda_p I_{k_p} + S_p)  Q^\\tp", "target_citation_content": "F.~R. Gantmacher. \\newblock \\em Applications of the theory of matrices. \\newblock Interscience Publishers, New York, NY, 1959."}}
{"id": "2502.16020v1_gap_0", "arxiv_id": "2502.16020v1", "title": "Interior-point algorithms with full Newton steps for nonsymmetric convex conic optimization", "publication_date": "2025-02-22", "problem_input": {"global_context": {"setup": "The paper considers convex optimization problems in standard conic form: $\\min \\mathbf{c}^\\top \\mathbf{x}$ s.t. $A\\mathbf{x} = \\mathbf{b}, \\mathbf{x} \\in \\mathcal{K}$, and its dual. $\\mathcal{K} \\subseteq \\mathbb{R}^n$ is a proper convex cone with interior $\\mathcal{K}^\\circ$, equipped with a logarithmically homogeneous self-concordant barrier (LHSCB) $f: \\mathcal{K}^{\\circ} \\rightarrow \\mathbb{R}$ with barrier parameter $\\nu$. The central path is defined by solutions to $\\mathbf{s} + \\tau g(\\mathbf{x}) = \\mathbf{0}$ for $\\tau > 0$, where $g$ is the gradient of $f$. The algorithm operates in a neighborhood $\\mathcal{N}(\\eta,\\tau) = \\{ (\\mathbf{x}, \\mathbf{y}, \\mathbf{s}) \\in \\mathcal{F}^\\circ : \\| \\mathbf{s} + \\tau g(\\mathbf{x}) \\|_{\\mathbf{x}}^* \\leq \\eta \\tau \\}$.", "goal": "Theorem 2.4: If $0 < \\eta \\leq \\frac{1}{4}$ and $\\vartheta = \\frac{\\eta / 2}{\\sqrt{\\nu} + 1}$, the proposed Algorithm 1 produces a feasible solution with duality gap below $\\varepsilon$ in $\\mathcal{O}(\\sqrt{\\nu} \\ln (\\frac{\\tau_0 \\nu}{\\varepsilon}))$ iterations."}, "local_context": {"anchor_latex": "A \\Delta \\mathbf{x} = \\mathbf{0}, \\quad A^{\\top} \\Delta \\mathbf{y} + \\Delta \\mathbf{s} = \\mathbf{0}, \\quad \\tau H(\\mathbf{x}) \\Delta \\mathbf{x} + \\Delta \\mathbf{s} = -(\\mathbf{s} + \\tau g(\\mathbf{x}))", "gap_objective": "Establish bounds on the local norms of the Newton search directions to analyze the algorithm's convergence."}}, "ground_truth": {"target_citation_key": "SkajaaYe2015", "target_lemma_latex": "\\| \\Delta \\mathbf{x} \\|_{\\mathbf{x}} \\leq \\eta, \\quad \\| \\Delta \\mathbf{s} \\|_{\\mathbf{x}}^* \\leq \\eta \\tau, \\quad \\| \\mathbf{s} + \\tau g(\\mathbf{x}) + \\Delta \\mathbf{s} \\|_{\\mathbf{x}}^* \\leq \\eta \\tau", "target_citation_content": "\\sc A.~Skajaa and Y.~Ye, \\em A homogeneous interior-point algorithm for nonsymmetric convex conic optimization, Mathematical Programming, 150 (2015), pp.~391--422, \\urlhttps://doi.org/10.1007/s10107-014-0773-1."}}
{"id": "2502.16020v1_gap_1", "arxiv_id": "2502.16020v1", "title": "Interior-point algorithms with full Newton steps for nonsymmetric convex conic optimization", "publication_date": "2025-02-22", "problem_input": {"global_context": {"setup": "The paper considers convex optimization problems in standard conic form: $\\min \\mathbf{c}^\\top \\mathbf{x}$ s.t. $A\\mathbf{x} = \\mathbf{b}, \\mathbf{x} \\in \\mathcal{K}$, and its dual. $\\mathcal{K} \\subseteq \\mathbb{R}^n$ is a proper convex cone with interior $\\mathcal{K}^\\circ$, equipped with a logarithmically homogeneous self-concordant barrier (LHSCB) $f: \\mathcal{K}^{\\circ} \\rightarrow \\mathbb{R}$ with barrier parameter $\\nu$. The central path is defined by solutions to $\\mathbf{s} + \\tau g(\\mathbf{x}) = \\mathbf{0}$ for $\\tau > 0$, where $g$ is the gradient of $f$. The algorithm operates in a neighborhood $\\mathcal{N}(\\eta,\\tau) = \\{ (\\mathbf{x}, \\mathbf{y}, \\mathbf{s}) \\in \\mathcal{F}^\\circ : \\| \\mathbf{s} + \\tau g(\\mathbf{x}) \\|_{\\mathbf{x}}^* \\leq \\eta \\tau \\}$.", "goal": "Theorem 2.4: If $0 < \\eta \\leq \\frac{1}{4}$ and $\\vartheta = \\frac{\\eta / 2}{\\sqrt{\\nu} + 1}$, the proposed Algorithm 1 produces a feasible solution with duality gap below $\\varepsilon$ in $\\mathcal{O}(\\sqrt{\\nu} \\ln (\\frac{\\tau_0 \\nu}{\\varepsilon}))$ iterations."}, "local_context": {"anchor_latex": "\\begin{aligned}\n    A \\Delta \\mathbf{x} & = \\mathbf{0} \\\\\n    A^{\\top} \\Delta \\mathbf{y} + \\Delta \\mathbf{s} & = \\mathbf{0} \\\\\n    \\tau H(\\mathbf{x}) \\Delta \\mathbf{x} + \\Delta \\mathbf{s} & = -(\\mathbf{s} + \\tau g(\\mathbf{x}))\n\\end{aligned}", "gap_objective": "Establish the orthogonality and local norm bounds of the Newton search directions determined by the system."}}, "ground_truth": {"target_citation_key": "PappYildiz2017", "target_lemma_latex": "\\Delta \\mathbf{x}^{\\top} \\Delta \\mathbf{s} = 0, \\quad \\| \\Delta \\mathbf{x} \\|_{\\mathbf{x}} \\leq \\eta, \\quad \\| \\Delta \\mathbf{s} \\|_{\\mathbf{x}}^* \\leq \\eta \\tau, \\quad \\| \\mathbf{s} + \\tau g(\\mathbf{x}) + \\Delta \\mathbf{s} \\|_{\\mathbf{x}}^* \\leq \\eta \\tau", "target_citation_content": "\\sc D.~Papp and S.~Y\\ild\\iz, \\em On ``A homogeneous interior-point algorithm for nonsymmetric convex conic optimization'', arXiv preprint arXiv:1712.00492, (2017), \\urlhttps://doi.org/10.48550/arXiv.1712.00492."}}
{"id": "2502.16020v1_gap_2", "arxiv_id": "2502.16020v1", "title": "Interior-point algorithms with full Newton steps for nonsymmetric convex conic optimization", "publication_date": "2025-02-22", "problem_input": {"global_context": {"setup": "The paper considers convex optimization problems in standard conic form: $\\min \\mathbf{c}^\\top \\mathbf{x}$ s.t. $A\\mathbf{x} = \\mathbf{b}, \\mathbf{x} \\in \\mathcal{K}$, and its dual. $\\mathcal{K} \\subseteq \\mathbb{R}^n$ is a proper convex cone with interior $\\mathcal{K}^\\circ$, equipped with a logarithmically homogeneous self-concordant barrier (LHSCB) $f: \\mathcal{K}^{\\circ} \\rightarrow \\mathbb{R}$ with barrier parameter $\\nu$. The central path is defined by solutions to $\\mathbf{s} + \\tau g(\\mathbf{x}) = \\mathbf{0}$ for $\\tau > 0$, where $g$ is the gradient of $f$. The algorithm operates in a neighborhood $\\mathcal{N}(\\eta,\\tau) = \\{ (\\mathbf{x}, \\mathbf{y}, \\mathbf{s}) \\in \\mathcal{F}^\\circ : \\| \\mathbf{s} + \\tau g(\\mathbf{x}) \\|_{\\mathbf{x}}^* \\leq \\eta \\tau \\}$.", "goal": "Theorem 2.4: If $0 < \\eta \\leq \\frac{1}{4}$ and $\\vartheta = \\frac{\\eta / 2}{\\sqrt{\\nu} + 1}$, the proposed Algorithm 1 produces a feasible solution with duality gap below $\\varepsilon$ in $\\mathcal{O}(\\sqrt{\\nu} \\ln (\\frac{\\tau_0 \\nu}{\\varepsilon}))$ iterations."}, "local_context": {"anchor_latex": "(\\mathbf{x}, \\mathbf{y}, \\mathbf{s}) \\in \\mathcal{N}(\\eta, \\tau) \\text{ and } (\\Delta \\mathbf{x}, \\Delta \\mathbf{y}, \\Delta \\mathbf{s}) \\text{ is the solution of the Newton system (NS)}", "gap_objective": "Bound the local norms of the Newton steps and the residual to ensure the iterate remains in the neighborhood"}}, "ground_truth": {"target_citation_key": "Serrano2015", "target_lemma_latex": "\\| \\Delta \\mathbf{x} \\|_{\\mathbf{x}} \\leq \\eta, \\quad \\| \\Delta \\mathbf{s} \\|_{\\mathbf{x}}^* \\leq \\eta \\tau, \\quad \\| \\mathbf{s} + \\tau g(\\mathbf{x}) + \\Delta \\mathbf{s} \\|_{\\mathbf{x}}^* \\leq \\eta \\tau", "target_citation_content": "\\sc S.~A. Serrano, \\em Algorithms for unsymmetric cone optimization and an implementation for problems with the exponential cone, Stanford University, 2015."}}
{"id": "2502.16020v1_gap_3", "arxiv_id": "2502.16020v1", "title": "Interior-point algorithms with full Newton steps for nonsymmetric convex conic optimization", "publication_date": "2025-02-22", "problem_input": {"global_context": {"setup": "The paper considers convex optimization problems in standard conic form: $\\min \\mathbf{c}^\\top \\mathbf{x}$ s.t. $A\\mathbf{x} = \\mathbf{b}, \\mathbf{x} \\in \\mathcal{K}$, and its dual. $\\mathcal{K} \\subseteq \\mathbb{R}^n$ is a proper convex cone with interior $\\mathcal{K}^\\circ$, equipped with a logarithmically homogeneous self-concordant barrier (LHSCB) $f: \\mathcal{K}^{\\circ} \\rightarrow \\mathbb{R}$ with barrier parameter $\\nu$. The central path is defined by solutions to $\\mathbf{s} + \\tau g(\\mathbf{x}) = \\mathbf{0}$ for $\\tau > 0$, where $g$ is the gradient of $f$. The algorithm operates in a neighborhood $\\mathcal{N}(\\eta,\\tau) = \\{ (\\mathbf{x}, \\mathbf{y}, \\mathbf{s}) \\in \\mathcal{F}^\\circ : \\| \\mathbf{s} + \\tau g(\\mathbf{x}) \\|_{\\mathbf{x}}^* \\leq \\eta \\tau \\}$.", "goal": "Theorem 2.4: If $0 < \\eta \\leq \\frac{1}{4}$ and $\\vartheta = \\frac{\\eta / 2}{\\sqrt{\\nu} + 1}$, the proposed Algorithm 1 produces a feasible solution with duality gap below $\\varepsilon$ in $\\mathcal{O}(\\sqrt{\\nu} \\ln (\\frac{\\tau_0 \\nu}{\\varepsilon}))$ iterations."}, "local_context": {"anchor_latex": "\\begin{aligned} \n G =  \\begin{pmatrix}\n   \\mathbf{0} & A & -\\mathbf{b} & \\phantom{-}\\bar{\\mathbf{b}} \\\\\n   -A^{\\top} & \\mathbf{0} & \\phantom{-}\\mathbf{c} & -\\bar{\\mathbf{c}}  \\\\\n   \\phantom{-}\\mathbf{b}^{\\top} & -\\mathbf{c}^{\\top} & \\phantom{-}0 & \\phantom{-}\\bar{z} \\\\\n   -\\mathbf{\\bar{b}}^{\\top} & \\phantom{-}\\mathbf{\\bar{c}}^{\\top} &  -\\bar{z} & \\phantom{-}0   \\end{pmatrix}\n\\\\\n\\min \\ &(\\mathbf{\\bar{x}}^{\\top} \\mathbf{\\bar{s}} + 1)\\theta \\\\\n\\textrm{s.t.}\\;\\;&G \\begin{pmatrix}\n \\mathbf{y} \\\\ \\mathbf{x} \\\\ \\xi \\\\ \\theta\n\\end{pmatrix} -\n\\begin{pmatrix}\n \\mathbf{0} \\\\ \\mathbf{s} \\\\ \\kappa \\\\ 0\n\\end{pmatrix} =\n\\begin{pmatrix}\n \\mathbf{0} \\\\ \\mathbf{0} \\\\ 0 \\\\ -\\mathbf{\\bar{x}}^{\\top} \\mathbf{\\bar{s}} - 1\n\\end{pmatrix} \\\\\n &            (\\mathbf{x}, \\xi) \\in \\mathcal{K} \\times \\mathbb{R}_{+}, \\  ( \\mathbf{s}, \\kappa)\\in \\mathcal{K}^* \\times \\mathbb{R}_{+}, \\  \\mathbf{y} \\in \\mathbb{R}^m\n\\end{aligned}", "gap_objective": "Establish the properties of the defined Homogeneous Self-Dual (HSD) model, specifically its self-duality, the existence of a trivial strictly feasible starting point, and the relationship between its optimal solutions and those of the original problem."}}, "ground_truth": {"target_citation_key": "deKlerkRoosTerlaky1997", "target_lemma_latex": "\\text{The HSD model is self-dual, and the point } (\\mathbf{x}, \\mathbf{y}, \\mathbf{s}, \\xi, \\theta, \\kappa) = (\\bar{\\mathbf{x}}, \\bar{\\mathbf{y}}, \\bar{\\mathbf{s}}, 1, 1, 1) \\text{ is a strictly feasible solution. The optimum value is } 0\\text{, and if } \\xi > 0 \\text{ at an optimal solution, then } (\\mathbf{x}/ \\xi, \\mathbf{y}/ \\xi, \\mathbf{s} / \\xi) \\text{ is an optimal solution to the original primal-dual pair of problems.}", "target_citation_content": "\\sc E.~de~Klerk, C.~Roos, and T.~Terlaky, \\em Initialization in semidefinite programming via a self-dual skew-symmetric embedding, Operations Research Letters, 20 (1997), pp.~213--221, \\urlhttps://doi.org/10.1016/S0167-6377(97)00011-4."}}
{"id": "2502.16020v1_gap_4", "arxiv_id": "2502.16020v1", "title": "Interior-point algorithms with full Newton steps for nonsymmetric convex conic optimization", "publication_date": "2025-02-22", "problem_input": {"global_context": {"setup": "The paper considers convex optimization problems in standard conic form: $\\min \\mathbf{c}^\\top \\mathbf{x}$ s.t. $A\\mathbf{x} = \\mathbf{b}, \\mathbf{x} \\in \\mathcal{K}$, and its dual. $\\mathcal{K} \\subseteq \\mathbb{R}^n$ is a proper convex cone with interior $\\mathcal{K}^\\circ$, equipped with a logarithmically homogeneous self-concordant barrier (LHSCB) $f: \\mathcal{K}^{\\circ} \\rightarrow \\mathbb{R}$ with barrier parameter $\\nu$. The central path is defined by solutions to $\\mathbf{s} + \\tau g(\\mathbf{x}) = \\mathbf{0}$ for $\\tau > 0$, where $g$ is the gradient of $f$. The algorithm operates in a neighborhood $\\mathcal{N}(\\eta,\\tau) = \\{ (\\mathbf{x}, \\mathbf{y}, \\mathbf{s}) \\in \\mathcal{F}^\\circ : \\| \\mathbf{s} + \\tau g(\\mathbf{x}) \\|_{\\mathbf{x}}^* \\leq \\eta \\tau \\}$.", "goal": "Theorem 2.4: If $0 < \\eta \\leq \\frac{1}{4}$ and $\\vartheta = \\frac{\\eta / 2}{\\sqrt{\\nu} + 1}$, the proposed Algorithm 1 produces a feasible solution with duality gap below $\\varepsilon$ in $\\mathcal{O}(\\sqrt{\\nu} \\ln (\\frac{\\tau_0 \\nu}{\\varepsilon}))$ iterations."}, "local_context": {"anchor_latex": "\\begin{aligned} \nG =  \\begin{pmatrix}\n   \\mathbf{0} & A & -\\mathbf{b} & \\phantom{-}\\bar{\\mathbf{b}} \\\\\n   -A^{\\top} & \\mathbf{0} & \\phantom{-}\\mathbf{c} & -\\bar{\\mathbf{c}}  \\\\\n   \\phantom{-}\\mathbf{b}^{\\top} & -\\mathbf{c}^{\\top} & \\phantom{-}0 & \\phantom{-}\\bar{z} \\\\\n   -\\mathbf{\\bar{b}}^{\\top} & \\phantom{-}\\mathbf{\\bar{c}}^{\\top} &  -\\bar{z} & \\phantom{-}0   \\end{pmatrix}, \\\\\n\\min \\ &(\\mathbf{\\bar{x}}^{\\top} \\mathbf{\\bar{s}} + 1)\\theta \\\\\n\\textrm{s.t.}\\;\\;&G \\begin{pmatrix}\n \\mathbf{y} \\\\ \\mathbf{x} \\\\ \\xi \\\\ \\theta\n\\end{pmatrix} -\n\\begin{pmatrix}\n \\mathbf{0} \\\\ \\mathbf{s} \\\\ \\kappa \\\\ 0\n\\end{pmatrix} =\n\\begin{pmatrix}\n \\mathbf{0} \\\\ \\mathbf{0} \\\\ 0 \\\\ -\\mathbf{\\bar{x}}^{\\top} \\mathbf{\\bar{s}} - 1\n\\end{pmatrix} \\\\\n &            (\\mathbf{x}, \\xi) \\in \\mathcal{K} \\times \\mathbb{R}_{+}, \\  ( \\mathbf{s}, \\kappa)\\in \\mathcal{K}^* \\times \\mathbb{R}_{+}, \\  \\mathbf{y} \\in \\mathbb{R}^m\n\\end{aligned}", "gap_objective": "Establish the fundamental properties of the Homogeneous Self-Dual (HSD) model, specifically its self-duality, the existence of a strictly feasible starting point, and the correspondence between its optimal solutions and those of the original problem."}}, "ground_truth": {"target_citation_key": "deKlerk1998", "target_lemma_latex": "\\text{The HSD model (3.11) is self-dual, and the point } (\\mathbf{x}, \\mathbf{y}, \\mathbf{s}, \\xi, \\theta, \\kappa) = (\\bar{\\mathbf{x}}, \\bar{\\mathbf{y}}, \\bar{\\mathbf{s}}, 1, 1, 1) \\text{ is a strictly feasible solution. The optimum value is } 0, \\text{ and if } \\xi > 0 \\text{ at an optimal solution, then } (\\mathbf{x}/ \\xi, \\mathbf{y}/ \\xi, \\mathbf{s} / \\xi) \\text{ is an optimal solution to the original primal-dual pair of problems.}", "target_citation_content": "\\sc E.~de~Klerk, C.~Roos, and T.~Terlaky, \\em Infeasible start semidefinite programming algorithms via self-dual embeddings, in Topics in Semidefinite and Interior Point Methods, H.~Wolkowicz and P.~M. Pardalos, eds., vol.~18 of Fields Institute Communications, American Mathematical Society, Providence, RI, 1998, pp.~215--236, \\urlhttps://doi.org/10.1090/fic/018/15."}}
{"id": "2502.16020v1_gap_5", "arxiv_id": "2502.16020v1", "title": "Interior-point algorithms with full Newton steps for nonsymmetric convex conic optimization", "publication_date": "2025-02-22", "problem_input": {"global_context": {"setup": "The paper considers convex optimization problems in standard conic form: $\\min \\mathbf{c}^\\top \\mathbf{x}$ s.t. $A\\mathbf{x} = \\mathbf{b}, \\mathbf{x} \\in \\mathcal{K}$, and its dual. $\\mathcal{K} \\subseteq \\mathbb{R}^n$ is a proper convex cone with interior $\\mathcal{K}^\\circ$, equipped with a logarithmically homogeneous self-concordant barrier (LHSCB) $f: \\mathcal{K}^{\\circ} \\rightarrow \\mathbb{R}$ with barrier parameter $\\nu$. The central path is defined by solutions to $\\mathbf{s} + \\tau g(\\mathbf{x}) = \\mathbf{0}$ for $\\tau > 0$, where $g$ is the gradient of $f$. The algorithm operates in a neighborhood $\\mathcal{N}(\\eta,\\tau) = \\{ (\\mathbf{x}, \\mathbf{y}, \\mathbf{s}) \\in \\mathcal{F}^\\circ : \\| \\mathbf{s} + \\tau g(\\mathbf{x}) \\|_{\\mathbf{x}}^* \\leq \\eta \\tau \\}$.", "goal": "Theorem 2.4: If $0 < \\eta \\leq \\frac{1}{4}$ and $\\vartheta = \\frac{\\eta / 2}{\\sqrt{\\nu} + 1}$, the proposed Algorithm 1 produces a feasible solution with duality gap below $\\varepsilon$ in $\\mathcal{O}(\\sqrt{\\nu} \\ln (\\frac{\\tau_0 \\nu}{\\varepsilon}))$ iterations."}, "local_context": {"anchor_latex": "\\min \\ (\\mathbf{\\bar{x}}^{\\top} \\mathbf{\\bar{s}} + 1)\\theta \\\\ \\textrm{s.t.}\\;\\;G \\begin{pmatrix} \\mathbf{y} \\\\ \\mathbf{x} \\\\ \\xi \\\\ \\theta \\end{pmatrix} - \\begin{pmatrix} \\mathbf{0} \\\\ \\mathbf{s} \\\\ \\kappa \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} \\mathbf{0} \\\\ \\mathbf{0} \\\\ 0 \\\\ -\\mathbf{\\bar{x}}^{\\top} \\mathbf{\\bar{s}} - 1 \\end{pmatrix} \\\\ (\\mathbf{x}, \\xi) \\in \\mathcal{K} \\times \\mathbb{R}_{+}, \\  ( \\mathbf{s}, \\kappa)\\in \\mathcal{K}^* \\times \\mathbb{R}_{+}, \\  \\mathbf{y} \\in \\mathbb{R}^m", "gap_objective": "Establish that the constructed homogeneous self-dual (HSD) model is indeed self-dual and admits a trivial strictly feasible starting point, justifying its use for initialization."}}, "ground_truth": {"target_citation_key": "Luo2000", "target_lemma_latex": "\\text{The HSD model (\\ref{eq:HSD_model}) is self-dual, and the point } (\\mathbf{x}, \\mathbf{y}, \\mathbf{s}, \\xi, \\theta, \\kappa) = (\\bar{\\mathbf{x}}, \\bar{\\mathbf{y}}, \\bar{\\mathbf{s}}, 1, 1, 1) \\text{ is a strictly feasible solution. The optimum value is } 0, \\text{ and if } \\xi > 0 \\text{ at an optimal solution, then } (\\mathbf{x}/ \\xi, \\mathbf{y}/ \\xi, \\mathbf{s} / \\xi) \\text{ is an optimal solution to the original primal-dual pair of problems.}", "target_citation_content": "\\sc Z.-Q. Luo, J.~F. Sturm, and S.~Zhang, \\em Conic convex programming and self-dual embedding, Optimization Methods and Software, 14 (2000), pp.~169--218, \\urlhttps://doi.org/10.1080/10556780008805800."}}
{"id": "2212.02727v5_gap_0", "arxiv_id": "2212.02727v5", "title": "Relative Well-Posedness of Truncated Constrained Systems Accompanied by Variational Calculus", "publication_date": "2022-12-06", "problem_input": {"global_context": {"setup": "The paper investigates the stability of set-valued mappings $S: X \\rightrightarrows Y$ between Banach spaces (often assumed reflexive), subject to domain constraints $\\Omega \\subset X$ and image truncations $\\Theta \\subset Y$. The analysis focuses on a point $(\\bar{x}, \\bar{y}) \\in \\operatorname{gph} S|_{\\Omega}^{\\Theta}$. Key definitions include the duality mapping $J_X$, $\\varepsilon$-normals $\\widehat N_\\varepsilon$, and newly introduced relative contingent coderivatives (e.g., $D_M^*S_\\Omega^\\Theta$).", "goal": "Theorem 3.8 establishes a complete characterization of the Lipschitz-like property of $S$ relative to $\\Omega \\times \\Theta$ around $(\\bar{x}, \\bar{y})$. Specifically, $S$ is relative Lipschitz-like if and only if it is partially sequentially normally compact (PSNC) relative to $\\Omega \\times \\Theta$ and its relative mixed contingent coderivative at zero is trivial ($D_M^*S_\\Omega^\\Theta(\\bar{x}|\\bar{y})(0)=\\{0\\}$)."}, "local_context": {"anchor_latex": "J_{X\\times Y}(x,y)=(J_X(x), J_Y(y))", "gap_objective": "To determine the subdifferential of the norm $\\partial\\|(\\cdot,\\cdot)\\|_{X\\times Y}(x,y)$ on the product space using the duality mapping."}}, "ground_truth": {"target_citation_key": "Nam", "target_lemma_latex": "\\partial\\|x\\| = \\begin{cases} B_{X^*} & \\text{if } x=0 \\\\ \\frac{J(x)}{\\|x\\|} & \\text{if } x\\neq 0 \\end{cases}", "target_citation_content": "B.S. Mordukhovich and N.M. Nam, \\it Convex Analysis and Beyond, I: Basic Theory, Springer, Cham, 2022."}}
{"id": "2212.02727v5_gap_1", "arxiv_id": "2212.02727v5", "title": "Relative Well-Posedness of Truncated Constrained Systems Accompanied by Variational Calculus", "publication_date": "2022-12-06", "problem_input": {"global_context": {"setup": "The paper investigates the stability of set-valued mappings $S: X \\rightrightarrows Y$ between Banach spaces (often assumed reflexive), subject to domain constraints $\\Omega \\subset X$ and image truncations $\\Theta \\subset Y$. The analysis focuses on a point $(\\bar{x}, \\bar{y}) \\in \\operatorname{gph} S|_{\\Omega}^{\\Theta}$. Key definitions include the duality mapping $J_X$, $\\varepsilon$-normals $\\widehat N_\\varepsilon$, and newly introduced relative contingent coderivatives (e.g., $D_M^*S_\\Omega^\\Theta$).", "goal": "Theorem 3.8 establishes a complete characterization of the Lipschitz-like property of $S$ relative to $\\Omega \\times \\Theta$ around $(\\bar{x}, \\bar{y})$. Specifically, $S$ is relative Lipschitz-like if and only if it is partially sequentially normally compact (PSNC) relative to $\\Omega \\times \\Theta$ and its relative mixed contingent coderivative at zero is trivial ($D_M^*S_\\Omega^\\Theta(\\bar{x}|\\bar{y})(0)=\\{0\\}$)."}, "local_context": {"anchor_latex": "\\widehat\\partial\\varphi(\\bar x):=\\Big\\{x^*\\in X^*~\\Big|~{ \\liminf\\limits_{x\\to\\bar x}}\\frac{\\varphi(x)-\\varphi(\\bar x)-\\langle x^*,x-\\bar x\\rangle}{\\|x-\\bar x\\|_X}\\ge 0\\Big\\}", "gap_objective": "Establish a fuzzy intersection rule for the set of $\\varepsilon$-normals to the intersection of two sets $\\Omega_1$ and $\\Omega_2$ in a reflexive Banach space."}}, "ground_truth": {"target_citation_key": "Mordukhovich2006", "target_lemma_latex": "Let X be a reflexive Banach space and \\Omega_1, \\Omega_2 \\subset X be locally closed around \\bar x \\in \\Omega_1 \\cap \\Omega_2. Suppose that x^* \\in \\widehat N(\\bar x; \\Omega_1 \\cap \\Omega_2). Then for any \\gamma > 0 there exist \\lambda \\geq 0, x_i \\in \\Omega_i \\cap (\\bar x + \\gamma B_X), and x_i^* \\in \\widehat N(x_i; \\Omega_i) + \\gamma B_{X^*}, i=1,2, such that \\lambda x^* = x_1^* + x_2^* and \\max\\{\\lambda, \\|x_1^*\\|\\} = 1.", "target_citation_content": "B.S. Mordukhovich, \\it Variational Analysis and Generalized Differentiation, I: Basic Theory, II; Applications, Springer, Berlin, 2006."}}
{"id": "2212.02727v5_gap_3", "arxiv_id": "2212.02727v5", "title": "Relative Well-Posedness of Truncated Constrained Systems Accompanied by Variational Calculus", "publication_date": "2022-12-06", "problem_input": {"global_context": {"setup": "The paper investigates the stability of set-valued mappings $S: X \\rightrightarrows Y$ between Banach spaces (often assumed reflexive), subject to domain constraints $\\Omega \\subset X$ and image truncations $\\Theta \\subset Y$. The analysis focuses on a point $(\\bar{x}, \\bar{y}) \\in \\operatorname{gph} S|_{\\Omega}^{\\Theta}$. Key definitions include the duality mapping $J_X$, $\\varepsilon$-normals $\\widehat N_\\varepsilon$, and newly introduced relative contingent coderivatives (e.g., $D_M^*S_\\Omega^\\Theta$).", "goal": "Theorem 3.8 establishes a complete characterization of the Lipschitz-like property of $S$ relative to $\\Omega \\times \\Theta$ around $(\\bar{x}, \\bar{y})$. Specifically, $S$ is relative Lipschitz-like if and only if it is partially sequentially normally compact (PSNC) relative to $\\Omega \\times \\Theta$ and its relative mixed contingent coderivative at zero is trivial ($D_M^*S_\\Omega^\\Theta(\\bar{x}|\\bar{y})(0)=\\{0\\}$)."}, "local_context": {"anchor_latex": "(\\tilde{x},\\tilde{y}) \\text{ is a local minimum of } \\varphi + \\phi", "gap_objective": "Obtain a fuzzy multiplier rule that expresses the necessary optimality condition for the sum of two functions in terms of their individual regular subgradients evaluated at nearby points."}}, "ground_truth": {"target_citation_key": "Mordukhovich2006", "target_lemma_latex": "Let X be an Asplund space, and let f_1, f_2: X \\to \\overline{\\mathbb{R}} be lower semicontinuous functions. If \\bar{x} is a local minimizer of f_1 + f_2, then for any \\varepsilon > 0, there exist x_1, x_2 \\in X close to \\bar{x} such that 0 \\in \\widehat{\\partial} f_1(x_1) + \\widehat{\\partial} f_2(x_2) + \\varepsilon B_{X^*}.", "target_citation_content": "B.S. Mordukhovich, \\it Variational Analysis and Generalized Differentiation, I: Basic Theory, II; Applications, Springer, Berlin, 2006."}}
{"id": "2212.02727v5_gap_4", "arxiv_id": "2212.02727v5", "title": "Relative Well-Posedness of Truncated Constrained Systems Accompanied by Variational Calculus", "publication_date": "2022-12-06", "problem_input": {"global_context": {"setup": "The paper investigates the stability of set-valued mappings $S: X \\rightrightarrows Y$ between Banach spaces (often assumed reflexive), subject to domain constraints $\\Omega \\subset X$ and image truncations $\\Theta \\subset Y$. The analysis focuses on a point $(\\bar{x}, \\bar{y}) \\in \\operatorname{gph} S|_{\\Omega}^{\\Theta}$. Key definitions include the duality mapping $J_X$, $\\varepsilon$-normals $\\widehat N_\\varepsilon$, and newly introduced relative contingent coderivatives (e.g., $D_M^*S_\\Omega^\\Theta$).", "goal": "Theorem 3.8 establishes a complete characterization of the Lipschitz-like property of $S$ relative to $\\Omega \\times \\Theta$ around $(\\bar{x}, \\bar{y})$. Specifically, $S$ is relative Lipschitz-like if and only if it is partially sequentially normally compact (PSNC) relative to $\\Omega \\times \\Theta$ and its relative mixed contingent coderivative at zero is trivial ($D_M^*S_\\Omega^\\Theta(\\bar{x}|\\bar{y})(0)=\\{0\\}$)."}, "local_context": {"anchor_latex": "d\\left(\\frac{J_X(x'-x)}{\\|x'-x\\|_X},J_X(T(x;\\Omega)\\cap\\mathbb S_X)\\right)<\\varepsilon\\;\\mbox{ whenever }\\;x,x'\\in\\Omega\\cap[\\bar x+\\delta B_X]~\\mbox{with}~x\\ne x'", "gap_objective": "To identify sufficient conditions on the Banach space $X$ (specifically regarding its dual $X^*$) that ensure the duality mapping $J_X$ is uniformly continuous on the unit sphere $\\mathbb{S}_X$, as required by the preceding lemma."}}, "ground_truth": {"target_citation_key": "Barbu1993", "target_lemma_latex": "The duality mapping J_X of a reflexive Banach space with the uniformly convex dual space X^* is uniformly continuous on \\mathbb S_X", "target_citation_content": "V. Barbu, \\it Analysis and Control of Nonlinear Infinite-dimensional Systems, Academic Press, Inc., Boston, MA, 1993."}}
{"id": "2212.02727v5_gap_5", "arxiv_id": "2212.02727v5", "title": "Relative Well-Posedness of Truncated Constrained Systems Accompanied by Variational Calculus", "publication_date": "2022-12-06", "problem_input": {"global_context": {"setup": "The paper investigates the stability of set-valued mappings $S: X \\rightrightarrows Y$ between Banach spaces (often assumed reflexive), subject to domain constraints $\\Omega \\subset X$ and image truncations $\\Theta \\subset Y$. The analysis focuses on a point $(\\bar{x}, \\bar{y}) \\in \\operatorname{gph} S|_{\\Omega}^{\\Theta}$. Key definitions include the duality mapping $J_X$, $\\varepsilon$-normals $\\widehat N_\\varepsilon$, and newly introduced relative contingent coderivatives (e.g., $D_M^*S_\\Omega^\\Theta$).", "goal": "Theorem 3.8 establishes a complete characterization of the Lipschitz-like property of $S$ relative to $\\Omega \\times \\Theta$ around $(\\bar{x}, \\bar{y})$. Specifically, $S$ is relative Lipschitz-like if and only if it is partially sequentially normally compact (PSNC) relative to $\\Omega \\times \\Theta$ and its relative mixed contingent coderivative at zero is trivial ($D_M^*S_\\Omega^\\Theta(\\bar{x}|\\bar{y})(0)=\\{0\\}$)."}, "local_context": {"anchor_latex": "\\big[x_k\\rightharpoonup x,~ \\|x_k\\|_X\\to \\|x\\|_X\\big]\\Longleftrightarrow x_k\\to x~~\\text{as}~k\\to\\infty", "gap_objective": "Identify sufficient conditions for a Banach space to satisfy the Kadec-Klee property (specifically concerning locally uniformly convex spaces)."}}, "ground_truth": {"target_citation_key": "deville", "target_lemma_latex": "\\text{Every locally uniformly convex Banach space with a strictly convex norm enjoys the Kadec-Klee property.}", "target_citation_content": "R. Deville, G. Godefroy and V. Zisler, \\it Smoothness and Renormings in Banach Spaces, Longman, Harlow, 1993."}}
{"id": "2212.02727v5_gap_6", "arxiv_id": "2212.02727v5", "title": "Relative Well-Posedness of Truncated Constrained Systems Accompanied by Variational Calculus", "publication_date": "2022-12-06", "problem_input": {"global_context": {"setup": "The paper investigates the stability of set-valued mappings $S: X \\rightrightarrows Y$ between Banach spaces (often assumed reflexive), subject to domain constraints $\\Omega \\subset X$ and image truncations $\\Theta \\subset Y$. The analysis focuses on a point $(\\bar{x}, \\bar{y}) \\in \\operatorname{gph} S|_{\\Omega}^{\\Theta}$. Key definitions include the duality mapping $J_X$, $\\varepsilon$-normals $\\widehat N_\\varepsilon$, and newly introduced relative contingent coderivatives (e.g., $D_M^*S_\\Omega^\\Theta$).", "goal": "Theorem 3.8 establishes a complete characterization of the Lipschitz-like property of $S$ relative to $\\Omega \\times \\Theta$ around $(\\bar{x}, \\bar{y})$. Specifically, $S$ is relative Lipschitz-like if and only if it is partially sequentially normally compact (PSNC) relative to $\\Omega \\times \\Theta$ and its relative mixed contingent coderivative at zero is trivial ($D_M^*S_\\Omega^\\Theta(\\bar{x}|\\bar{y})(0)=\\{0\\}$)."}, "local_context": {"anchor_latex": "(\\tilde y_k^*,-\\tilde z_k^*)\\in\\widehat N\\big((\\tilde y_k,\\tilde z_k);\\operatorname{gph} S_2|^\\Theta\\big)", "gap_objective": "Express the regular normal cone to the graph of the strictly differentiable function S_2 = f in terms of its strict derivative."}}, "ground_truth": {"target_citation_key": "Mordukhovich2006", "target_lemma_latex": "\\widehat N((\\bar x, \\bar y); \\operatorname{gph} f) = \\big\\{ (x^*, y^*) \\in X^* \\times Y^* \\mid x^* + \\nabla f(\\bar x)^* y^* = 0 \\big\\}", "target_citation_content": "B.S. Mordukhovich, \\it Variational Analysis and Generalized Differentiation, I: Basic Theory, II; Applications, Springer, Berlin, 2006."}}
{"id": "2212.02727v5_gap_7", "arxiv_id": "2212.02727v5", "title": "Relative Well-Posedness of Truncated Constrained Systems Accompanied by Variational Calculus", "publication_date": "2022-12-06", "problem_input": {"global_context": {"setup": "The paper investigates the stability of set-valued mappings $S: X \\rightrightarrows Y$ between Banach spaces (often assumed reflexive), subject to domain constraints $\\Omega \\subset X$ and image truncations $\\Theta \\subset Y$. The analysis focuses on a point $(\\bar{x}, \\bar{y}) \\in \\operatorname{gph} S|_{\\Omega}^{\\Theta}$. Key definitions include the duality mapping $J_X$, $\\varepsilon$-normals $\\widehat N_\\varepsilon$, and newly introduced relative contingent coderivatives (e.g., $D_M^*S_\\Omega^\\Theta$).", "goal": "Theorem 3.8 establishes a complete characterization of the Lipschitz-like property of $S$ relative to $\\Omega \\times \\Theta$ around $(\\bar{x}, \\bar{y})$. Specifically, $S$ is relative Lipschitz-like if and only if it is partially sequentially normally compact (PSNC) relative to $\\Omega \\times \\Theta$ and its relative mixed contingent coderivative at zero is trivial ($D_M^*S_\\Omega^\\Theta(\\bar{x}|\\bar{y})(0)=\\{0\\}$)."}, "local_context": {"anchor_latex": "\\bar x\\in\\inte \\Omega", "gap_objective": "Evaluate the mixed contingent coderivative of $S_1$ relative to $\\Omega$ at $(\\bar x, \\bar y)$ given the interiority of $\\bar x$."}}, "ground_truth": {"target_citation_key": "Mordukhovich2006", "target_lemma_latex": "D^*S_1(\\bar x\\vbl\\bar y)(y^*) = \\{0\\} \\quad \\text{for all } y^* \\in Y", "target_citation_content": "B.S. Mordukhovich, \\it Variational Analysis and Generalized Differentiation, I: Basic Theory, II; Applications, Springer, Berlin, 2006."}}
{"id": "2401.00108v2_gap_0", "arxiv_id": "2401.00108v2", "title": "Stochastic Optimization under Hidden Convexity", "publication_date": "2023-12-30", "problem_input": {"global_context": {"setup": "Consider the constrained stochastic optimization problem min_{x in X} F(x) := E[f(x, xi)], where X is a closed convex subset of R^d. We assume the problem admits a hidden convex structure: F(x) = H(c(x)), where c: X -> U is an invertible map and H: U -> R is a convex function on the convex set U = c(X). This structure is characterized by the modulus mu_c > 0 such that ||c(x) - c(y)|| >= mu_c ||x - y|| for all x, y in X. We assume F is l-weakly convex. The algorithm has access to a stochastic subgradient oracle g(x, xi) such that E[g(x, xi)] in partial F(x) with bounded second moment E[||g(x, xi)||^2] <= G_F^2 (or bounded variance sigma^2 in the smooth case).", "goal": "Prove global convergence rates and sample complexity for the Projected Stochastic Subgradient Method and Projected SGD (with and without momentum) applied to hidden convex problems, specifically bounding the expected Moreau envelope E[Phi_{1/rho}(x^t) - F(x^*)] or the function value gap."}, "local_context": {"anchor_latex": "0 \\in \\partial (F + \\delta_{\\cX})(\\bar{x})", "gap_objective": "Compute the subdifferential of the composite function $(H + \\delta_{\\cU}) \\circ c$ using the chain rule."}}, "ground_truth": {"target_citation_key": "rockafellar2009variational", "target_lemma_latex": "\\partial (g \\circ c)(\\bar{x}) = \\nabla c(\\bar{x})^* \\partial g(c(\\bar{x}))", "target_citation_content": "R~Tyrrell Rockafellar and Roger J-B Wets. \\newblock \\em Variational analysis, volume 317. \\newblock Springer Science \\& Business Media, 2009."}}
{"id": "2401.00108v2_gap_1", "arxiv_id": "2401.00108v2", "title": "Stochastic Optimization under Hidden Convexity", "publication_date": "2023-12-30", "problem_input": {"global_context": {"setup": "Consider the constrained stochastic optimization problem min_{x in X} F(x) := E[f(x, xi)], where X is a closed convex subset of R^d. We assume the problem admits a hidden convex structure: F(x) = H(c(x)), where c: X -> U is an invertible map and H: U -> R is a convex function on the convex set U = c(X). This structure is characterized by the modulus mu_c > 0 such that ||c(x) - c(y)|| >= mu_c ||x - y|| for all x, y in X. We assume F is l-weakly convex. The algorithm has access to a stochastic subgradient oracle g(x, xi) such that E[g(x, xi)] in partial F(x) with bounded second moment E[||g(x, xi)||^2] <= G_F^2 (or bounded variance sigma^2 in the smooth case).", "goal": "Prove global convergence rates and sample complexity for the Projected Stochastic Subgradient Method and Projected SGD (with and without momentum) applied to hidden convex problems, specifically bounding the expected Moreau envelope E[Phi_{1/rho}(x^t) - F(x^*)] or the function value gap."}, "local_context": {"anchor_latex": "c(\\cdot) \\text{ is invertible with a Lipschitz continuous inverse}", "gap_objective": "\\nabla c(\\bar{x}) \\text{ is invertible}"}}, "ground_truth": {"target_citation_key": "LAWSON2020123913", "target_lemma_latex": "\\text{If a differentiable map } f \\text{ has a Lipschitz continuous inverse, then its Jacobian } \\nabla f(x) \\text{ is invertible.}", "target_citation_content": "Jimmie Lawson. \\newblock An inverse function theorem converse. \\newblock \\em Journal of Mathematical Analysis and Applications, 486(2):123913, 2020."}}
{"id": "2401.00108v2_gap_2", "arxiv_id": "2401.00108v2", "title": "Stochastic Optimization under Hidden Convexity", "publication_date": "2023-12-30", "problem_input": {"global_context": {"setup": "Consider the constrained stochastic optimization problem min_{x in X} F(x) := E[f(x, xi)], where X is a closed convex subset of R^d. We assume the problem admits a hidden convex structure: F(x) = H(c(x)), where c: X -> U is an invertible map and H: U -> R is a convex function on the convex set U = c(X). This structure is characterized by the modulus mu_c > 0 such that ||c(x) - c(y)|| >= mu_c ||x - y|| for all x, y in X. We assume F is l-weakly convex. The algorithm has access to a stochastic subgradient oracle g(x, xi) such that E[g(x, xi)] in partial F(x) with bounded second moment E[||g(x, xi)||^2] <= G_F^2 (or bounded variance sigma^2 in the smooth case).", "goal": "Prove global convergence rates and sample complexity for the Projected Stochastic Subgradient Method and Projected SGD (with and without momentum) applied to hidden convex problems, specifically bounding the expected Moreau envelope E[Phi_{1/rho}(x^t) - F(x^*)] or the function value gap."}, "local_context": {"anchor_latex": "\\norm{(\\nabla c(x))^{-1}}_{\\text{op}} \\text{ is bounded on a compact set } \\cX", "gap_objective": "\\text{Establish that the inverse map } c^{-1}(\\cdot) \\text{ is continuously differentiable on } \\cU"}}, "ground_truth": {"target_citation_key": "ivanov2023hadamard", "target_lemma_latex": "\\text{Hadamard Global Inverse Function Theorem}", "target_citation_content": "Milen Ivanov and Nadia Zlateva. \\newblock Hadamard inverse function theorem proved by variational analysis. \\newblock \\em Serdica Mathematical Journal, 49, 2023."}}
{"id": "2401.00108v2_gap_3", "arxiv_id": "2401.00108v2", "title": "Stochastic Optimization under Hidden Convexity", "publication_date": "2023-12-30", "problem_input": {"global_context": {"setup": "Consider the constrained stochastic optimization problem min_{x in X} F(x) := E[f(x, xi)], where X is a closed convex subset of R^d. We assume the problem admits a hidden convex structure: F(x) = H(c(x)), where c: X -> U is an invertible map and H: U -> R is a convex function on the convex set U = c(X). This structure is characterized by the modulus mu_c > 0 such that ||c(x) - c(y)|| >= mu_c ||x - y|| for all x, y in X. We assume F is l-weakly convex. The algorithm has access to a stochastic subgradient oracle g(x, xi) such that E[g(x, xi)] in partial F(x) with bounded second moment E[||g(x, xi)||^2] <= G_F^2 (or bounded variance sigma^2 in the smooth case).", "goal": "Prove global convergence rates and sample complexity for the Projected Stochastic Subgradient Method and Projected SGD (with and without momentum) applied to hidden convex problems, specifically bounding the expected Moreau envelope E[Phi_{1/rho}(x^t) - F(x^*)] or the function value gap."}, "local_context": {"anchor_latex": "\\Lambda_t := \\Exp{ \\Phi_{1/\\rho}(x^t) - F(x^*) }", "gap_objective": "Control the distance between one step of the stochastic subgradient method $x^{t+1}$ and one step of the proximal point method $\\hat{x}^t$ to bound the error introduced by stochastic updates."}}, "ground_truth": {"target_citation_key": "davis2019stochastic", "target_lemma_latex": "\\mathbb{E}\\left[ \\sqnorm{ x^{t+1}-\\hat{x}^t } \\mid x^t\\right] \\leq(1-\\stepsize \\rho)\\sqnorm{x^t-\\hat{x}^t } + 4 G_F^2 \\stepsize^2", "target_citation_content": "Damek Davis and Dmitriy Drusvyatskiy. \\newblock Stochastic model-based minimization of weakly convex functions. \\newblock \\em SIAM Journal on Optimization, 29(1):207--239, 2019."}}
{"id": "2401.00108v2_gap_4", "arxiv_id": "2401.00108v2", "title": "Stochastic Optimization under Hidden Convexity", "publication_date": "2023-12-30", "problem_input": {"global_context": {"setup": "Consider the constrained stochastic optimization problem min_{x in X} F(x) := E[f(x, xi)], where X is a closed convex subset of R^d. We assume the problem admits a hidden convex structure: F(x) = H(c(x)), where c: X -> U is an invertible map and H: U -> R is a convex function on the convex set U = c(X). This structure is characterized by the modulus mu_c > 0 such that ||c(x) - c(y)|| >= mu_c ||x - y|| for all x, y in X. We assume F is l-weakly convex. The algorithm has access to a stochastic subgradient oracle g(x, xi) such that E[g(x, xi)] in partial F(x) with bounded second moment E[||g(x, xi)||^2] <= G_F^2 (or bounded variance sigma^2 in the smooth case).", "goal": "Prove global convergence rates and sample complexity for the Projected Stochastic Subgradient Method and Projected SGD (with and without momentum) applied to hidden convex problems, specifically bounding the expected Moreau envelope E[Phi_{1/rho}(x^t) - F(x^*)] or the function value gap."}, "local_context": {"anchor_latex": "x^{t+1} = \\Pi_{\\mathcal{X}}(x^t-\\stepsize \\, g^t) , \\qquad g^{t+1} = (1-\\momentum) \\, g^{t} + \\momentum \\, \\nabla f(x^{t+1}, \\xi^{t+1})", "gap_objective": "Establish a recursive bound for the expected squared error of the momentum gradient estimator, $\\mathbb{E}[ \\|g^{t+1} - \\nabla F(x^{t+1})\\|^2 ]$, in terms of the previous error and algorithm parameters."}}, "ground_truth": {"target_citation_key": "fatkhullin2023momentum", "target_lemma_latex": "\\Exp{ \\sqnorm{g^{t+1} - \\nabla F(x^{t+1})} }  \\leq (1 - \\momentum) \\Exp{ \\sqnorm{  g^{t} - \\nabla F(x^{t}) } }  + \\fr{3 L^2}{\\momentum} \\Exp{ \\sqnorm{  x^{t} - x^{t+1}  } } + \\momentum^2 \\sigma^2", "target_citation_content": "Ilyas Fatkhullin, Alexander Tyurin, and Peter Richtárik. \\newblock Momentum provably improves error feedback! \\newblock In \\em Advances in Neural Information Processing Systems, 2023."}}
{"id": "2502.18370v1_gap_0", "arxiv_id": "2502.18370v1", "title": "Convergence rate for linear minimizer-estimators in the moment-sum-of-squares hierarchy", "publication_date": "2025-02-25", "problem_input": {"global_context": {"setup": "The paper investigates the Polynomial Optimization Problem (POP) $f^\\star = \\min_{\\vx \\in \\bK} f(\\vx)$, where $\\bK$ is a closed basic semialgebraic set. The Moment-SoS hierarchy is employed, generating a sequence of moment relaxations with optimal pseudo-moments $L_d^\\star$. The analysis assumes the Archimedean property holds for $\\bK$.", "goal": "To establish quantitative convergence rates for approximating the moments of measures supported on the set of minimizers $\\bS^\\star$ using the pseudo-moments $L_d^\\star$, and to derive convergence rates for linear minimizer estimators $\\vx^{(d)}$."}, "local_context": {"anchor_latex": "f \\in \\mathbb{R}[\\mathbf{X}], \\quad \\mathbf{K} \\subset \\mathbb{R}^n \\text{ is a bounded closed semialgebraic set}, \\quad g(\\mathbf{x}) := \\mathrm{dist}(\\mathbf{x}, \\mathbf{S}^\\star) \\text{ where } \\mathbf{S}^\\star = \\{\\mathbf{x} \\in \\mathbf{K} : f(\\mathbf{x}) = 0\\}", "gap_objective": "Bound the distance function g in terms of the polynomial f on the set K using the semialgebraic property."}}, "ground_truth": {"target_citation_key": "lojasiewicz1959probleme", "target_lemma_latex": "\\text{Let } \\mathbf{K} \\text{ be a bounded closed semialgebraic set and } f,g \\text{ be continuous semialgebraic functions with } f^{-1}(\\{0\\}) \\subset g^{-1}(\\{0\\}). \\text{ Then there exist } \\mathfrak{c}, \\mathcal{L} \\geq 0 \\text{ with } |g(\\mathbf{x})|^{\\mathcal{L}} \\leq \\mathfrak{c} |f(\\mathbf{x})| \\text{ for all } \\mathbf{x} \\in \\mathbf{K}.", "target_citation_content": "Stanis\\law \\Lojasiewicz. \\newblock Sur le probleme de la division. \\newblock \\em Studia Mathematica, 18(1):87--136, 1959."}}
{"id": "2502.18370v1_gap_1", "arxiv_id": "2502.18370v1", "title": "Convergence rate for linear minimizer-estimators in the moment-sum-of-squares hierarchy", "publication_date": "2025-02-25", "problem_input": {"global_context": {"setup": "The paper investigates the Polynomial Optimization Problem (POP) $f^\\star = \\min_{\\vx \\in \\bK} f(\\vx)$, where $\\bK$ is a closed basic semialgebraic set. The Moment-SoS hierarchy is employed, generating a sequence of moment relaxations with optimal pseudo-moments $L_d^\\star$. The analysis assumes the Archimedean property holds for $\\bK$.", "goal": "To establish quantitative convergence rates for approximating the moments of measures supported on the set of minimizers $\\bS^\\star$ using the pseudo-moments $L_d^\\star$, and to derive convergence rates for linear minimizer estimators $\\vx^{(d)}$."}, "local_context": {"anchor_latex": "L_d \\in \\mathcal{Q}_d(\\mathbf{p})^* \\text{ with } L_d(1)=1 \\text{ and } L_d(f) \\leq m_d^\\star + \\varepsilon_d", "gap_objective": "Approximate the pseudo-moments of $L_d$ by the moments of a probability measure $\\mu'$ supported on $\\mathbf{K}$ with a quantitative error bound."}}, "ground_truth": {"target_citation_key": "baldi2021moment", "target_lemma_latex": "d_H(\\mathcal{M}^{(1)}(\\mathbf{K})^t, \\mathcal{L}_d^{(1)}(\\mathbf{p})^t) \\leq 6 \\gamma(n,\\mathbf{p})^{\\frac{1}{2.5n\\text{\\L}}} t^{\\frac{12}{5}} \\binom{n+t}{t} d^{-\\frac{1}{2.5n\\text{\\L}}}", "target_citation_content": "Lorenzo Baldi and Bernard Mourrain. \\newblock On the effective Putinar鈥檚 Positivstellensatz and moment approximation. \\newblock \\em Mathematical Programming, 200(1):71--103, 2023."}}
{"id": "2502.18370v1_gap_2", "arxiv_id": "2502.18370v1", "title": "Convergence rate for linear minimizer-estimators in the moment-sum-of-squares hierarchy", "publication_date": "2025-02-25", "problem_input": {"global_context": {"setup": "The paper investigates the Polynomial Optimization Problem (POP) $f^\\star = \\min_{\\vx \\in \\bK} f(\\vx)$, where $\\bK$ is a closed basic semialgebraic set. The Moment-SoS hierarchy is employed, generating a sequence of moment relaxations with optimal pseudo-moments $L_d^\\star$. The analysis assumes the Archimedean property holds for $\\bK$.", "goal": "To establish quantitative convergence rates for approximating the moments of measures supported on the set of minimizers $\\bS^\\star$ using the pseudo-moments $L_d^\\star$, and to derive convergence rates for linear minimizer estimators $\\vx^{(d)}$."}, "local_context": {"anchor_latex": "\\text{Let } f\\in \\R[\\bX]. \\text{ Assume that } \\bK \\subset [-1,1]^n \\text{ has non-empty interior and is a convex closed basic semialgebraic set.}", "gap_objective": "Determine the convergence rate of the upper bound hierarchy values u_d^\\star to the minimum f^\\star for convex bodies."}}, "ground_truth": {"target_citation_key": "de2017convergence", "target_lemma_latex": "\\exists d_0 \\in \\N, C' \\text{ such that } \\forall d \\geq d_0, \\quad u_d^\\star - f^\\star \\leq \\frac{C'}{\\sqrt{d}}", "target_citation_content": "Etienne De~Klerk, Monique Laurent, and Zhao Sun. \\newblock Convergence analysis for lasserre鈥檚 measure-based hierarchy of upper bounds for polynomial optimization. \\newblock \\em Mathematical Programming, 162(1):363--392, 2017."}}
{"id": "2312.14341v2_gap_0", "arxiv_id": "2312.14341v2", "title": "A full splitting algorithm for fractional programs with structured numerators and denominators", "publication_date": "2023-12-22", "problem_input": {"global_context": {"setup": "The problem considers minimizing a fractional function $F({\\h x}):=\\frac{g(A{\\h x})+h({\\h x})}{f(K{\\h x})}$ over a nonempty convex compact set ${\\cal S} \\subseteq {\\mathbb R}^n$. Here, $f:{\\mathbb R}^p\\rightarrow{{\\overline{\\mathbb R}}}$ and $g: {\\mathbb R}^s\\rightarrow{\\overline{\\mathbb R}}$ are proper, convex, lower semicontinuous functions; $A$ and $K$ are linear operators; $h$ is a differentiable function with $L_{\\nabla h}$-Lipschitz continuous gradient. It is assumed that $f(K{\\h x})>0$ on ${\\cal S}$. The algorithm analyzed is the Adaptive FSPS (Full Splitting Proximal Subgradient with extrapolation), which generates a sequence $\\{{\\h x}^k, {\\h y}^k, {\\h z}^k, {\\h u}^k\\}$ using proximal evaluations of $g^*$, subgradients of $f$, and gradients of $h$.", "goal": "Theorem 6.5: Under the KL property assumptions (on either the merit function $\\Gamma$ or $\\Pi$), the sequence generated by Adaptive FSPS satisfies $\\sum_{k} (\\|{\\h x}^k-{\\h x}^{k+1}\\| + \\|{\\h u}^k-{\\h u}^{k+1}\\| + \\|{\\h z}^k -{\\h z}^{k+1}\\|) <+\\infty$ and converges to a limiting lifted stationary point of the problem."}, "local_context": {"anchor_latex": "{\\hat{\\partial}}(\\alpha_1 f_2)({\\h x})\\neq {\\emptyset}", "gap_objective": "Relate the Fr\\'echet subdifferential of the difference $\\alpha_2 f_1 - \\alpha_1 f_2$ to the difference of their subdifferentials"}}, "ground_truth": {"target_citation_key": "MNY06", "target_lemma_latex": "{\\hat\\partial} (\\phi_1 - \\phi_2)(\\bar{x}) \\subseteq {\\hat\\partial} \\phi_1(\\bar{x}) - {\\hat\\partial} \\phi_2(\\bar{x})", "target_citation_content": "B.~S. Mordukhovich, N.~M. Nam and N.~D. Yen, \\em Fr\\'echet subdifferential calculus and optimality conditions in nondifferentiable programming, Optimization 55 (2006), pp. 685--708. \\vspace-0.03cm"}}
{"id": "2312.14341v2_gap_1", "arxiv_id": "2312.14341v2", "title": "A full splitting algorithm for fractional programs with structured numerators and denominators", "publication_date": "2023-12-22", "problem_input": {"global_context": {"setup": "The problem considers minimizing a fractional function $F({\\h x}):=\\frac{g(A{\\h x})+h({\\h x})}{f(K{\\h x})}$ over a nonempty convex compact set ${\\cal S} \\subseteq {\\mathbb R}^n$. Here, $f:{\\mathbb R}^p\\rightarrow{{\\overline{\\mathbb R}}}$ and $g: {\\mathbb R}^s\\rightarrow{\\overline{\\mathbb R}}$ are proper, convex, lower semicontinuous functions; $A$ and $K$ are linear operators; $h$ is a differentiable function with $L_{\\nabla h}$-Lipschitz continuous gradient. It is assumed that $f(K{\\h x})>0$ on ${\\cal S}$. The algorithm analyzed is the Adaptive FSPS (Full Splitting Proximal Subgradient with extrapolation), which generates a sequence $\\{{\\h x}^k, {\\h y}^k, {\\h z}^k, {\\h u}^k\\}$ using proximal evaluations of $g^*$, subgradients of $f$, and gradients of $h$.", "goal": "Theorem 6.5: Under the KL property assumptions (on either the merit function $\\Gamma$ or $\\Pi$), the sequence generated by Adaptive FSPS satisfies $\\sum_{k} (\\|{\\h x}^k-{\\h x}^{k+1}\\| + \\|{\\h u}^k-{\\h u}^{k+1}\\| + \\|{\\h z}^k -{\\h z}^{k+1}\\|) <+\\infty$ and converges to a limiting lifted stationary point of the problem."}, "local_context": {"anchor_latex": "\\dom g = \\R^n, \\quad \\nabla g \\text{ is } L_{\\nabla g}\\text{-Lipschitz continuous}, \\quad {{\\h z}}=\\nabla g({\\h w}+\\overline{\\h u})", "gap_objective": "Upper bound for g({\\h w})-g({\\h w}+\\overline {\\h u}) + \\langle \\overline{\\h u}, {{\\h z}} \\rangle"}}, "ground_truth": {"target_citation_key": "BST14", "target_lemma_latex": "f(y) \\leq f(x) + \\langle \\nabla f(x), y-x \\rangle + \\frac{L}{2}\\|y-x\\|^2", "target_citation_content": "J.~Bolte, S.~Sabach, and M.~Teboulle, \\em Proximal alternating linearized minimization for nonconvex and nonsmooth problems, Mathematical Programming 146 (2014), pp. 459-494. \\vspace-0.03cm"}}
{"id": "2312.14341v2_gap_2", "arxiv_id": "2312.14341v2", "title": "A full splitting algorithm for fractional programs with structured numerators and denominators", "publication_date": "2023-12-22", "problem_input": {"global_context": {"setup": "The problem considers minimizing a fractional function $F({\\h x}):=\\frac{g(A{\\h x})+h({\\h x})}{f(K{\\h x})}$ over a nonempty convex compact set ${\\cal S} \\subseteq {\\mathbb R}^n$. Here, $f:{\\mathbb R}^p\\rightarrow{{\\overline{\\mathbb R}}}$ and $g: {\\mathbb R}^s\\rightarrow{\\overline{\\mathbb R}}$ are proper, convex, lower semicontinuous functions; $A$ and $K$ are linear operators; $h$ is a differentiable function with $L_{\\nabla h}$-Lipschitz continuous gradient. It is assumed that $f(K{\\h x})>0$ on ${\\cal S}$. The algorithm analyzed is the Adaptive FSPS (Full Splitting Proximal Subgradient with extrapolation), which generates a sequence $\\{{\\h x}^k, {\\h y}^k, {\\h z}^k, {\\h u}^k\\}$ using proximal evaluations of $g^*$, subgradients of $f$, and gradients of $h$.", "goal": "Theorem 6.5: Under the KL property assumptions (on either the merit function $\\Gamma$ or $\\Pi$), the sequence generated by Adaptive FSPS satisfies $\\sum_{k} (\\|{\\h x}^k-{\\h x}^{k+1}\\| + \\|{\\h u}^k-{\\h u}^{k+1}\\| + \\|{\\h z}^k -{\\h z}^{k+1}\\|) <+\\infty$ and converges to a limiting lifted stationary point of the problem."}, "local_context": {"anchor_latex": "f \\text{ is a proper, convex function, } \\mathcal{S} \\text{ is compact, and } K(\\mathcal{S}) \\subseteq \\operatorname{int}(\\operatorname{dom} f)", "gap_objective": "\\sup_{{\\h x}\\in\\cal S} f(K{\\h x})<+\\infty"}}, "ground_truth": {"target_citation_key": "Rock70", "target_lemma_latex": "\\text{Let } f \\text{ be a proper convex function on } \\mathbb{R}^n. \\text{ Then } f \\text{ is locally Lipschitzian on } \\operatorname{int}(\\operatorname{dom} f).", "target_citation_content": "R.~T. Rockafellar, \\em Convex Analysis, Princeton University Press, Princeton, 1970. \\vspace-0.03cm"}}
{"id": "2312.14341v2_gap_3", "arxiv_id": "2312.14341v2", "title": "A full splitting algorithm for fractional programs with structured numerators and denominators", "publication_date": "2023-12-22", "problem_input": {"global_context": {"setup": "The problem considers minimizing a fractional function $F({\\h x}):=\\frac{g(A{\\h x})+h({\\h x})}{f(K{\\h x})}$ over a nonempty convex compact set ${\\cal S} \\subseteq {\\mathbb R}^n$. Here, $f:{\\mathbb R}^p\\rightarrow{{\\overline{\\mathbb R}}}$ and $g: {\\mathbb R}^s\\rightarrow{\\overline{\\mathbb R}}$ are proper, convex, lower semicontinuous functions; $A$ and $K$ are linear operators; $h$ is a differentiable function with $L_{\\nabla h}$-Lipschitz continuous gradient. It is assumed that $f(K{\\h x})>0$ on ${\\cal S}$. The algorithm analyzed is the Adaptive FSPS (Full Splitting Proximal Subgradient with extrapolation), which generates a sequence $\\{{\\h x}^k, {\\h y}^k, {\\h z}^k, {\\h u}^k\\}$ using proximal evaluations of $g^*$, subgradients of $f$, and gradients of $h$.", "goal": "Theorem 6.5: Under the KL property assumptions (on either the merit function $\\Gamma$ or $\\Pi$), the sequence generated by Adaptive FSPS satisfies $\\sum_{k} (\\|{\\h x}^k-{\\h x}^{k+1}\\| + \\|{\\h u}^k-{\\h u}^{k+1}\\| + \\|{\\h z}^k -{\\h z}^{k+1}\\|) <+\\infty$ and converges to a limiting lifted stationary point of the problem."}, "local_context": {"anchor_latex": "g \\text{ is essentially strictly convex}", "gap_objective": "Establish the smoothness properties of the conjugate function $g^*$"}}, "ground_truth": {"target_citation_key": "Rock70", "target_lemma_latex": "f \\text{ is essentially strictly convex} \\iff f^* \\text{ is essentially smooth}", "target_citation_content": "R.~T. Rockafellar, \\em Convex Analysis, Princeton University Press, Princeton, 1970. \\vspace-0.03cm"}}
{"id": "2312.14341v2_gap_4", "arxiv_id": "2312.14341v2", "title": "A full splitting algorithm for fractional programs with structured numerators and denominators", "publication_date": "2023-12-22", "problem_input": {"global_context": {"setup": "The problem considers minimizing a fractional function $F({\\h x}):=\\frac{g(A{\\h x})+h({\\h x})}{f(K{\\h x})}$ over a nonempty convex compact set ${\\cal S} \\subseteq {\\mathbb R}^n$. Here, $f:{\\mathbb R}^p\\rightarrow{{\\overline{\\mathbb R}}}$ and $g: {\\mathbb R}^s\\rightarrow{\\overline{\\mathbb R}}$ are proper, convex, lower semicontinuous functions; $A$ and $K$ are linear operators; $h$ is a differentiable function with $L_{\\nabla h}$-Lipschitz continuous gradient. It is assumed that $f(K{\\h x})>0$ on ${\\cal S}$. The algorithm analyzed is the Adaptive FSPS (Full Splitting Proximal Subgradient with extrapolation), which generates a sequence $\\{{\\h x}^k, {\\h y}^k, {\\h z}^k, {\\h u}^k\\}$ using proximal evaluations of $g^*$, subgradients of $f$, and gradients of $h$.", "goal": "Theorem 6.5: Under the KL property assumptions (on either the merit function $\\Gamma$ or $\\Pi$), the sequence generated by Adaptive FSPS satisfies $\\sum_{k} (\\|{\\h x}^k-{\\h x}^{k+1}\\| + \\|{\\h u}^k-{\\h u}^{k+1}\\| + \\|{\\h z}^k -{\\h z}^{k+1}\\|) <+\\infty$ and converges to a limiting lifted stationary point of the problem."}, "local_context": {"anchor_latex": "\\Pi ({\\h x}, {\\h z},{\\h u}) = \\frac{{\\Psi}({\\h x},{\\h z},{\\h u}, \\delta,\\gamma)}{f(K{\\h x})}", "gap_objective": "Compute the Fréchet subdifferential of the merit function \\Pi, given that f is differentiable and g is essentially strictly convex (implying g^* is differentiable)."}}, "ground_truth": {"target_citation_key": "BDL", "target_lemma_latex": "{\\hat\\partial} \\left(\\frac{f_1}{f_2}\\right)({{\\h x}}) = \\frac{f_2({{\\h x}}){\\hat\\partial} f_1({{\\h x}}) - f_1({{\\h x}})\\nabla f_2({{\\h x}})}{f_2({{\\h x}})^2}", "target_citation_content": "R.~I. Bo\\ct, M. Dao, and G. Li, \\em Extrapolated proximal subgradient algorithms for nonconvex and nonsmooth fractional programs, Mathematics of Operations Research 47 (2022), pp.~2415--2443. \\vspace-0.03cm"}}
{"id": "2312.14341v2_gap_5", "arxiv_id": "2312.14341v2", "title": "A full splitting algorithm for fractional programs with structured numerators and denominators", "publication_date": "2023-12-22", "problem_input": {"global_context": {"setup": "The problem considers minimizing a fractional function $F({\\h x}):=\\frac{g(A{\\h x})+h({\\h x})}{f(K{\\h x})}$ over a nonempty convex compact set ${\\cal S} \\subseteq {\\mathbb R}^n$. Here, $f:{\\mathbb R}^p\\rightarrow{{\\overline{\\mathbb R}}}$ and $g: {\\mathbb R}^s\\rightarrow{\\overline{\\mathbb R}}$ are proper, convex, lower semicontinuous functions; $A$ and $K$ are linear operators; $h$ is a differentiable function with $L_{\\nabla h}$-Lipschitz continuous gradient. It is assumed that $f(K{\\h x})>0$ on ${\\cal S}$. The algorithm analyzed is the Adaptive FSPS (Full Splitting Proximal Subgradient with extrapolation), which generates a sequence $\\{{\\h x}^k, {\\h y}^k, {\\h z}^k, {\\h u}^k\\}$ using proximal evaluations of $g^*$, subgradients of $f$, and gradients of $h$.", "goal": "Theorem 6.5: Under the KL property assumptions (on either the merit function $\\Gamma$ or $\\Pi$), the sequence generated by Adaptive FSPS satisfies $\\sum_{k} (\\|{\\h x}^k-{\\h x}^{k+1}\\| + \\|{\\h u}^k-{\\h u}^{k+1}\\| + \\|{\\h z}^k -{\\h z}^{k+1}\\|) <+\\infty$ and converges to a limiting lifted stationary point of the problem."}, "local_context": {"anchor_latex": "\\Omega \\text{ is a compact set and } \\forall (\\overline{\\h x},{\\overline{\\h y}},{\\overline{\\h z}},{\\overline{\\h u}}) \\in \\Omega, \\; \\Gamma(\\overline{\\h x}, {\\overline{\\h y}}, {\\overline{\\h z}},{\\overline{\\h u}}) = {\\overline{ \\theta}}", "gap_objective": "To extend the pointwise Kurdyka-Łojasiewicz (KL) property assumed on the set \\Omega to a uniform KL inequality valid on a neighborhood of \\Omega."}}, "ground_truth": {"target_citation_key": "BST14", "target_lemma_latex": "\\text{Let } \\Omega \\subseteq \\mathbb{R}^n \\text{ be a compact set and let } f: \\mathbb{R}^n \\to \\overline{\\mathbb{R}} \\text{ be a proper lower semicontinuous function. Assume that } f \\text{ is constant on } \\Omega \\text{ and satisfies the KL property at each point of } \\Omega. \\text{ Then there exist } \\varepsilon > 0, \\eta > 0 \\text{ and } \\phi \\in \\Phi_\\eta \\text{ such that for all } x \\in \\{z : \\text{dist}(z, \\Omega) < \\varepsilon\\} \\cap \\{z : f(\\Omega) < f(z) < f(\\Omega) + \\eta\\}, \\text{ one has } \\phi'(f(x) - f(\\Omega)) \\text{dist}(0, \\partial f(x)) \\ge 1.", "target_citation_content": "J.~Bolte, S.~Sabach, and M.~Teboulle, \\em Proximal alternating linearized minimization for nonconvex and nonsmooth problems, Mathematical Programming 146 (2014), pp. 459-494. \\vspace-0.03cm"}}
{"id": "2501.03698v1_gap_0", "arxiv_id": "2501.03698v1", "title": "Computational complexity of sum-of-squares bounds for copositive programs", "publication_date": "2025-01-07", "problem_input": {"global_context": {"setup": "The paper investigates the computational complexity of solving semidefinite programming (SDP) relaxations for Copositive Programs (CP). Specifically, it focuses on the sum-of-squares (SoS) hierarchies $\\mathcal{K}_n^{(r)}$ and $\\mathcal{Q}_n^{(r)}$ approximating the copositive cone $\\mathrm{COP}_n$.", "goal": "To establish sufficient conditions (Polynomially Bounded Optimal Solution and Interior Point existence) under which the SoS relaxations of a copositive program can be computed in polynomial time to a fixed precision (Theorem 1.1)."}, "local_context": {"anchor_latex": "\\mathcal R := \\{X\\succeq 0 :\\ \\langle A_i,X\\rangle = b_i,\\ i=1,\\dots,m\\}", "gap_objective": "To state a theorem providing sufficient geometric conditions (specifically regarding inscribed and circumscribed balls of the feasible region) that guarantee the semidefinite program can be solved to a fixed accuracy in polynomial time."}}, "ground_truth": {"target_citation_key": "dKV16", "target_lemma_latex": "Let R_1,R_2 >0 be given and suppose that there exists an X_0\\in \\mathcal R so that: B(X_0,R_1) \\subseteq \\mathcal R \\subseteq B(X_0,R_2), \\dots Then for any rational \\varepsilon>0 one can find a rational matrix X^*\\in\\mathcal R such that \\langle C,X^*\\rangle - \\mathrm{val} \\leq \\varepsilon in time polynomial in n,m,\\log(R_2/R_1),\\log(1/\\varepsilon) and the bit size of the input data C,A_i,b_i and the feasible point X_0.", "target_citation_content": "Etienne de~Klerk and Frank Vallentin. \\newblock On the turing model complexity of interior point methods for semidefinite programming. \\newblock \\em SIAM Journal on Optimization, 26(3):1944--1961, 2016."}}
{"id": "2501.03698v1_gap_1", "arxiv_id": "2501.03698v1", "title": "Computational complexity of sum-of-squares bounds for copositive programs", "publication_date": "2025-01-07", "problem_input": {"global_context": {"setup": "The paper investigates the computational complexity of solving semidefinite programming (SDP) relaxations for Copositive Programs (CP). Specifically, it focuses on the sum-of-squares (SoS) hierarchies $\\mathcal{K}_n^{(r)}$ and $\\mathcal{Q}_n^{(r)}$ approximating the copositive cone $\\mathrm{COP}_n$.", "goal": "To establish sufficient conditions (Polynomially Bounded Optimal Solution and Interior Point existence) under which the SoS relaxations of a copositive program can be computed in polynomial time to a fixed precision (Theorem 1.1)."}, "local_context": {"anchor_latex": "\\|p\\|_{\\mathbb{R}[x]} = \\max_{\\alpha} \\frac{|c_\\alpha|}{\\binom{|\\alpha|}{\\alpha}} \\quad \\text{where } p=\\sum_{|\\alpha|\\leq d} c_\\alpha x^\\alpha", "gap_objective": "Bound the coefficient norm of a polynomial in terms of its supremum norm on $[-1, 1]^n$."}}, "ground_truth": {"target_citation_key": "KORDA20171", "target_lemma_latex": "\\|p\\|_{\\mathbb{R}[x]} \\leq 3^{d+1}\\max_{x\\in [-1,1]^n}|p(x)|", "target_citation_content": "Milan Korda, Didier Henrion, and Colin~N. Jones. \\newblock Convergence rates of moment-sum-of-squares hierarchies for optimal control problems. \\newblock \\em Systems \\& Control Letters, 100:1--5, 2017."}}
{"id": "2501.03698v1_gap_2", "arxiv_id": "2501.03698v1", "title": "Computational complexity of sum-of-squares bounds for copositive programs", "publication_date": "2025-01-07", "problem_input": {"global_context": {"setup": "The paper investigates the computational complexity of solving semidefinite programming (SDP) relaxations for Copositive Programs (CP). Specifically, it focuses on the sum-of-squares (SoS) hierarchies $\\mathcal{K}_n^{(r)}$ and $\\mathcal{Q}_n^{(r)}$ approximating the copositive cone $\\mathrm{COP}_n$.", "goal": "To establish sufficient conditions (Polynomially Bounded Optimal Solution and Interior Point existence) under which the SoS relaxations of a copositive program can be computed in polynomial time to a fixed precision (Theorem 1.1)."}, "local_context": {"anchor_latex": "\\text{In this section, we present a sufficient condition that guarantees that the coefficients in certain sum-of-squares proofs of nonnegativity have polynomial bit size in } n.", "gap_objective": "To guarantee that a full-dimensional semialgebraic set defined by polynomials with bounded bit size contains a ball of sufficiently large (exponentially bounded inverse) radius around a strictly feasible point."}}, "ground_truth": {"target_citation_key": "GPS23", "target_lemma_latex": "Let K=\\{x\\in \\mathbb{R}^n: g_1(x)\\geq 0, \\dots, g_m(x)\\geq 0\\} \\text{ be a full-dimensional semialgebraic set, defined by polynomials } g_1, \\ldots, g_m \\text{ whose coefficients have polynomial bit size in } n. \\text{ Assume there exists } x^* \\in \\R^n, \\text{ with } \\|x^*\\|_2 \\leq 2^{\\poly(n)} \\text{ such that } g_i(x^*)>0 \\text{ for all } i=1, \\dots, m. \\text{ Then, there exists } r \\in \\R \\text{ with } 2^{-\\poly(n)} \\leq r \\leq 2^{\\poly(n)} \\text{ such that } B_r(x^*)= \\{y\\in \\mathbb{R}^n: \\|y-x^*\\|_2\\leq r\\}\\subseteq K.", "target_citation_content": "Sander Gribling, Sven Polak, and Lucas Slot. \\newblock A note on the computational complexity of the moment-sos hierarchy for polynomial optimization. \\newblock In \\em Proceedings of the 2023 International Symposium on Symbolic and Algebraic Computation, ISSAC '23, page 280鈥288, New York, NY, USA, 2023. Association for Computing Machinery."}}
{"id": "2404.18097v3_gap_0", "arxiv_id": "2404.18097v3", "title": "Approximations of Rockafellians, Lagrangians, and Dual Functions", "publication_date": "2024-04-28", "problem_input": {"global_context": {"setup": "The paper considers an optimization problem of minimizing $\\phi:\\mathbb{R}^n\\to [-\\infty,\\infty]$ and approximating problems for $\\phi^\\nu$. It utilizes Rockafellians $f, f^\\nu: \\mathbb{R}^m\\times\\mathbb{R}^n\\to [-\\infty,\\infty]$ where $f(0,x) = \\phi(x)$, and defines substitute problems: Tilted Rockafellians $f_y(u,x) = f(u,x) - \\langle y, u\\rangle$, Lagrangians $l(x,y) = \\inf_u f_y(u,x)$, and dual functions $\\psi(y) = \\inf_{u,x} f_y(u,x)$. The analysis relies on epi-convergence ($f^\\nu \\xrightarrow{e} f$) and tightness.", "goal": "To prove that if $f^\\nu \\xrightarrow{e} f$ and $y^\\nu \\to y$, then $f^\\nu_{y^\\nu} \\xrightarrow{e} f_y$, $l^\\nu(\\cdot,y^\\nu) \\xrightarrow{e} l(\\cdot,y)$, and $\\psi^\\nu \\xrightarrow{h} \\psi$ (hypo-convergence), and to provide quantitative error bounds using truncated Hausdorff distance."}, "local_context": {"anchor_latex": "\\text{Theorem 3.1 and Proposition 6.1(d) imply that any cluster point } (\\bar u, \\bar x) \\text{ of } \\epsilon^\\nu\\text{-minimizers of } f^\\nu_{y^\\nu} \\text{ satisfies } (\\bar u, \\bar x) \\in \\nargmin f_y", "gap_objective": "Conclude that \\bar x \\in \\nargmin \\phi using the assumption that f is strictly exact supported by y"}}, "ground_truth": {"target_citation_key": "RoysetChenEckstrand.22", "target_lemma_latex": "\\text{If } f \\text{ is strictly exact for } \\phi \\text{ supported by } y, \\text{ then } \\nargmin f_y = \\{0\\} \\times \\nargmin \\phi", "target_citation_content": "J.~O. Royset, L.~L. Chen, and E.~Eckstrand. \\newblock Rockafellian relaxation and stochastic optimization under perturbations. \\newblock \\em Mathematics of Operations Research, to appear, 2025."}}
{"id": "2404.18097v3_gap_1", "arxiv_id": "2404.18097v3", "title": "Approximations of Rockafellians, Lagrangians, and Dual Functions", "publication_date": "2024-04-28", "problem_input": {"global_context": {"setup": "The paper considers an optimization problem of minimizing $\\phi:\\mathbb{R}^n\\to [-\\infty,\\infty]$ and approximating problems for $\\phi^\\nu$. It utilizes Rockafellians $f, f^\\nu: \\mathbb{R}^m\\times\\mathbb{R}^n\\to [-\\infty,\\infty]$ where $f(0,x) = \\phi(x)$, and defines substitute problems: Tilted Rockafellians $f_y(u,x) = f(u,x) - \\langle y, u\\rangle$, Lagrangians $l(x,y) = \\inf_u f_y(u,x)$, and dual functions $\\psi(y) = \\inf_{u,x} f_y(u,x)$. The analysis relies on epi-convergence ($f^\\nu \\xrightarrow{e} f$) and tightness.", "goal": "To prove that if $f^\\nu \\xrightarrow{e} f$ and $y^\\nu \\to y$, then $f^\\nu_{y^\\nu} \\xrightarrow{e} f_y$, $l^\\nu(\\cdot,y^\\nu) \\xrightarrow{e} l(\\cdot,y)$, and $\\psi^\\nu \\xrightarrow{h} \\psi$ (hypo-convergence), and to provide quantitative error bounds using truncated Hausdorff distance."}, "local_context": {"anchor_latex": "x^\nu \\in X^\nu", "gap_objective": "Characterize the minimizers of the tilted Rockafellian function $f_{y^\\nu}^\\nu(\\cdot, x^\\nu)$ in terms of the subdifferential of $h^\\nu$."}}, "ground_truth": {"target_citation_key": "primer", "target_lemma_latex": "u^\\nu \\in \\nargmin f_{y^\\nu}^\\nu(\\cdot, x^\\nu) \\Longleftrightarrow y^\\nu \\in \\partial h^\\nu(w^\\nu) \\quad \\text{with} \\quad w^\\nu = G^\\nu(x^\\nu) + u^\\nu", "target_citation_content": "J.~O. Royset and R.~J-B Wets. \\newblock \\em An Optimization Primer. \\newblock Springer, 2021."}}
{"id": "2404.18097v3_gap_2", "arxiv_id": "2404.18097v3", "title": "Approximations of Rockafellians, Lagrangians, and Dual Functions", "publication_date": "2024-04-28", "problem_input": {"global_context": {"setup": "The paper considers an optimization problem of minimizing $\\phi:\\mathbb{R}^n\\to [-\\infty,\\infty]$ and approximating problems for $\\phi^\\nu$. It utilizes Rockafellians $f, f^\\nu: \\mathbb{R}^m\\times\\mathbb{R}^n\\to [-\\infty,\\infty]$ where $f(0,x) = \\phi(x)$, and defines substitute problems: Tilted Rockafellians $f_y(u,x) = f(u,x) - \\langle y, u\\rangle$, Lagrangians $l(x,y) = \\inf_u f_y(u,x)$, and dual functions $\\psi(y) = \\inf_{u,x} f_y(u,x)$. The analysis relies on epi-convergence ($f^\\nu \\xrightarrow{e} f$) and tightness.", "goal": "To prove that if $f^\\nu \\xrightarrow{e} f$ and $y^\\nu \\to y$, then $f^\\nu_{y^\\nu} \\xrightarrow{e} f_y$, $l^\\nu(\\cdot,y^\\nu) \\xrightarrow{e} l(\\cdot,y)$, and $\\psi^\\nu \\xrightarrow{h} \\psi$ (hypo-convergence), and to provide quantitative error bounds using truncated Hausdorff distance."}, "local_context": {"anchor_latex": "h^{\\nu*} \\eto h^* \\text{ and } y \\notin \\bdry(\\dom h^*)", "gap_objective": "h^{\\nu*}(y) \\to h^*(y)"}}, "ground_truth": {"target_citation_key": "VaAn", "target_lemma_latex": "\\text{If } f^\\nu, f \\text{ are proper, lsc, convex functions and } f^\\nu \\eto f, \\text{ then } f^\\nu(x) \\to f(x) \\text{ for all } x \\notin \\bdry(\\dom f).", "target_citation_content": "R. T. Rockafellar and R.~J-B Wets. \\newblock \\em Variational Analysis. \\newblock Springer, 1998."}}
{"id": "2404.18097v3_gap_3", "arxiv_id": "2404.18097v3", "title": "Approximations of Rockafellians, Lagrangians, and Dual Functions", "publication_date": "2024-04-28", "problem_input": {"global_context": {"setup": "The paper considers an optimization problem of minimizing $\\phi:\\mathbb{R}^n\\to [-\\infty,\\infty]$ and approximating problems for $\\phi^\\nu$. It utilizes Rockafellians $f, f^\\nu: \\mathbb{R}^m\\times\\mathbb{R}^n\\to [-\\infty,\\infty]$ where $f(0,x) = \\phi(x)$, and defines substitute problems: Tilted Rockafellians $f_y(u,x) = f(u,x) - \\langle y, u\\rangle$, Lagrangians $l(x,y) = \\inf_u f_y(u,x)$, and dual functions $\\psi(y) = \\inf_{u,x} f_y(u,x)$. The analysis relies on epi-convergence ($f^\\nu \\xrightarrow{e} f$) and tightness.", "goal": "To prove that if $f^\\nu \\xrightarrow{e} f$ and $y^\\nu \\to y$, then $f^\\nu_{y^\\nu} \\xrightarrow{e} f_y$, $l^\\nu(\\cdot,y^\\nu) \\xrightarrow{e} l(\\cdot,y)$, and $\\psi^\\nu \\xrightarrow{h} \\psi$ (hypo-convergence), and to provide quantitative error bounds using truncated Hausdorff distance."}, "local_context": {"anchor_latex": "-\\psi(y) = \\sup\\{ \\langle y,u\\rangle - f(u,x) \\mid (u,x) \\in \\dom f \\} \\text{ for all } y\\in \\mathbb{R}^m", "gap_objective": "Conclude that the function -\\psi is lower semicontinuous"}}, "ground_truth": {"target_citation_key": "primer", "target_lemma_latex": "The pointwise supremum of a family of lower semicontinuous functions is lower semicontinuous.", "target_citation_content": "J.~O. Royset and R.~J-B Wets. \\newblock \\em An Optimization Primer. \\newblock Springer, 2021."}}
{"id": "2404.18097v3_gap_4", "arxiv_id": "2404.18097v3", "title": "Approximations of Rockafellians, Lagrangians, and Dual Functions", "publication_date": "2024-04-28", "problem_input": {"global_context": {"setup": "The paper considers an optimization problem of minimizing $\\phi:\\mathbb{R}^n\\to [-\\infty,\\infty]$ and approximating problems for $\\phi^\\nu$. It utilizes Rockafellians $f, f^\\nu: \\mathbb{R}^m\\times\\mathbb{R}^n\\to [-\\infty,\\infty]$ where $f(0,x) = \\phi(x)$, and defines substitute problems: Tilted Rockafellians $f_y(u,x) = f(u,x) - \\langle y, u\\rangle$, Lagrangians $l(x,y) = \\inf_u f_y(u,x)$, and dual functions $\\psi(y) = \\inf_{u,x} f_y(u,x)$. The analysis relies on epi-convergence ($f^\\nu \\xrightarrow{e} f$) and tightness.", "goal": "To prove that if $f^\\nu \\xrightarrow{e} f$ and $y^\\nu \\to y$, then $f^\\nu_{y^\\nu} \\xrightarrow{e} f_y$, $l^\\nu(\\cdot,y^\\nu) \\xrightarrow{e} l(\\cdot,y)$, and $\\psi^\\nu \\xrightarrow{h} \\psi$ (hypo-convergence), and to provide quantitative error bounds using truncated Hausdorff distance."}, "local_context": {"anchor_latex": "-\\psi^\\nu \\text{ and } -\\psi \\text{ are convex functions with } \\dom(-\\psi) \\text{ having a nonempty interior and } -\\psi \\text{ being lsc}", "gap_objective": "Establish the hypo-convergence \\psi^\\nu \\hto \\psi (equivalently -\\psi^\\nu \\eto -\\psi) by reducing it to pointwise convergence conditions"}}, "ground_truth": {"target_citation_key": "primer", "target_lemma_latex": "Let f, f^\\nu: \\reals^n \\to \\Reals be convex functions. If f is lsc with \\nt(\\dom f) \\neq \\emptyset, then f^\\nu \\eto f if and only if f^\\nu(x) \\to f(x) for all x in a dense subset of \\dom f.", "target_citation_content": "J.~O. Royset and R.~J-B Wets. \\newblock \\em An Optimization Primer. \\newblock Springer, 2021."}}
{"id": "2502.04339v1_gap_0", "arxiv_id": "2502.04339v1", "title": "Analysis of Diffusion Models for Manifold Data", "publication_date": "2025-02-01", "problem_input": {"global_context": {"setup": "We consider a generative diffusion model for data $x$ in an ambient space $\\mathbb{R}^d$. The data samples $x_i$ lie on a lower-dimensional manifold defined by $x_i = \\phi(\\frac{F\\xi_i}{\\sqrt{p}})$, where $p < d$, $F \\in \\mathbb{R}^{d \\times p}$ is a matrix (random Gaussian or orthogonal columns), and $\\phi$ is a point-wise non-linear activation function. The latent variables $\\xi_i$ are sampled from a mixture of two Gaussians $q(\\xi) = \\frac{1}{2} q_+(\\xi) + \\frac{1}{2} q_-(\\xi)$ in $\\mathbb{R}^p$. The system is analyzed in the high-dimensional asymptotic limit $d, p, n \\to \\infty$ with fixed ratios $p/d = \\beta$ and sample size $n = e^{\\alpha d}$. The backward diffusion process is governed by the empirical score function derived from the training samples.", "goal": "Derive explicit analytical expressions for the speciation time $t_S$ (when the process specializes to a class) and the collapse time $t_C$ (when the process collapses to a single training sample) in the specified high-dimensional regime."}, "local_context": {"anchor_latex": "\\zeta_{jl}^\\pm = \\mathbb{E}_{u,v\\sim\\mathcal{N}(0,\\Theta_{jl})}\\left[\\phi\\left(\\sqrt{\\rho}\\; u +\\lambda_j^\\pm\\right)\\phi\\left(\\sqrt{\\rho} v +\\lambda_l^\\pm\\right)\\right]", "gap_objective": "Expand the expectation of the product of non-linear functions of correlated Gaussian variables $u, v$ in powers of their correlation $\\theta_{jl}$ to simplify the expression."}}, "ground_truth": {"target_citation_key": "kibble_extension_1945", "target_lemma_latex": "\\mathbb{E}_{u, v \\sim \\mathcal{N}(0, \\Sigma_\\rho)}[f(u)g(v)] = \\sum_{k=0}^\\infty \\frac{\\rho^k}{k!} \\mathbb{E}[f(u)He_k(u)] \\mathbb{E}[g(v)He_k(v)]", "target_citation_content": "W.~F. Kibble, ``\\BIBforeignlanguageenAn extension of a theorem of Mehler's on Hermite polynomials,'' \\emph\\BIBforeignlanguageenMathematical Proceedings of the Cambridge Philosophical Society, vol.~41, no.~1, pp. 12--15, Jun. 1945."}}
{"id": "2502.04339v1_gap_1", "arxiv_id": "2502.04339v1", "title": "Analysis of Diffusion Models for Manifold Data", "publication_date": "2025-02-01", "problem_input": {"global_context": {"setup": "We consider a generative diffusion model for data $x$ in an ambient space $\\mathbb{R}^d$. The data samples $x_i$ lie on a lower-dimensional manifold defined by $x_i = \\phi(\\frac{F\\xi_i}{\\sqrt{p}})$, where $p < d$, $F \\in \\mathbb{R}^{d \\times p}$ is a matrix (random Gaussian or orthogonal columns), and $\\phi$ is a point-wise non-linear activation function. The latent variables $\\xi_i$ are sampled from a mixture of two Gaussians $q(\\xi) = \\frac{1}{2} q_+(\\xi) + \\frac{1}{2} q_-(\\xi)$ in $\\mathbb{R}^p$. The system is analyzed in the high-dimensional asymptotic limit $d, p, n \\to \\infty$ with fixed ratios $p/d = \\beta$ and sample size $n = e^{\\alpha d}$. The backward diffusion process is governed by the empirical score function derived from the training samples.", "goal": "Derive explicit analytical expressions for the speciation time $t_S$ (when the process specializes to a class) and the collapse time $t_C$ (when the process collapses to a single training sample) in the specified high-dimensional regime."}, "local_context": {"anchor_latex": "\\text{The matrix } F \\text{ is assumed to be a random matrix with i.i.d standard Gaussian entries.}", "gap_objective": "Replace the non-linear matrix function of random features with a statistically equivalent linear model (Gaussian Equivalence Principle) to compute the trace."}}, "ground_truth": {"target_citation_key": "gerace_generalisation_2020", "target_lemma_latex": "\\Gamma_0\\left(\\frac{FM}{\\sqrt{p}}\\right) \\approx \\varrho_0 \\mathbf{1}_d \\mathbf{1}_d^\\top + \\varrho_1 \\left(\\frac{F}{\\sqrt{p}} \\right) M + \\varrho_* \\Xi", "target_citation_content": "F.~Gerace, B.~Loureiro, F.~Krzakala, M.~Mezard, and L.~Zdeborova, ``\\BIBforeignlanguageenGeneralisation error in learning with random features and the hidden manifold model,'' in \\emph\\BIBforeignlanguageenProceedings of the 37th International Conference on Machine Learning.\\hskip 1em plus 0.5em minus 0.4em\\relax PMLR, Nov. 2020, pp. 3452--3462, iSSN: 2640-3498."}}
{"id": "2502.04339v1_gap_2", "arxiv_id": "2502.04339v1", "title": "Analysis of Diffusion Models for Manifold Data", "publication_date": "2025-02-01", "problem_input": {"global_context": {"setup": "We consider a generative diffusion model for data $x$ in an ambient space $\\mathbb{R}^d$. The data samples $x_i$ lie on a lower-dimensional manifold defined by $x_i = \\phi(\\frac{F\\xi_i}{\\sqrt{p}})$, where $p < d$, $F \\in \\mathbb{R}^{d \\times p}$ is a matrix (random Gaussian or orthogonal columns), and $\\phi$ is a point-wise non-linear activation function. The latent variables $\\xi_i$ are sampled from a mixture of two Gaussians $q(\\xi) = \\frac{1}{2} q_+(\\xi) + \\frac{1}{2} q_-(\\xi)$ in $\\mathbb{R}^p$. The system is analyzed in the high-dimensional asymptotic limit $d, p, n \\to \\infty$ with fixed ratios $p/d = \\beta$ and sample size $n = e^{\\alpha d}$. The backward diffusion process is governed by the empirical score function derived from the training samples.", "goal": "Derive explicit analytical expressions for the speciation time $t_S$ (when the process specializes to a class) and the collapse time $t_C$ (when the process collapses to a single training sample) in the specified high-dimensional regime."}, "local_context": {"anchor_latex": "\\sum_{j=1}^d \\Gamma_0\\left(\\lambda_j\\right)^2 = \\frac{1}{d} \\tr\\left[\\Gamma_0\\left(\\frac{FM}{\\sqrt{p}}\\right) \\Gamma_0\\left(\\frac{FM}{\\sqrt{p}}\\right)^\\top \\right]", "gap_objective": "Evaluate the trace of the matrix formed by the element-wise non-linear application $\\Gamma_0$ on the product of a random Gaussian matrix $F$ and a structured matrix $M$, in the high-dimensional limit."}}, "ground_truth": {"target_citation_key": "goldt_gaussian_2022", "target_lemma_latex": "\\Gamma_0\\left(\\frac{FM}{\\sqrt{p}}\\right) \\simeq \\varrho_0 \\one_d \\one_d^\\top + \\varrho_1 \\left(\\frac{F}{\\sqrt{p}} \\right) M + \\varrho_* \\Xi", "target_citation_content": "S.~Goldt, B.~Loureiro, G.~Reeves, F.~Krzakala, M.~Mezard, and L.~Zdeborova, ``\\BIBforeignlanguageenThe Gaussian equivalence of generative models for learning with shallow neural networks,'' in \\emph\\BIBforeignlanguageenProceedings of the 2nd Mathematical and Scientific Machine Learning Conference.\\hskip 1em plus 0.5em minus 0.4em\\relax PMLR, Apr. 2022, pp. 426--471, iSSN: 2640-3498."}}
